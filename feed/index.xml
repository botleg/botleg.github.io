<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>botleg</title>
    <description>Hi, botleg is a blog where you can find tutorials and techniques in web development, devops, databases, cloud computing and anything related to technology.</description>
    <link>https://botleg.com/</link>
    <atom:link href="https://botleg.com/feed" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 16 Apr 2018 13:52:24 +0000</pubDate>
    <lastBuildDate>Mon, 16 Apr 2018 13:52:24 +0000</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>Developing in AWS Lambda with Serverless Framework</title>
        <author><name>Hanzel Jesheen</name></author>
        <description>&lt;p&gt;Serverless or &lt;code class=&quot;highlighter-rouge&quot;&gt;Function as a Service&lt;/code&gt;, in a nutshell, is composed of some function and events configured for it. When the event is triggered, the function will be executed and whatever is returned by the function becomes the output. You are only charged for the time your function is executing. This is currently the highest level of abstration available. You don’t have to worry about deploying or scaling the function. By definition, High Availability and Auto-Scaling is built into the application.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://aws.amazon.com/&quot;&gt;AWS&lt;/a&gt; came up with the first serverless service called &lt;a href=&quot;https://aws.amazon.com/lambda/&quot;&gt;AWS Lambda&lt;/a&gt; and it is currently the biggest player in the space. With Lambda, you can write functions in Node.js, Python, Java and even C#. You are charged for every 100ms the code is executing. It is also connected to other services within AWS ecosystem. Other popular services are Google Cloud Functions, Azure Functions and Apache OpenWhisk.&lt;/p&gt;

&lt;p&gt;In this article, we will create a sample application using AWS Lambda and Serverless framework to find latency between different regions within AWS. The code for this application can be found &lt;a href=&quot;https://github.com/botleg/serverless-ping&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;why-serverless-framework&quot;&gt;Why Serverless Framework?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://serverless.com/&quot;&gt;Serverless&lt;/a&gt; is a framework that helps with the development in serverless platforms. In the traditional development with AWS Lambda, you need to write the function, add the dependencies, archive all the files to a &lt;code class=&quot;highlighter-rouge&quot;&gt;.zip&lt;/code&gt; file and upload it in the console and setup its configurations. This is not a streamlined approach for Serverless development. The following are some of the problems that this method has, which can be solved using Serverless Framework.&lt;/p&gt;

&lt;h1 id=&quot;hard-to-deploy&quot;&gt;Hard to deploy&lt;/h1&gt;

&lt;p&gt;Every time, you make some changes, you would have to archive the files to a &lt;code class=&quot;highlighter-rouge&quot;&gt;.zip&lt;/code&gt; file and upload it. This process is even more difficult if you have multiple dependent functions or services. Once you have setup the serverless framework, you can deploy the latest version of the code with the a single command, &lt;code class=&quot;highlighter-rouge&quot;&gt;sls deploy&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&quot;no-declarative-configuration&quot;&gt;No declarative configuration&lt;/h1&gt;

&lt;p&gt;If you are configuring the lambda functions from the AWS console, you have to fill a lot of fields up. You also have to go to a bunch of other services and set it all up. This makes it difficult to share your code. The functions will come with long set of steps for its configuration and deployment. With serverless framework, you can provide all the configuration related to the functions in a file called &lt;code class=&quot;highlighter-rouge&quot;&gt;serverless.yml&lt;/code&gt;. This file will contain the information about the service provider and all the functions. You can also add additional resources needed for the functions in the file.&lt;/p&gt;

&lt;h1 id=&quot;hard-to-test-locally&quot;&gt;Hard to test locally&lt;/h1&gt;

&lt;p&gt;With the console way, you can’t really test the functions locally before deploying it. With serverless framework, you can invoke the functions manually with the &lt;code class=&quot;highlighter-rouge&quot;&gt;sls invoke&lt;/code&gt; command. If the function name is &lt;code class=&quot;highlighter-rouge&quot;&gt;test&lt;/code&gt;, you can invoke it locally with &lt;code class=&quot;highlighter-rouge&quot;&gt;sls invoke local -f test&lt;/code&gt;. You can also run the version deployed in the AWS using the command, &lt;code class=&quot;highlighter-rouge&quot;&gt;sls invoke -f test&lt;/code&gt;. If you need to pass any JSON data to the functions, you can save the data to a file and give its path with the &lt;code class=&quot;highlighter-rouge&quot;&gt;sls invoke&lt;/code&gt; command. So, if the data file is &lt;code class=&quot;highlighter-rouge&quot;&gt;data.json&lt;/code&gt; and it is in the same folder as &lt;code class=&quot;highlighter-rouge&quot;&gt;serverless.yml&lt;/code&gt;, the command becomes &lt;code class=&quot;highlighter-rouge&quot;&gt;sls invoke local -f test -p data.json&lt;/code&gt;&lt;/p&gt;

&lt;h1 id=&quot;hard-to-get-logs&quot;&gt;Hard to get logs&lt;/h1&gt;

&lt;p&gt;With the console method, you have to go the CloudWatch and watch the logs. In the serverless framework, you can see the logs with the command, &lt;code class=&quot;highlighter-rouge&quot;&gt;sls logs&lt;/code&gt;. To see the logs for the function &lt;code class=&quot;highlighter-rouge&quot;&gt;test&lt;/code&gt; for the last 5 minutes, you can use the command &lt;code class=&quot;highlighter-rouge&quot;&gt;sls logs -f test --startTime 5m&lt;/code&gt;. You can also stream the logs to the console using &lt;code class=&quot;highlighter-rouge&quot;&gt;sls logs -f test -t&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;These are some of the issue that serverless framework solves for you. When you run the &lt;code class=&quot;highlighter-rouge&quot;&gt;sls deploy&lt;/code&gt; command, the following things happen:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The entire code base is archived to a &lt;code class=&quot;highlighter-rouge&quot;&gt;.zip&lt;/code&gt; file.&lt;/li&gt;
  &lt;li&gt;A &lt;code class=&quot;highlighter-rouge&quot;&gt;S3 bucket&lt;/code&gt; is created and the archived file is uploaded to it.&lt;/li&gt;
  &lt;li&gt;In the case of AWS, the framework reads the &lt;code class=&quot;highlighter-rouge&quot;&gt;serverless.yml&lt;/code&gt; file and creates corresponding &lt;code class=&quot;highlighter-rouge&quot;&gt;CloudFormation&lt;/code&gt; templates. This templates will contain the instructions to create lambda functions using the archived file from S3 bucket. It will also included the addtional resources and policies that is present in the &lt;code class=&quot;highlighter-rouge&quot;&gt;serverless.yml&lt;/code&gt; file.&lt;/li&gt;
  &lt;li&gt;The template created is pushed to the S3 bucket and it is executed. This creates all the functions and dependent services.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;installing-serverless-framework&quot;&gt;Installing Serverless Framework&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://serverless.com/&quot;&gt;Serverless&lt;/a&gt; is essentially an &lt;code class=&quot;highlighter-rouge&quot;&gt;Node.js CLI&lt;/code&gt; and it is available as a &lt;code class=&quot;highlighter-rouge&quot;&gt;NPM&lt;/code&gt; package. So, you need to have Node.js and npm installed in the system. If it is not already installed, check &lt;a href=&quot;https://nodejs.org/en/download/&quot;&gt;here&lt;/a&gt; to download the latest version. Once Node.js and npm is installed, you can install serverless framework with,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;npm install -g serverless&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can now use the serverless framwork using the command &lt;code class=&quot;highlighter-rouge&quot;&gt;serverless&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;sls&lt;/code&gt;. Now, you need to connect your AWS account to serverless. For this, you need to have &lt;code class=&quot;highlighter-rouge&quot;&gt;AWS Access Keys&lt;/code&gt;. To generate these, you can check &lt;a href=&quot;http://docs.aws.amazon.com/general/latest/gr/managing-aws-access-keys.html&quot;&gt;here&lt;/a&gt;. You will now have an &lt;code class=&quot;highlighter-rouge&quot;&gt;Access Key ID&lt;/code&gt; and a &lt;code class=&quot;highlighter-rouge&quot;&gt;Secret Access Key&lt;/code&gt;. Now you can associate serverless with your AWS account with the command,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;serverless config credentials --provider aws --key &amp;lt;Access Key ID&amp;gt; --secret &amp;lt;Secret Access Key&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;demo-application&quot;&gt;Demo Application&lt;/h2&gt;

&lt;p&gt;Now, we are ready to start developing in AWS Lambda with serverless framework. We will build a sample application that does &lt;code class=&quot;highlighter-rouge&quot;&gt;ping&lt;/code&gt; test to see the latency between different regions with AWS. We will deploy the application in one region and we can see the latency from that region to other regions. The result of the &lt;code class=&quot;highlighter-rouge&quot;&gt;ping&lt;/code&gt; tests will be stored in a S3 bucket. As the input, we will use a &lt;code class=&quot;highlighter-rouge&quot;&gt;JSON&lt;/code&gt; file with the list of regions and end-points. The code for this application is in &lt;code class=&quot;highlighter-rouge&quot;&gt;javascript&lt;/code&gt; and the runtime used is &lt;code class=&quot;highlighter-rouge&quot;&gt;Node.js 6.10&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/ping-arch@2x.jpg&quot; srcset=&quot;/assets/images/ping-arch@1x.jpg 300w, /assets/images/ping-arch@2x.jpg 600w, /assets/images/ping-arch@3x.jpg 900w&quot; sizes=&quot;(min-width: 960px) 900px, 100vw&quot; alt=&quot;Demo Application Architecture&quot; class=&quot;center-image&quot; /&gt;
&lt;em class=&quot;image-caption&quot;&gt;Demo Application Architecture&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;All the ping tests are independent to others, so we can run it in parallel. To do this, we use AWS &lt;a href=&quot;https://aws.amazon.com/sns&quot;&gt;Simple Notification Service (SNS)&lt;/a&gt;. SNS is bascially a notification service from AWS. With SNS, we can have multiple topics and each topic can have multiple subscribers. When a message is published to the topic, all its subscribers are notified. Here, we use one lambda function called &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt; to read from the input and publish message for each item in the data to a SNS topic. The second function, &lt;code class=&quot;highlighter-rouge&quot;&gt;ping&lt;/code&gt; becomes the subscriber for this topic. So each message published to the SNS topic will trigger lambda functions that will run in parallel. All these lambda function will run ping test for one region and stores the result in a S3 bucket.&lt;/p&gt;

&lt;h2 id=&quot;list-function&quot;&gt;List Function&lt;/h2&gt;

&lt;p&gt;List function should read from the JSON data and publish each entry as a message to a SNS topic. The data file &lt;code class=&quot;highlighter-rouge&quot;&gt;data.js&lt;/code&gt; looks this,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;nx&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;exports&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;s1&quot;&gt;'N.Virginia'&lt;/span&gt;      &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ec2.us-east-1.amazonaws.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s1&quot;&gt;'Ohio'&lt;/span&gt;            &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ec2.us-east-2.amazonaws.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s1&quot;&gt;'N.California'&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ec2.us-west-1.amazonaws.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s1&quot;&gt;'Oregon'&lt;/span&gt;          &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ec2.us-west-2.amazonaws.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s1&quot;&gt;'Canada'&lt;/span&gt;          &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ec2.ca-central-1.amazonaws.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s1&quot;&gt;'Frankfurt'&lt;/span&gt;       &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ec2.eu-central-1.amazonaws.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s1&quot;&gt;'London'&lt;/span&gt;          &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ec2.eu-west-2.amazonaws.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s1&quot;&gt;'Singapore'&lt;/span&gt;       &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ec2.ap-southeast-1.amazonaws.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s1&quot;&gt;'Sydney'&lt;/span&gt;          &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ec2.ap-southeast-2.amazonaws.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s1&quot;&gt;'Mumbai'&lt;/span&gt;          &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ec2.ap-south-1.amazonaws.com'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s1&quot;&gt;'SãoPaulo'&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'ec2.sa-east-1.amazonaws.com'&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We have a object with the region names as the keys and its URL endpoint as the values. We will be doing the ping test to the endpoints and save the results in S3 bucket as files named with the region name. This is just sample data that points to the &lt;code class=&quot;highlighter-rouge&quot;&gt;EC2&lt;/code&gt; endpoint in each region. The javascript file that contains the main function, &lt;code class=&quot;highlighter-rouge&quot;&gt;index.js&lt;/code&gt; is given below.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;s1&quot;&gt;'use strict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kr&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;AWS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'aws-sdk'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'./data'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;exports&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;handler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;callback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kr&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;split&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;invokedFunctionArn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;':'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;topic&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;arn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;aws&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]}:&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]}:&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;$&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;TOPIC_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;`&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;sns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;AWS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;SNS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;item&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;publish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;Message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;stringify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;region&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}),&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;TopicArn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;topic&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;promise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;nx&quot;&gt;callback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The code will be run on &lt;code class=&quot;highlighter-rouge&quot;&gt;Node.js 6.10&lt;/code&gt; runtime and it is in &lt;a href=&quot;http://es6-features.org/&quot;&gt;ES6&lt;/a&gt;. So, we start by choosing &lt;code class=&quot;highlighter-rouge&quot;&gt;strict&lt;/code&gt; mode. We will import &lt;code class=&quot;highlighter-rouge&quot;&gt;aws-sdk&lt;/code&gt; to publish messages to SNS and the data file, &lt;code class=&quot;highlighter-rouge&quot;&gt;data.js&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;handler&lt;/code&gt; function is the one that should be executed when the event is triggered. It receives three paramaters:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;event&lt;/code&gt;: This will contain information related to the event that triggered this function. If the event configured in an &lt;code class=&quot;highlighter-rouge&quot;&gt;API Gateway&lt;/code&gt; endpoint, you receive the URL, request headers and so on.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;context&lt;/code&gt;: This will contain the information about the AWS account that runs the function. You can fetch your AWS account number and region from this.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;callback&lt;/code&gt;: This is a function that should be called to return values from the function. In the case of &lt;code class=&quot;highlighter-rouge&quot;&gt;API Gateway&lt;/code&gt; event, this is where you will provide the response.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first thing we do in the function is to get the &lt;a href=&quot;http://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html&quot;&gt;ARN&lt;/a&gt; for the SNS topic that we need to publish to. This will be in the format &lt;code class=&quot;highlighter-rouge&quot;&gt;arn:aws:sns:&amp;lt;region&amp;gt;:&amp;lt;account number&amp;gt;:&amp;lt;topic name&amp;gt;&lt;/code&gt;. We are parsing the &lt;code class=&quot;highlighter-rouge&quot;&gt;context&lt;/code&gt; object to get the &lt;code class=&quot;highlighter-rouge&quot;&gt;account number&lt;/code&gt; and the &lt;code class=&quot;highlighter-rouge&quot;&gt;region&lt;/code&gt;. We are getting the &lt;code class=&quot;highlighter-rouge&quot;&gt;topic name&lt;/code&gt; from environment variables. We will talk more about this while writing &lt;code class=&quot;highlighter-rouge&quot;&gt;serverless.yml&lt;/code&gt; file. Now, for every &lt;code class=&quot;highlighter-rouge&quot;&gt;key&lt;/code&gt; in the data, we will publish a new message to SNS topic. We use the &lt;code class=&quot;highlighter-rouge&quot;&gt;sns.publish()&lt;/code&gt; function for this. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Message&lt;/code&gt; will contain region name as &lt;code class=&quot;highlighter-rouge&quot;&gt;region&lt;/code&gt; and endpoint as &lt;code class=&quot;highlighter-rouge&quot;&gt;url&lt;/code&gt;, converted to string. Also &lt;code class=&quot;highlighter-rouge&quot;&gt;TopicArn&lt;/code&gt; parameter will contain the topic name. We will also apply a &lt;code class=&quot;highlighter-rouge&quot;&gt;catch&lt;/code&gt; clause for error handling. Finally, as we don’t have to return anything from this function, we end with &lt;code class=&quot;highlighter-rouge&quot;&gt;callback(null)&lt;/code&gt;. Put both &lt;code class=&quot;highlighter-rouge&quot;&gt;data.js&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;index.js&lt;/code&gt; in the folder &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt; placed in the root of the project.&lt;/p&gt;

&lt;h2 id=&quot;ping-function&quot;&gt;Ping Function&lt;/h2&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;ping&lt;/code&gt; function is triggered by the SNS topic. Each instance of the function will act on one message or one region. It will receive the endpoint for one region and the ping test is done on it. The result is then saved into a S3 bucket with the region name as the file name. This function is given below in the file &lt;code class=&quot;highlighter-rouge&quot;&gt;index.js&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;s1&quot;&gt;'use strict'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kr&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Promise&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'bluebird'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;ping&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;Promise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;promisify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'tcp-ping'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;ping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;AWS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'aws-sdk'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;exports&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;handler&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;callback&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'Records'&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kr&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;event&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Records&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Sns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Message&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;nx&quot;&gt;ping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;address&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;then&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;s3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;AWS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;S3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;s3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;putObject&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;Bucket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;BUCKET_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;Key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;region&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;na&quot;&gt;Body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;stringify&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;}).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;promise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}).&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;catch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;console&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;err&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We start by importing &lt;code class=&quot;highlighter-rouge&quot;&gt;tcp-ping&lt;/code&gt; to do the ping test, &lt;code class=&quot;highlighter-rouge&quot;&gt;bluebird&lt;/code&gt; to &lt;a href=&quot;http://bluebirdjs.com/docs/api/promise.promisify.html&quot;&gt;promisify&lt;/a&gt; the ping test and &lt;code class=&quot;highlighter-rouge&quot;&gt;aws-sdk&lt;/code&gt; to write the result to S3. As before, &lt;code class=&quot;highlighter-rouge&quot;&gt;handler&lt;/code&gt; is the function triggered by the event. The message received from the SNS topic will be found at &lt;code class=&quot;highlighter-rouge&quot;&gt;event.Records[0].Sns.Message&lt;/code&gt; and we parse it to &lt;code class=&quot;highlighter-rouge&quot;&gt;body&lt;/code&gt;. We will do the ping test on the endpoint, &lt;code class=&quot;highlighter-rouge&quot;&gt;body.url&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;ping&lt;/code&gt; function.&lt;/p&gt;

&lt;p&gt;We now have to write the result of the ping test to the S3 bucket. For that, we will create a new &lt;code class=&quot;highlighter-rouge&quot;&gt;S3&lt;/code&gt; object and call its &lt;code class=&quot;highlighter-rouge&quot;&gt;putObject&lt;/code&gt; method. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Bucket&lt;/code&gt; name is obtained from the environment variable. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Key&lt;/code&gt;, or the file name, is the region name and is found at &lt;code class=&quot;highlighter-rouge&quot;&gt;body.region&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Body&lt;/code&gt; of the file is the result of the ping test as a string. As before, we add a couple of &lt;code class=&quot;highlighter-rouge&quot;&gt;catch&lt;/code&gt; clauses for error handling. Put this file &lt;code class=&quot;highlighter-rouge&quot;&gt;index.js&lt;/code&gt; inside the folder &lt;code class=&quot;highlighter-rouge&quot;&gt;ping&lt;/code&gt; placed in the project root.&lt;/p&gt;

&lt;h2 id=&quot;serverless-files&quot;&gt;Serverless Files&lt;/h2&gt;

&lt;p&gt;To manage the dependencies of this Node.js project, we need to have a &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file. We are using &lt;code class=&quot;highlighter-rouge&quot;&gt;aws-sdk&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;bluebird&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;tcp-ping&lt;/code&gt; as the &lt;code class=&quot;highlighter-rouge&quot;&gt;npm&lt;/code&gt; dependencies. So the &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file will look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;serverless-ping&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;dependencies&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;aws-sdk&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;^2.55.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;bluebird&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;^3.5.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;tcp-ping&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;^0.1.1&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now, we come to the &lt;code class=&quot;highlighter-rouge&quot;&gt;serverless.yml&lt;/code&gt; file. The configuration file of this project for serverles framework. It will contain configuration related to the service provider and each function. It also includes any additional resources needed for the project. To know more about this file, check &lt;a href=&quot;https://serverless.com/framework/docs/providers/aws/guide/serverless.yml/&quot;&gt;here&lt;/a&gt;. The file for this project looks like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-config&quot; data-lang=&quot;config&quot;&gt;&lt;span class=&quot;n&quot;&gt;service&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;ServerlessPing&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;custom&lt;/span&gt;: ${&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;(&lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;yml&lt;/span&gt;)}

&lt;span class=&quot;n&quot;&gt;provider&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;aws&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;stage&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;dev&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;runtime&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;nodejs6&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;10&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;region&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;us&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;west&lt;/span&gt;-&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;: ${&lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;(&lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;yml&lt;/span&gt;)}
  &lt;span class=&quot;n&quot;&gt;iamRoleStatements&lt;/span&gt;:
    - &lt;span class=&quot;n&quot;&gt;Effect&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'Allow'&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;Action&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'SNS:Publish'&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;Resource&lt;/span&gt;:
        &lt;span class=&quot;n&quot;&gt;Fn&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;Join&lt;/span&gt;:
          - &lt;span class=&quot;s1&quot;&gt;':'&lt;/span&gt;
          - - &lt;span class=&quot;s1&quot;&gt;'arn:aws:sns'&lt;/span&gt;
            - &lt;span class=&quot;n&quot;&gt;Ref&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'AWS::Region'&lt;/span&gt;
            - &lt;span class=&quot;n&quot;&gt;Ref&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'AWS::AccountId'&lt;/span&gt;
            - ${&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;:&lt;span class=&quot;n&quot;&gt;custom&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;TOPIC_NAME&lt;/span&gt;}
    - &lt;span class=&quot;n&quot;&gt;Effect&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'Allow'&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;Action&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'S3:PutObject'&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;Resource&lt;/span&gt;:
        &lt;span class=&quot;n&quot;&gt;Fn&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;Join&lt;/span&gt;:
          - &lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;
          - - &lt;span class=&quot;s1&quot;&gt;'arn:aws:s3:::'&lt;/span&gt;
            - ${&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;:&lt;span class=&quot;n&quot;&gt;custom&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;BUCKET_NAME&lt;/span&gt;}
            - &lt;span class=&quot;s1&quot;&gt;'/*'&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;functions&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;handler&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;list&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;handler&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;ping&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;handler&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;ping&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;handler&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;events&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;sns&lt;/span&gt;: ${&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;:&lt;span class=&quot;n&quot;&gt;custom&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;TOPIC_NAME&lt;/span&gt;}

&lt;span class=&quot;n&quot;&gt;resources&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;Resources&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;PingBucket&lt;/span&gt;:
      &lt;span class=&quot;n&quot;&gt;Type&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;AWS&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;S3&lt;/span&gt;::&lt;span class=&quot;n&quot;&gt;Bucket&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;Properties&lt;/span&gt;:
&lt;span class=&quot;n&quot;&gt;BucketName&lt;/span&gt;: ${&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;:&lt;span class=&quot;n&quot;&gt;custom&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;BUCKET_NAME&lt;/span&gt;}&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We start with the project name, &lt;code class=&quot;highlighter-rouge&quot;&gt;ServerlessPing&lt;/code&gt; in this case. We can add custom variables from external files to this file. We use this to setup environment variables and to use those values in this file. This lets us store secret values within the project that we don’t want to share with the code. In this case, we have a file for environment variables called &lt;code class=&quot;highlighter-rouge&quot;&gt;env.yml&lt;/code&gt;. This file looks like below:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-config&quot; data-lang=&quot;config&quot;&gt;&lt;span class=&quot;n&quot;&gt;TOPIC_NAME&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;ping&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;BUCKET_NAME&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;awspingdump&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Here, the &lt;code class=&quot;highlighter-rouge&quot;&gt;TOPIC_NAME&lt;/code&gt; refers to the name of the SNS topic and the &lt;code class=&quot;highlighter-rouge&quot;&gt;BUCKET_NAME&lt;/code&gt; refers to the S3 bucket to store the results in. As all the S3 buckets should have a unique name, you would have to change the &lt;code class=&quot;highlighter-rouge&quot;&gt;BUCKET_NAME&lt;/code&gt; to something else. To refer to these values in the &lt;code class=&quot;highlighter-rouge&quot;&gt;serverless.yml&lt;/code&gt;, we use the &lt;code class=&quot;highlighter-rouge&quot;&gt;custom&lt;/code&gt; key which is directed to the &lt;code class=&quot;highlighter-rouge&quot;&gt;env.yml&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;With the &lt;code class=&quot;highlighter-rouge&quot;&gt;provider&lt;/code&gt; object in &lt;code class=&quot;highlighter-rouge&quot;&gt;serverless.yml&lt;/code&gt;, we will setup configuration related to the service provider. These are common for all functions. Here, the &lt;code class=&quot;highlighter-rouge&quot;&gt;name&lt;/code&gt; of the provider is &lt;code class=&quot;highlighter-rouge&quot;&gt;aws&lt;/code&gt; and the stage is currently &lt;code class=&quot;highlighter-rouge&quot;&gt;dev&lt;/code&gt;. As the function goes for production, you can change &lt;code class=&quot;highlighter-rouge&quot;&gt;stage&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;prod&lt;/code&gt;. As the code is javascript, we ues &lt;code class=&quot;highlighter-rouge&quot;&gt;Node.js 6.10&lt;/code&gt; as the runtime. Also, we set the region to deploy the function as &lt;code class=&quot;highlighter-rouge&quot;&gt;us-west-2&lt;/code&gt;. To move it to some other region, just change this field. We also need to use the file &lt;code class=&quot;highlighter-rouge&quot;&gt;env.yml&lt;/code&gt; to set the environment variables. For this, we use the &lt;code class=&quot;highlighter-rouge&quot;&gt;environment&lt;/code&gt; field and we point it to external file &lt;code class=&quot;highlighter-rouge&quot;&gt;env.yml&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Next, we will set the &lt;code class=&quot;highlighter-rouge&quot;&gt;iamRoleStatements&lt;/code&gt;. This is to set permission to be applied to the functions. In our case, we need the function to able to publish to SNS topic and put files in S3. To know more about this, check &lt;a href=&quot;https://serverless.com/framework/docs/providers/aws/guide/iam/&quot;&gt;here&lt;/a&gt;. For each entry in &lt;code class=&quot;highlighter-rouge&quot;&gt;iamRoleStatements&lt;/code&gt;, we need to mention three fields: &lt;code class=&quot;highlighter-rouge&quot;&gt;Effect&lt;/code&gt; which could be &lt;code class=&quot;highlighter-rouge&quot;&gt;Allow&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;Deny&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;Action&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Resource&lt;/code&gt; name.&lt;/p&gt;

&lt;p&gt;The first statement is to be able to publish to SNS. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Effect&lt;/code&gt; is &lt;code class=&quot;highlighter-rouge&quot;&gt;Allow&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Action&lt;/code&gt; is &lt;code class=&quot;highlighter-rouge&quot;&gt;SNS:Publish&lt;/code&gt;. As discussed before, the name of topic is in the format &lt;code class=&quot;highlighter-rouge&quot;&gt;arn:aws:sns:&amp;lt;region&amp;gt;:&amp;lt;account number&amp;gt;:&amp;lt;topic name&amp;gt;&lt;/code&gt;. To construct this, we use &lt;code class=&quot;highlighter-rouge&quot;&gt;Fn::Join&lt;/code&gt; which joins the list of items with a &lt;code class=&quot;highlighter-rouge&quot;&gt;delimiter&lt;/code&gt;, which is &lt;code class=&quot;highlighter-rouge&quot;&gt;:&lt;/code&gt; in this case. We start with &lt;code class=&quot;highlighter-rouge&quot;&gt;arn:aws:sns&lt;/code&gt;, to which we append AWS region name with &lt;code class=&quot;highlighter-rouge&quot;&gt;Ref: 'AWS::Region'&lt;/code&gt; and AWS account number with &lt;code class=&quot;highlighter-rouge&quot;&gt;Ref: 'AWS::AccountId'&lt;/code&gt;. Finally, we also append the topic name obtained from the &lt;code class=&quot;highlighter-rouge&quot;&gt;env.yml&lt;/code&gt; file, which is read from the custom field. This can obtainer with &lt;code class=&quot;highlighter-rouge&quot;&gt;${self:custom.TOPIC_NAME}&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The second statement is to be able to put files into S3 bucket. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Effect&lt;/code&gt; is &lt;code class=&quot;highlighter-rouge&quot;&gt;Allow&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Action&lt;/code&gt; is &lt;code class=&quot;highlighter-rouge&quot;&gt;S3:PutObject&lt;/code&gt;. To give permission to write to a bucket, we need to give resource name in the format &lt;code class=&quot;highlighter-rouge&quot;&gt;arn:aws:s3:::&amp;lt;bucket name&amp;gt;/*&lt;/code&gt;. As before, we will construct this using &lt;code class=&quot;highlighter-rouge&quot;&gt;Fn::Join&lt;/code&gt;, but now the delimiter is blank. We start with &lt;code class=&quot;highlighter-rouge&quot;&gt;arn:aws:s3:::&lt;/code&gt;, to which we append the bucket name from the &lt;code class=&quot;highlighter-rouge&quot;&gt;custom&lt;/code&gt; field, with &lt;code class=&quot;highlighter-rouge&quot;&gt;${self:custom.BUCKET_NAME}&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;/*&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;After the provider configuration, we set up configuration for each function. The first function is &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt;. Handler for this function is &lt;code class=&quot;highlighter-rouge&quot;&gt;handler&lt;/code&gt; in the file &lt;code class=&quot;highlighter-rouge&quot;&gt;index.js&lt;/code&gt; in the &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt; folder, so that is given as &lt;code class=&quot;highlighter-rouge&quot;&gt;list.handler&lt;/code&gt;. For this demo, we will run this function manually with &lt;code class=&quot;highlighter-rouge&quot;&gt;sls invoke&lt;/code&gt; command. You can set up a variety of events for each functions. You can see more about events &lt;a href=&quot;https://serverless.com/framework/docs/providers/aws/guide/events/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The second function is &lt;code class=&quot;highlighter-rouge&quot;&gt;ping&lt;/code&gt;. As before, the handler for it is &lt;code class=&quot;highlighter-rouge&quot;&gt;handler&lt;/code&gt; within &lt;code class=&quot;highlighter-rouge&quot;&gt;index.js&lt;/code&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;ping&lt;/code&gt; folder. So, handler becomes &lt;code class=&quot;highlighter-rouge&quot;&gt;ping.handler&lt;/code&gt;. This function is to be triggered by the SNS topic. which makes the event &lt;code class=&quot;highlighter-rouge&quot;&gt;sns&lt;/code&gt;. The topic name is obtained from the &lt;code class=&quot;highlighter-rouge&quot;&gt;custom&lt;/code&gt; field, so the topic name is &lt;code class=&quot;highlighter-rouge&quot;&gt;${self:custom.TOPIC_NAME}&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Finally, we need to provision a S3 bucket to store the results. We add the &lt;code class=&quot;highlighter-rouge&quot;&gt;resources&lt;/code&gt; object to this file for this. We have a resource named &lt;code class=&quot;highlighter-rouge&quot;&gt;PingBucket&lt;/code&gt;, which is a S3 bucket or &lt;code class=&quot;highlighter-rouge&quot;&gt;AWS::S3::Bucket&lt;/code&gt;. For properties, we give the name of the bucket from the value in the &lt;code class=&quot;highlighter-rouge&quot;&gt;custom&lt;/code&gt; field: &lt;code class=&quot;highlighter-rouge&quot;&gt;${self:custom.BUCKET_NAME}&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;deploying-application&quot;&gt;Deploying Application&lt;/h2&gt;

&lt;p&gt;Place the files &lt;code class=&quot;highlighter-rouge&quot;&gt;serverless.yml&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;env.yml&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; in the project the root. It should also contain the &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;ping&lt;/code&gt; folder. We can import the dependencies with the command,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;npm install&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We are now ready to deploy this application, which can done with a single command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sls deploy&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This will archive the project file and push it to S3; create the necessary cloudformation template to deploy the function and events; and create the additional S3 bucket. After the deploy is done, you can see the Lambda jobs, SNS topics, and S3 buckets created. If you make any changes, you can deploy the changes with the same &lt;code class=&quot;highlighter-rouge&quot;&gt;sls deploy&lt;/code&gt; command. We will now manually trigger the &lt;code class=&quot;highlighter-rouge&quot;&gt;list&lt;/code&gt; function, which will trigger multiple &lt;code class=&quot;highlighter-rouge&quot;&gt;ping&lt;/code&gt; functions and fill up the S3 bucket with ping test results.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sls invoke -f list&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now if you check the S3 bucket, you can see the files for each region. Each file will contain the JSON result of the ping test of that region.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/s3-dump@2x.jpg&quot; srcset=&quot;/assets/images/s3-dump@1x.jpg 300w, /assets/images/s3-dump@2x.jpg 600w, /assets/images/s3-dump@3x.jpg 900w&quot; sizes=&quot;(min-width: 960px) 900px, 100vw&quot; alt=&quot;Ping results in S3&quot; class=&quot;center-image&quot; /&gt;
&lt;em class=&quot;image-caption&quot;&gt;Ping results in S3&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article, we have made an introduction to serverless with AWS Lambda and Serverless framework. We have also designed an application to leverage the advantages provided by the serverless approach and deployed it using serverless framework to AWS Lambda. This approach can be used in a wide variety of use-cases to get high-available application at a fraction of the cost.&lt;/p&gt;

&lt;p&gt;You can remove the complete function off AWS with the command &lt;code class=&quot;highlighter-rouge&quot;&gt;sls remove&lt;/code&gt;. This will remove the functions, events and any additional resources.&lt;/p&gt;
</description>
        <pubDate>Tue, 30 May 2017 18:00:00 +0000</pubDate>
        <link>https://botleg.com/stories/developing-in-aws-lambda-with-serverless-framework/</link>
        <guid isPermaLink="true">https://botleg.com/stories/developing-in-aws-lambda-with-serverless-framework/</guid>
        
        <category>serverless</category>
        
        <category>lambda</category>
        
        <category>aws</category>
        
        <category>sns</category>
        
        <category>faas</category>
        
        <category>ping</category>
        
        <category>arn</category>
        
        <category>s3</category>
        
        
        <category>cloud</category>
        
      </item>
    
      <item>
        <title>Log Management for Docker Swarm with ELK Stack</title>
        <author><name>Hanzel Jesheen</name></author>
        <description>&lt;p&gt;In the &lt;a href=&quot;/stories/monitoring-docker-swarm-with-cadvisor-influxdb-and-grafana/&quot;&gt;previous article&lt;/a&gt;, we covered how to monitor a Docker Swarm. As a follow up, in this article, we will go through setting up a dynamic solution for log management in a docker swarm. We will be collecting logs from all the containers in all the nodes of the swarm. With all this data, we would also be able to do querying and analysis.&lt;/p&gt;

&lt;p&gt;We will use the very popular &lt;a href=&quot;https://www.elastic.co/products&quot;&gt;ELK stack&lt;/a&gt; from &lt;a href=&quot;https://www.elastic.co&quot;&gt;elastic&lt;/a&gt; for log management. This includes &lt;a href=&quot;https://www.elastic.co/products/elasticsearch&quot;&gt;Elasticsearch&lt;/a&gt;, &lt;a href=&quot;https://www.elastic.co/products/logstash&quot;&gt;Logstash&lt;/a&gt; and &lt;a href=&quot;https://www.elastic.co/products/kibana&quot;&gt;Kibana&lt;/a&gt;. &lt;code class=&quot;highlighter-rouge&quot;&gt;Elasticsearch&lt;/code&gt; is the database to store the log data and query for it. &lt;code class=&quot;highlighter-rouge&quot;&gt;Logstash&lt;/code&gt; is a log collection pipeline that ingests logs from multiple sources and feeds it to Elasticsearch. &lt;code class=&quot;highlighter-rouge&quot;&gt;Kibana&lt;/code&gt; is the web UI to display Elasticsearch data. We will also deploy &lt;a href=&quot;https://github.com/gliderlabs/logspout&quot;&gt;logspout&lt;/a&gt; to all nodes in the swarm, which will connect to docker daemon in the host to collect all logs and feed it to logstash. All these tools are open-source and can be deployed as a container.&lt;/p&gt;

&lt;p&gt;We will use the Docker Swarm Mode to build the cluster and deploy these services as a stack. This allows for us to collect logs from any container without making any changes. Any logs that can be seen with &lt;code class=&quot;highlighter-rouge&quot;&gt;docker logs&lt;/code&gt; command will be automatically collected. Also, logs will collected from any new nodes joining the swarm. All the files used for this project can be found &lt;a href=&quot;https://github.com/botleg/swarm-logging&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;the-stack&quot;&gt;The Stack&lt;/h2&gt;

&lt;p&gt;The tools that we use for log management stack are all open-source. These tools are all container-friendly and easily scalable. Our stack comprises of the following tools.&lt;/p&gt;

&lt;h1 id=&quot;elasticsearch&quot;&gt;Elasticsearch&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Elasticsearch is a distributed, RESTful search and analytics engine capable of solving a growing number of use cases.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://www.elastic.co/products/elasticsearch&quot;&gt;Elasticsearch&lt;/a&gt; is essentially a database that store JSON documents, based on &lt;a href=&quot;https://lucene.apache.org/&quot;&gt;Apache Lucene&lt;/a&gt;. It is a very powerful and efficent full-text search engine with a REST API. In this article, we will deploy only a single instance of Elasticsearch. However, for any sort of production setup, you would need to setup a cluster of Elasticsearch. To setup an Elasticsearch cluster, check &lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/current/docker.html#docker-cli-run-prod-mode&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;https://github.com/deviantony/docker-elk/wiki/Elasticsearch-cluster&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;logstash&quot;&gt;Logstash&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Logstash is an open source, server-side data processing pipeline that ingests data from a multitude of sources simultaneously, transforms it, and then sends it to your favorite “stash”.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://www.elastic.co/products/logstash&quot;&gt;Logstash&lt;/a&gt; ingests data from many source, do some processing and then feed it to Elasticsearch. In this demo, we are pushing the logs to a single instance for logstash. We can have multiple instances of logstash and even have a layer of &lt;a href=&quot;https://www.elastic.co/products/beats&quot;&gt;Beats shippers&lt;/a&gt; that push logs to logstash.&lt;/p&gt;

&lt;h1 id=&quot;kibana&quot;&gt;Kibana&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Kibana lets you visualize your Elasticsearch data and navigate the Elastic Stack.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://www.elastic.co/products/kibana&quot;&gt;Kibana&lt;/a&gt; is a web UI for elastic stack. It lets you see and query the log data. You can create graphs and dashboards with the data. Kibana stores all the information including the graphs in elasticsearch. So, Kibana in itself is stateless and can be scaled independently.&lt;/p&gt;

&lt;h1 id=&quot;logspout&quot;&gt;Logspout&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Log routing for Docker container logs&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/gliderlabs/logspout&quot;&gt;Logspout&lt;/a&gt; from Gliderlabs is log router that connects to the docker daemon and collects logs from all its container. Here, we use the logstash plugin to push it to logstash. We use the &lt;a href=&quot;https://github.com/Bekt/logspout-logstash&quot;&gt;bekt/logspout-logstash&lt;/a&gt; image for this. We deploy it to all nodes in the cluster to get all the logs.&lt;/p&gt;

&lt;h2 id=&quot;docker-swarm-mode&quot;&gt;Docker Swarm Mode&lt;/h2&gt;

&lt;p&gt;The first thing to do is to create a &lt;a href=&quot;https://docs.docker.com/engine/swarm/&quot;&gt;Docker Swarm&lt;/a&gt; with the &lt;a href=&quot;https://docs.docker.com/machine/&quot;&gt;docker-machine&lt;/a&gt;. We will be creating a swarm with one manager named &lt;code class=&quot;highlighter-rouge&quot;&gt;manager&lt;/code&gt; and two workers named &lt;code class=&quot;highlighter-rouge&quot;&gt;agent1&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;agent2&lt;/code&gt;. To follow along with the demonstration, you need to have the following prerequisites:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker&lt;/code&gt;: version &amp;gt;= 1.13, to support Docker Compose File version 3 and Swarm Mode.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Machine&lt;/code&gt;: version &amp;gt;= 0.8&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Compose&lt;/code&gt;: version &amp;gt;= 1.10, to support Docker Compose file version 3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I have explained how to do this in my previous article, &lt;a href=&quot;/stories/monitoring-docker-swarm-with-cadvisor-influxdb-and-grafana/&quot;&gt;Monitoring Docker Swarm with cAdvisor, InfluxDB and Grafana&lt;/a&gt;. Follow the steps in the section &lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Swarm Mode&lt;/code&gt; of that article to create and setup the Swarm. Once the swarm is setup, you can see the hosts with &lt;code class=&quot;highlighter-rouge&quot;&gt;docker node ls&lt;/code&gt; command. The output of this command must look something like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
3j231njh03spl0j8h67z069cy &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;  manager   Ready   Active        Leader
muxpteij6aldkixnl31f0asar    agent1    Ready   Active
y2gstaqpqix1exz09nyjn8z41    agent2    Ready   Active&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;docker-stack&quot;&gt;Docker Stack&lt;/h2&gt;

&lt;p&gt;For elasticsearch to not give &lt;code class=&quot;highlighter-rouge&quot;&gt;Out of Memory&lt;/code&gt; errors, we need set &lt;code class=&quot;highlighter-rouge&quot;&gt;vm.max_map_count&lt;/code&gt; of the kernel of VMs to atleast &lt;code class=&quot;highlighter-rouge&quot;&gt;262144&lt;/code&gt;. To do this, run the following commands.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-machine ssh manager sudo sysctl -w vm.max_map_count&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;262144
docker-machine ssh agent1 sudo sysctl -w vm.max_map_count&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;262144
docker-machine ssh agent2 sudo sysctl -w vm.max_map_count&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;262144&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We will define the entire stack for logging in the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-stack.yml&lt;/code&gt; file. This will contain the information about different services including the deploy stratergies. This file will be in the &lt;a href=&quot;https://docs.docker.com/compose/compose-file/&quot;&gt;docker-compose v3&lt;/a&gt; format. We can then deploy it with one command. The &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-stack.yml&lt;/code&gt; file is given below.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'3'&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;elasticsearch&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;elastic&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;co&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;elasticsearch&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;elasticsearch&lt;/span&gt;:&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
      &lt;span class=&quot;n&quot;&gt;ES_JAVA_OPTS&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'-Xms256m -Xmx256m'&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;xpack&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;security&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;enabled&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'false'&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;xpack&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;monitoring&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;enabled&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'false'&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;xpack&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;enabled&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'false'&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;xpack&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;watcher&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;enabled&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'false'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;esdata&lt;/span&gt;:/&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;share&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;elasticsearch&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;deploy&lt;/span&gt;:
      &lt;span class=&quot;n&quot;&gt;replicas&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;placement&lt;/span&gt;:
        &lt;span class=&quot;n&quot;&gt;constraints&lt;/span&gt;:
          - &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;hostname&lt;/span&gt; == &lt;span class=&quot;n&quot;&gt;agent1&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;logstash&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;elastic&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;co&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;logstash&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;logstash&lt;/span&gt;:&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
      - ./&lt;span class=&quot;n&quot;&gt;logstash&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;logstash&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;:/&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;share&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;logstash&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;pipeline&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;logstash&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depends_on&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;elasticsearch&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;deploy&lt;/span&gt;:
      &lt;span class=&quot;n&quot;&gt;replicas&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;logspout&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;bekt&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;logspout&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;logstash&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
      &lt;span class=&quot;n&quot;&gt;ROUTE_URIS&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'logstash://logstash:5000'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
      - /&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;sock&lt;/span&gt;:/&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;sock&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depends_on&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;logstash&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;deploy&lt;/span&gt;:
      &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;global&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;restart_policy&lt;/span&gt;:
        &lt;span class=&quot;n&quot;&gt;condition&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;on&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;failure&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;delay&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;kibana&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;elastic&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;co&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;kibana&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;kibana&lt;/span&gt;:&lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
      - &lt;span class=&quot;s1&quot;&gt;'80:5601'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depends_on&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;elasticsearch&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
      &lt;span class=&quot;n&quot;&gt;ELASTICSEARCH_URL&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'http://elasticsearch:9200'&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;XPACK_SECURITY_ENABLED&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'false'&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;XPACK_MONITORING_ENABLED&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'false'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;deploy&lt;/span&gt;:
      &lt;span class=&quot;n&quot;&gt;replicas&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;esdata&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We will start by saying that we are using the version 3 of &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose&lt;/code&gt; file. We have following 4 services in the stack.&lt;/p&gt;

&lt;h1 id=&quot;elasticsearch-1&quot;&gt;elasticsearch&lt;/h1&gt;

&lt;p&gt;For the Elasticsearch service, we use the offical &lt;code class=&quot;highlighter-rouge&quot;&gt;docker.elastic.co/elasticsearch/elasticsearch&lt;/code&gt; image. With the &lt;code class=&quot;highlighter-rouge&quot;&gt;ES_JAVA_OPTS&lt;/code&gt; environment variable, we will set the heap space, 256MB as the minimum and maximum here. Also, the official image comes with &lt;a href=&quot;https://www.elastic.co/products/x-pack&quot;&gt;X-Pack&lt;/a&gt; installed, which will take care of security, monitoring, alerting etc. of the elastic stack. For this demo, we will disable the X-Pack. We set &lt;code class=&quot;highlighter-rouge&quot;&gt;xpack.security.enabled&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;xpack.monitoring.enabled&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;xpack.graph.enabled&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;xpack.watcher.enabled&lt;/code&gt; as &lt;code class=&quot;highlighter-rouge&quot;&gt;false&lt;/code&gt; to do this. We will setup a docker volume named &lt;code class=&quot;highlighter-rouge&quot;&gt;esdata&lt;/code&gt; mounted at &lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/share/elasticsearch/data&lt;/code&gt; to store all Elasticsearch data. In the deploy key, we are saying that we need one copy of it. We are placing this service in &lt;code class=&quot;highlighter-rouge&quot;&gt;agent1&lt;/code&gt; node. This is done to make sure that the volume is always in that host.&lt;/p&gt;

&lt;h1 id=&quot;logstash-1&quot;&gt;logstash&lt;/h1&gt;

&lt;p&gt;We will use the official &lt;code class=&quot;highlighter-rouge&quot;&gt;docker.elastic.co/logstash/logstash&lt;/code&gt; image for logstash. We also need to setup a custom configuration file for logstash to define its pipeline. The configuration file &lt;code class=&quot;highlighter-rouge&quot;&gt;logstash.conf&lt;/code&gt; is given below.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;input&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;udp&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;port&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5000&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;codec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=~&lt;/span&gt; &lt;span class=&quot;sr&quot;&gt;/logstash/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;elasticsearch&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hosts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;elasticsearch:9200&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;stdout&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;codec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rubydebug&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The config file contains three sections. The &lt;code class=&quot;highlighter-rouge&quot;&gt;input&lt;/code&gt; section defines where logstash is listening for log data. In this case, logstash will listen at port &lt;code class=&quot;highlighter-rouge&quot;&gt;5000&lt;/code&gt; where log will be coming in &lt;code class=&quot;highlighter-rouge&quot;&gt;json&lt;/code&gt; format and using &lt;code class=&quot;highlighter-rouge&quot;&gt;UDP&lt;/code&gt; protocol. The &lt;code class=&quot;highlighter-rouge&quot;&gt;filter&lt;/code&gt; section can do some processing with the log data. Here, we will drop all the logs coming from &lt;code class=&quot;highlighter-rouge&quot;&gt;logstash&lt;/code&gt; image, as those are duplicates. The &lt;code class=&quot;highlighter-rouge&quot;&gt;output&lt;/code&gt; section defines where logstash is feeding the data to. Here, we will send it to &lt;code class=&quot;highlighter-rouge&quot;&gt;elasticsearch&lt;/code&gt; service at port &lt;code class=&quot;highlighter-rouge&quot;&gt;9200&lt;/code&gt;. We will use the &lt;code class=&quot;highlighter-rouge&quot;&gt;rubydebug&lt;/code&gt; codec as it will use &lt;a href=&quot;https://github.com/awesome-print/awesome_print&quot;&gt;Ruby Awesome Print&lt;/a&gt; library to pretty-print the data.&lt;/p&gt;

&lt;p&gt;Put this file, &lt;code class=&quot;highlighter-rouge&quot;&gt;logstash.conf&lt;/code&gt; in a folder named &lt;code class=&quot;highlighter-rouge&quot;&gt;logstash&lt;/code&gt;. We are creating a volume to share this file at the location &lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/share/logstash/pipeline&lt;/code&gt; of the container. This will then be read automatically when logstash starts up. Also, this service depends on Elasticsearch as it feed data to it. As before, we only need one copy of this service.&lt;/p&gt;

&lt;h1 id=&quot;logspout-1&quot;&gt;logspout&lt;/h1&gt;

&lt;p&gt;For &lt;code class=&quot;highlighter-rouge&quot;&gt;logspout&lt;/code&gt;, we use &lt;a href=&quot;https://hub.docker.com/r/bekt/logspout-logstash&quot;&gt;bekt/logspout-logstash&lt;/a&gt; image. This image contains &lt;a href=&quot;https://github.com/gliderlabs/logspout&quot;&gt;logspout&lt;/a&gt; with &lt;a href=&quot;https://github.com/looplab/logspout-logstash&quot;&gt;logstash plugin&lt;/a&gt;. We need to provide the &lt;code class=&quot;highlighter-rouge&quot;&gt;ROUTE_URIS&lt;/code&gt; environment variable with the location of logstash. In this case, it is &lt;code class=&quot;highlighter-rouge&quot;&gt;logstash:5000&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;logstash&lt;/code&gt; protocol. We also need to create a volume for the Docker socket, &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/run/docker.sock&lt;/code&gt;. This lets the container to attach to the docker daemon in the host and collect all the logs. This service depends on Logstash as it feed data to it. We need to deploy this service to all the nodes. So we use the &lt;code class=&quot;highlighter-rouge&quot;&gt;global&lt;/code&gt; mode for &lt;code class=&quot;highlighter-rouge&quot;&gt;deploy&lt;/code&gt;. Also, there is a chance for this service to fail bacause logstash is not ready. So, we setup a restart policy that restarts the service if it fails with a delay of 30 seconds.&lt;/p&gt;

&lt;h1 id=&quot;kibana-1&quot;&gt;kibana&lt;/h1&gt;

&lt;p&gt;We use the official &lt;code class=&quot;highlighter-rouge&quot;&gt;docker.elastic.co/kibana/kibana&lt;/code&gt; image and expose the port &lt;code class=&quot;highlighter-rouge&quot;&gt;5601&lt;/code&gt; of the container to port &lt;code class=&quot;highlighter-rouge&quot;&gt;80&lt;/code&gt; of the host. The &lt;code class=&quot;highlighter-rouge&quot;&gt;router mesh&lt;/code&gt; feature will then let us access kibana from port 80 of any host in the swarm. This service get data from Elasticsearch, so depended on it. We need to set the &lt;code class=&quot;highlighter-rouge&quot;&gt;ELASTICSEARCH_URL&lt;/code&gt; to the elasticsearch service, &lt;code class=&quot;highlighter-rouge&quot;&gt;http://elasticsearch:9200&lt;/code&gt; in this case. We also set the &lt;code class=&quot;highlighter-rouge&quot;&gt;XPACK_SECURITY_ENABLED&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;XPACK_MONITORING_ENABLED&lt;/code&gt; environment variables as &lt;code class=&quot;highlighter-rouge&quot;&gt;false&lt;/code&gt;, to disable &lt;code class=&quot;highlighter-rouge&quot;&gt;X-Pack&lt;/code&gt;. Here also, we only need one instance of this service.&lt;/p&gt;

&lt;p&gt;Finally, at the end of the file, we have the &lt;code class=&quot;highlighter-rouge&quot;&gt;volumes&lt;/code&gt; key with the &lt;code class=&quot;highlighter-rouge&quot;&gt;esdata&lt;/code&gt; volumes. We are using the &lt;code class=&quot;highlighter-rouge&quot;&gt;local&lt;/code&gt; driver for this so the data will be stored in the host containing the service. As Elasticsearch service is placed in &lt;code class=&quot;highlighter-rouge&quot;&gt;agent1&lt;/code&gt;, the volume is always present there.&lt;/p&gt;

&lt;p&gt;To deploy this stack, save the above file as &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-stack.yml&lt;/code&gt; and run the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker stack deploy -c docker-stack.yml elk&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This will start the services in the stack named &lt;code class=&quot;highlighter-rouge&quot;&gt;elk&lt;/code&gt;. The first time takes more time as the nodes have to download the images. To see the services in the stack, you can use the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker stack services elk&lt;/code&gt;, the output of the command will look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;ID            NAME                   MODE        REPLICAS  IMAGE
07h9zishcka5  logging_logspout       global      3/3       bekt/logspout-logstash:latest
7upb3emlhsft  logging_kibana         replicated  1/1       docker.elastic.co/kibana/kibana:5.3.2
puxx0x4txa50  logging_logstash       replicated  1/1       docker.elastic.co/logstash/logstash:5.3.2
wyjkad4do7oi  logging_elasticsearch  replicated  1/1       docker.elastic.co/elasticsearch/elasticsearch:5.3.2&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can see the running containers in the stack with the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker stack ps elk&lt;/code&gt;. Its output will look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;ID            NAME                                        IMAGE                                                NODE     DESIRED STATE  CURRENT STATE               ERROR                      PORTS
jqr1m6ts21p3  logging_logspout.pt27y28y0t5zzph3oi72tmy58  bekt/logspout-logstash:latest                        agent2   Running        Running about a minute ago
4zwvtt3momu3  logging_logspout.9m6jopba7lr0o40hw9nwe7zfb  bekt/logspout-logstash:latest                        agent1   Running        Running about a minute ago
mgpsi68gcvd9  logging_logspout.ub1sl7d5fy9dbnlx8um67a03t  bekt/logspout-logstash:latest                        manager  Running        Running about a minute ago
unz9qrfit8li  logging_logstash.1                          logstash:alpine                                      agent1   Running        Running 2 minutes ago
jjin64lsw2dr  logging_kibana.1                            docker.elastic.co/kibana/kibana:5.3.0                agent2   Running        Running 2 minutes ago
orzfd05rzq8e  logging_elasticsearch.1                     docker.elastic.co/elasticsearch/elasticsearch:5.3.0  agent1   Running        Running 3 minutes ago&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;setup-kibana&quot;&gt;Setup Kibana&lt;/h2&gt;

&lt;p&gt;Once the services have started, you can open kibana with the following command:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;open http://&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;docker-machine ip manager&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/kibana-index@2x.jpg&quot; srcset=&quot;/assets/images/kibana-index@1x.jpg 300w, /assets/images/kibana-index@2x.jpg 600w, /assets/images/kibana-index@3x.jpg 900w&quot; sizes=&quot;(min-width: 960px) 900px, 100vw&quot; alt=&quot;Add default index pattern&quot; class=&quot;center-image&quot; /&gt;
&lt;em class=&quot;image-caption&quot;&gt;Add Default Index Pattern&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;It might take some time for kibana to load up. So, if the page doesn’t load up, wait for a few minutes and try again. The first time kibana is opened, it will ask to specify a default index pattern. Logstash will create index starting with &lt;code class=&quot;highlighter-rouge&quot;&gt;logstash-&lt;/code&gt;, so the default index pattern is &lt;code class=&quot;highlighter-rouge&quot;&gt;logstash-*&lt;/code&gt;. Also the Time-field name is &lt;code class=&quot;highlighter-rouge&quot;&gt;@timestamp&lt;/code&gt;. This is the field that stores the time when the log entry is made. Click on the &lt;code class=&quot;highlighter-rouge&quot;&gt;Create&lt;/code&gt; button to set it up. Now go to the &lt;code class=&quot;highlighter-rouge&quot;&gt;Discover&lt;/code&gt; tab to see all the log entries. To the left, you can see all the fields indentified from the logs. If you click on any field, you can see the top values and its percentages. The &lt;code class=&quot;highlighter-rouge&quot;&gt;docker.image&lt;/code&gt; field will give the docker image used, the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker.name&lt;/code&gt; field gives the container name, etc.&lt;/p&gt;

&lt;p&gt;To test this setup, we will deploy another stack and see its logs from here. For this we will use a simple stack containing a single service. It will be &lt;a href=&quot;https://www.nginx.com&quot;&gt;nginx&lt;/a&gt; webserver serving a static webpage. The image used for this is &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/nginx-html&lt;/code&gt; and we expose port &lt;code class=&quot;highlighter-rouge&quot;&gt;80&lt;/code&gt; of the container as port &lt;code class=&quot;highlighter-rouge&quot;&gt;8000&lt;/code&gt; in the host. Also, we deploy 5 instances of this service, just to see logs from different instances. The stack file for this stack &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx.yml&lt;/code&gt; is given below.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'3'&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;nginx&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;hanzel&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;nginx&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
      - &lt;span class=&quot;s2&quot;&gt;&quot;8000:80&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;deploy&lt;/span&gt;:
      &lt;span class=&quot;n&quot;&gt;replicas&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;5&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We will deploy this stack using the command,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker stack deploy -c nginx.yml nginx&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can see the services in the &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx&lt;/code&gt; stack with the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker stack services nginx&lt;/code&gt;. The output of the command will look something like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;ID            NAME         MODE        REPLICAS  IMAGE
dl8k8w2wief5  nginx_nginx  replicated  5/5       hanzel/nginx-html:latest&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can open up the nginx webserver with the following command&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;open http://&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;docker-machine ip manager:8000&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Refresh the page a few times to generate some log entries. Now you can see the logs in Kibana. Use the query &lt;code class=&quot;highlighter-rouge&quot;&gt;docker.image: nginx AND (200 OR 304)&lt;/code&gt; in Kibana. This filter will fetch the log entries where the docker image name contains &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx&lt;/code&gt; and the log message contains &lt;code class=&quot;highlighter-rouge&quot;&gt;200&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;304&lt;/code&gt;. If you look at the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker.image&lt;/code&gt; field on the left, you can see that we are reading logs from multiple containers across different hosts.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/kibana-nginx@2x.jpg&quot; srcset=&quot;/assets/images/kibana-nginx@1x.jpg 300w, /assets/images/kibana-nginx@2x.jpg 600w, /assets/images/kibana-nginx@3x.jpg 900w&quot; sizes=&quot;(min-width: 960px) 900px, 100vw&quot; alt=&quot;Kibana logs for nginx&quot; class=&quot;center-image&quot; /&gt;
&lt;em class=&quot;image-caption&quot;&gt;Kibana logs for nginx&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article, we have deployed a dynamic log management solution for our docker swarm. Once the stack is setup, logs are automatically collected from all the containers across all the hosts in the swarm. To do this, we have used popular open-source tools like Elasticsearch, Logstash, Kibana and Logspout.&lt;/p&gt;

&lt;p&gt;Once you are done with the demonstration, you can remove the stack with command,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker stack rm elk
docker stack rm nginx&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;If you are done with the VMs created for the demo, you can stop and remove then with the following commands,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-machine stop manager agent1 agent2
docker-machine rm -f manager agent1 agent2&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Sun, 30 Apr 2017 18:00:00 +0000</pubDate>
        <link>https://botleg.com/stories/log-management-of-docker-swarm-with-elk-stack/</link>
        <guid isPermaLink="true">https://botleg.com/stories/log-management-of-docker-swarm-with-elk-stack/</guid>
        
        <category>docker</category>
        
        <category>swarm</category>
        
        <category>log</category>
        
        <category>logging</category>
        
        <category>elk</category>
        
        <category>elasticsearch</category>
        
        <category>logstash</category>
        
        <category>kibana</category>
        
        <category>logspout</category>
        
        <category>elastic</category>
        
        <category>xpack</category>
        
        <category>docker-machine</category>
        
        <category>swarmmode</category>
        
        
        <category>devops</category>
        
      </item>
    
      <item>
        <title>Monitoring Docker Swarm with cAdvisor, InfluxDB and Grafana</title>
        <author><name>Hanzel Jesheen</name></author>
        <description>&lt;p&gt;Monitoring is essential to know the state of our running applications. When you are running your applications in a scalable environment like Docker Swarm, you need a scalable monitoring solution as well. In this article, we will setup just that.&lt;/p&gt;

&lt;p&gt;We will install &lt;a href=&quot;https://github.com/google/cadvisor&quot;&gt;cAdvisor&lt;/a&gt; agents in each nodes to collect host and container metrics. We will save these time-series metrics in &lt;a href=&quot;https://github.com/influxdata/influxdb&quot;&gt;InfluxDB&lt;/a&gt;. We will use &lt;a href=&quot;https://github.com/grafana/grafana&quot;&gt;Grafana&lt;/a&gt; to setup dashboards for this metrics. All these tools are open-source and can be deployed as a container.&lt;/p&gt;

&lt;p&gt;We will use the Docker Swarm Mode to build the cluster and deploy these services as a stack. This allows for a dynamic setup for monitoring. Once we deploy this stack in a swarm, any new nodes joining the swarm will be automatically monitored. All the files used for this project can be found &lt;a href=&quot;https://github.com/botleg/swarm-monitoring&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;tools-overview&quot;&gt;Tools Overview&lt;/h2&gt;

&lt;p&gt;There are plenty of options for monitoring solutions. We are using open-source and container friendly services to build our stack. Our stack comprises of the following services.&lt;/p&gt;

&lt;h1 id=&quot;cadvisor&quot;&gt;cAdvisor&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/google/cadvisor&quot;&gt;cAdvisor&lt;/a&gt; collects the metric from the host and docker containers. It is deployed as a docker image with shared volumes to docker socket and root file system of the host. cAdvisor pushed these metrics to a bunch of time-series database including InfluxDB, Prometheus, etc. It even has a web UI that shows graphs of the metrics collected.&lt;/p&gt;

&lt;h1 id=&quot;influxdb&quot;&gt;InfluxDB&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Scalable datastore for metrics, events, and real-time analytics&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/influxdata/influxdb&quot;&gt;InfluxDB&lt;/a&gt; is open source time series database. You can save numeric value metrics with tags. It supports a SQL like query language to query for data. The tags let us filter data for a specific host and even a spefic container.&lt;/p&gt;

&lt;h1 id=&quot;grafana&quot;&gt;Grafana&lt;/h1&gt;
&lt;blockquote&gt;
  &lt;p&gt;Grafana is an open source, feature rich metrics dashboard and graph editor for Graphite, Elasticsearch, OpenTSDB, Prometheus and InfluxDB.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/grafana/grafana&quot;&gt;Grafana&lt;/a&gt; is a popular graphing tool that lets you build dashboards with data from Graphite, Elasticsearch, OpenTSDB, Prometheus and, of course, InfluxDB. From version 4 of grafana, you can also setup alerts based on query conditions. We will setup dashboard that can be drilled down to specific host and service.&lt;/p&gt;

&lt;h2 id=&quot;docker-swarm-mode&quot;&gt;Docker Swarm Mode&lt;/h2&gt;

&lt;p&gt;Docker introduced &lt;code class=&quot;highlighter-rouge&quot;&gt;Swarm Mode&lt;/code&gt; from version 1.12.0. This allows us to easily create and manage swarm of multiple hosts. The swarm mode has the key-value store for service discovery and orchestration capability in-built. You can join hosts into a swarm as a manager or a worker. Generally, manager handles the orchestration part and workers are used to run the containers. Since this is for demostration, we will run InfluxDB and Grafana in the manager itself.&lt;/p&gt;

&lt;p&gt;Swarm Mode has an interesting feature called &lt;code class=&quot;highlighter-rouge&quot;&gt;router mesh&lt;/code&gt;. This acts as virtual load balancer. Let’s say that we have 10 containers running across 5 nodes and they listen to the port 80. Now, if you access the port 80 of any of the hosts. You will directed to any one of the 10 running instance, even the instances that are not even in that particular host. So you can publish the IP of any of the nodes and the requests will be automatically load balanced between all the 10 containers.&lt;/p&gt;

&lt;p&gt;To follow along with the demonstration, you need to have the following prerequisites:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker&lt;/code&gt;: version &amp;gt;= 17.10 CE, to support Docker Compose File version 3 and Swarm Mode.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Machine&lt;/code&gt;: version &amp;gt;= 0.12&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Compose&lt;/code&gt;: version &amp;gt;= 1.16, to support Docker Compose file version 3&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will be creating 3 local VMs to form the swarm using the &lt;code class=&quot;highlighter-rouge&quot;&gt;Virtualbox&lt;/code&gt; plugin of &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-machine&lt;/code&gt;. For this, you need to have &lt;a href=&quot;https://www.virtualbox.org/&quot;&gt;Virtualbox&lt;/a&gt; installed in the system. You may also deploy the nodes in cloud services using different plugins. The steps after creating in the VMs are same for all the plugins. You can read more about docker-machine &lt;a href=&quot;https://docs.docker.com/machine/get-started/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will using the default options to create the VMs. To know more about the options available, check &lt;a href=&quot;https://docs.docker.com/machine/drivers/virtualbox/&quot;&gt;here&lt;/a&gt;. We will create a host named &lt;code class=&quot;highlighter-rouge&quot;&gt;manager&lt;/code&gt; that acts as the manager for the swarm and two hosts &lt;code class=&quot;highlighter-rouge&quot;&gt;agent1&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;agent2&lt;/code&gt; to act as the workers. You may create as many nodes as you want. Just repeat the commands with the host names changed. To create the VMs, execute the follwing commands.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-machine create manager
docker-machine create agent1
docker-machine create agent2&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;These commands may take some time. After creating the VMS, the output for the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-machine ls&lt;/code&gt; should look something like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;NAME      ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER        ERRORS
agent1    -        virtualbox   Running   tcp://192.168.99.101:2376           v17.03.1-ce
agent2    -        virtualbox   Running   tcp://192.168.99.102:2376           v17.03.1-ce
manager   -        virtualbox   Running   tcp://192.168.99.100:2376           v17.03.1-ce          &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now you have to switch context to use the docker engine in the &lt;code class=&quot;highlighter-rouge&quot;&gt;manager&lt;/code&gt;. We will be doing the rest of the demostration in the docker engine of the &lt;code class=&quot;highlighter-rouge&quot;&gt;manager&lt;/code&gt; and NOT in our local system. To do this, run the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;docker-machine env manager&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We have now switched over to the docker engine in &lt;code class=&quot;highlighter-rouge&quot;&gt;manager&lt;/code&gt;. We will initialize the swarm with &lt;code class=&quot;highlighter-rouge&quot;&gt;manager&lt;/code&gt; acting as its manager. We have to mention the IP which will be published for other nodes to join the swarm. We will use the IP of &lt;code class=&quot;highlighter-rouge&quot;&gt;manager&lt;/code&gt; for this. The command, &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-machine ip manager&lt;/code&gt; will get you this. So, to create the swarm, run the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker swarm init --advertise-addr &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;docker-machine ip manager&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now, we need to add the two workers to this swarm. To do this, we need to pass a &lt;code class=&quot;highlighter-rouge&quot;&gt;Join Token&lt;/code&gt; and the IP published when the swarm was created. To get the token for joining the swarm as a worker, you can run the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker swarm join-token -q worker&lt;/code&gt;. As before, &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-machine ip manager&lt;/code&gt; will get the IP for joining and the default port for this is &lt;code class=&quot;highlighter-rouge&quot;&gt;2377&lt;/code&gt;. We could join the swarm by changing the context to each of the workers, but it is easier to run the commands as via SSH. To join workers to the swarm, run the following commands.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-machine ssh agent1 docker swarm join --token &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;docker swarm join-token -q worker&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;docker-machine ip manager&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;:2377
docker-machine ssh agent2 docker swarm join --token &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;docker swarm join-token -q worker&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;docker-machine ip manager&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;:2377&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can see the nodes in the swarm with the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker node ls&lt;/code&gt;. Once the workers are added the output of the command must look something like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
3j231njh03spl0j8h67z069cy &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt;  manager   Ready   Active        Leader
muxpteij6aldkixnl31f0asar    agent1    Ready   Active
y2gstaqpqix1exz09nyjn8z41    agent2    Ready   Active&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;docker-stack&quot;&gt;Docker Stack&lt;/h2&gt;

&lt;p&gt;With the version 3 of &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose&lt;/code&gt; file, we can define the entire stack with the deployment strategy with one file and deploy it with one command. The main difference between version 2 and 3 of docker-compose file is the introduction of the &lt;code class=&quot;highlighter-rouge&quot;&gt;deploy&lt;/code&gt; parameter for each service. This parameter will define where and how you want the containers to be deployed. The &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose&lt;/code&gt; file for the monitoring file is given below.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'3'&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;influx&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;influxdb&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;influx&lt;/span&gt;:/&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;influxdb&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;deploy&lt;/span&gt;:
      &lt;span class=&quot;n&quot;&gt;replicas&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;placement&lt;/span&gt;:
        &lt;span class=&quot;n&quot;&gt;constraints&lt;/span&gt;:
          - &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;role&lt;/span&gt; == &lt;span class=&quot;n&quot;&gt;manager&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;grafana&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;grafana&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;grafana&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
      - &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;:&lt;span class=&quot;m&quot;&gt;80&lt;/span&gt;:&lt;span class=&quot;m&quot;&gt;3000&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;grafana&lt;/span&gt;:/&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;grafana&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depends_on&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;influx&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;deploy&lt;/span&gt;:
      &lt;span class=&quot;n&quot;&gt;replicas&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;placement&lt;/span&gt;:
        &lt;span class=&quot;n&quot;&gt;constraints&lt;/span&gt;:
          - &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;.&lt;span class=&quot;n&quot;&gt;role&lt;/span&gt; == &lt;span class=&quot;n&quot;&gt;manager&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;cadvisor&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;google&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;cadvisor&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hostname&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'{{.Node.Hostname}}'&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;command&lt;/span&gt;: -&lt;span class=&quot;n&quot;&gt;logtostderr&lt;/span&gt; -&lt;span class=&quot;n&quot;&gt;docker_only&lt;/span&gt; -&lt;span class=&quot;n&quot;&gt;storage_driver&lt;/span&gt;=&lt;span class=&quot;n&quot;&gt;influxdb&lt;/span&gt; -&lt;span class=&quot;n&quot;&gt;storage_driver_db&lt;/span&gt;=&lt;span class=&quot;n&quot;&gt;cadvisor&lt;/span&gt; -&lt;span class=&quot;n&quot;&gt;storage_driver_host&lt;/span&gt;=&lt;span class=&quot;n&quot;&gt;influx&lt;/span&gt;:&lt;span class=&quot;m&quot;&gt;8086&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
      - /:/&lt;span class=&quot;n&quot;&gt;rootfs&lt;/span&gt;:&lt;span class=&quot;n&quot;&gt;ro&lt;/span&gt;
      - /&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;:/&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;run&lt;/span&gt;:&lt;span class=&quot;n&quot;&gt;rw&lt;/span&gt;
      - /&lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;:/&lt;span class=&quot;n&quot;&gt;sys&lt;/span&gt;:&lt;span class=&quot;n&quot;&gt;ro&lt;/span&gt;
      - /&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;/:/&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;:&lt;span class=&quot;n&quot;&gt;ro&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depends_on&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;influx&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;deploy&lt;/span&gt;:
      &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;global&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;influx&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;grafana&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We will start by saying that we are using the version 3 of &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose&lt;/code&gt; file. We have following 3 services in the stack.&lt;/p&gt;

&lt;h1 id=&quot;influx&quot;&gt;influx&lt;/h1&gt;

&lt;p&gt;This uses the &lt;code class=&quot;highlighter-rouge&quot;&gt;influxdb&lt;/code&gt; image and for persistent storage, we are creating a volume named &lt;code class=&quot;highlighter-rouge&quot;&gt;influx&lt;/code&gt; that is mounted to the &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/lib/influxdb&lt;/code&gt; folder in the container. In the deploy key, we are saying that we need one copy of InfluxDB which we will place in the &lt;code class=&quot;highlighter-rouge&quot;&gt;manager&lt;/code&gt;. Since we are using docker engine in the &lt;code class=&quot;highlighter-rouge&quot;&gt;manager&lt;/code&gt;, we can execute commands to this container from here itself. As both the other services needs influxDB to run, we will add a &lt;code class=&quot;highlighter-rouge&quot;&gt;depends_on&lt;/code&gt; key to other services with &lt;code class=&quot;highlighter-rouge&quot;&gt;influx&lt;/code&gt; in it.&lt;/p&gt;

&lt;h1 id=&quot;grafana-1&quot;&gt;grafana&lt;/h1&gt;

&lt;p&gt;We will use the image &lt;code class=&quot;highlighter-rouge&quot;&gt;grafana/grafana&lt;/code&gt; and expose the port &lt;code class=&quot;highlighter-rouge&quot;&gt;3000&lt;/code&gt; of the container to port &lt;code class=&quot;highlighter-rouge&quot;&gt;80&lt;/code&gt; of the host. The &lt;code class=&quot;highlighter-rouge&quot;&gt;router mesh&lt;/code&gt; feature will then let us access grafana from port 80 of any host in the swarm. We have another volume named &lt;code class=&quot;highlighter-rouge&quot;&gt;grafana&lt;/code&gt; mounted to &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/lib/grafana&lt;/code&gt; in the container for persistent data. As before, we also deploy one copy of grafana in the &lt;code class=&quot;highlighter-rouge&quot;&gt;manager&lt;/code&gt;.&lt;/p&gt;

&lt;h1 id=&quot;cadvisor-1&quot;&gt;cadvisor&lt;/h1&gt;

&lt;p&gt;cAdvisor service has much more configuration required than the other services. To know more, check &lt;a href=&quot;https://github.com/google/cadvisor&quot;&gt;this&lt;/a&gt; out. The hostname key is a tricky one. We intend to put one agent in each node of the swarm and this container will collect all metrics from the node and the containers running in it. When cAdvisor send metrics to InfluxDB, it send it with a tag &lt;code class=&quot;highlighter-rouge&quot;&gt;machine&lt;/code&gt; that contains the hostname of cAdvisor container. We need to match it with the hostname of the node running it. Docker stacks allows templating in naming. We have named the containers with the ID of the node running it so that we know where the metric is coming from. The is done by the value &lt;code class=&quot;highlighter-rouge&quot;&gt;'{{.Node.Hostname}}'&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We also add some command line parameters to cadvisor. The &lt;code class=&quot;highlighter-rouge&quot;&gt;logtostderr&lt;/code&gt; redirects the logs generated by cadvsior to &lt;code class=&quot;highlighter-rouge&quot;&gt;stderr&lt;/code&gt;, which makes it easy to debug. The &lt;code class=&quot;highlighter-rouge&quot;&gt;docker_only&lt;/code&gt; flag says that we are only interested in docker based containers. The next three parameters defines where you want metrics to be pushed for storage. We are asking cAdvisor to push the metrics to &lt;code class=&quot;highlighter-rouge&quot;&gt;cadvisor&lt;/code&gt; database in InfluxDB server listening at &lt;code class=&quot;highlighter-rouge&quot;&gt;influx:8086&lt;/code&gt;. This will send the metrics to the influx service in the stack. In a stack, all ports are exposed and you don’t have to specifically mention them.&lt;/p&gt;

&lt;p&gt;cAdvisor need the volumes mentioned in the file to collect the metrics from the host and docker system. We use the mode &lt;code class=&quot;highlighter-rouge&quot;&gt;global&lt;/code&gt; for deploy in cadvisor service. This will ensure that exactly one instance of cadvisor service will be run in each node of the swarm.&lt;/p&gt;

&lt;p&gt;Finally, at the end of the file, we have the &lt;code class=&quot;highlighter-rouge&quot;&gt;volumes&lt;/code&gt; key with the &lt;code class=&quot;highlighter-rouge&quot;&gt;influx&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;grafana&lt;/code&gt; volumes. As we are using the &lt;code class=&quot;highlighter-rouge&quot;&gt;local&lt;/code&gt; driver for both the volumes, the volumes will be stored in the &lt;code class=&quot;highlighter-rouge&quot;&gt;manager&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;To deploy this stack, save the above file as &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-stack.yml&lt;/code&gt; and run the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker stack deploy -c docker-stack.yml monitor&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This will start the services in the stack which is named &lt;code class=&quot;highlighter-rouge&quot;&gt;monitor&lt;/code&gt;. This might take some time the first time as the nodes have to download the images. Also, you need to create the database named &lt;code class=&quot;highlighter-rouge&quot;&gt;cadvisor&lt;/code&gt; in InfluxDB to store the metrics.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker &lt;span class=&quot;nb&quot;&gt;exec&lt;/span&gt; &lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;docker ps | grep -i influx | awk &lt;span class=&quot;s1&quot;&gt;'{print $1}'&lt;/span&gt;&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt; influx -execute &lt;span class=&quot;s1&quot;&gt;'CREATE DATABASE cadvisor'&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This command might fail saying that the &lt;code class=&quot;highlighter-rouge&quot;&gt;influx&lt;/code&gt; container doesn’t exist. This is beacuse the container is not yet ready. Wait for some time and run it again. We are able to run the commands in the &lt;code class=&quot;highlighter-rouge&quot;&gt;influx&lt;/code&gt; service beacuse it is running in &lt;code class=&quot;highlighter-rouge&quot;&gt;manager&lt;/code&gt; and we are using its docker engine. To find the ID of InfluxDB container, you can use the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker ps | grep -i influx | awk '{print $1}'&lt;/code&gt; and we are executing the command &lt;code class=&quot;highlighter-rouge&quot;&gt;influx -execute 'CREATE DATABASE cadvisor'&lt;/code&gt; to create the new database names &lt;code class=&quot;highlighter-rouge&quot;&gt;cadvisor&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;To see the services in the stack, you can use the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker stack services monitor&lt;/code&gt;, the output of the command will look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;ID            NAME              MODE        REPLICAS  IMAGE
0fru8w12pqdx  monitor_influx    replicated  1/1       influxdb:latest
m4r34h5ho984  monitor_grafana   replicated  1/1       grafana/grafana:latest
s1yeap330m7e  monitor_cadvisor  global      3/3       google/cadvisor:latest&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can see the running containers in the stack with the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker stack ps monitor&lt;/code&gt;. Its output will look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;ID            NAME                                        IMAGE                   NODE     DESIRED STATE  CURRENT STATE               ERROR  PORTS
n7kobaozqzj6  monitor_cadvisor.y78ac29r904m8uy6hxffb7uvn  google/cadvisor:latest  agent2   Running        Running about a minute ago
1nsispop3hsu  monitor_cadvisor.z52c9vloiutl5dbuj5lnykzvl  google/cadvisor:latest  agent1   Running        Running about a minute ago
9n6djc80mamd  monitor_cadvisor.qn82bfj5cpin2cpmx9qv1j56s  google/cadvisor:latest  manager  Running        Running about a minute ago
hyr8piriwa0x  monitor_grafana.1                           grafana/grafana:latest  manager  Running        Running about a minute ago
zk7u8g73ko5w  monitor_influx.1                            influxdb:latest         manager  Running        Running about a minute ago&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;setting-up-grafana&quot;&gt;Setting Up Grafana&lt;/h2&gt;

&lt;p&gt;Once the services are deployed, you can open up grafana with the IP of any node in the swarm. We will open the IP of manager with the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;open http://&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;docker-machine ip manager&lt;span class=&quot;sb&quot;&gt;`&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;By default, use the username &lt;code class=&quot;highlighter-rouge&quot;&gt;admin&lt;/code&gt; and password &lt;code class=&quot;highlighter-rouge&quot;&gt;admin&lt;/code&gt; to login to grafana. The first thing to do in grafana is to add InfluxDB as the datasource. In the home page, there must be a &lt;code class=&quot;highlighter-rouge&quot;&gt;Create your first data source&lt;/code&gt; link, click that. If the link is not visible, you can select &lt;code class=&quot;highlighter-rouge&quot;&gt;Data Sources&lt;/code&gt; from menu and choosing &lt;code class=&quot;highlighter-rouge&quot;&gt;Add data source&lt;/code&gt; from there. This will give you the form to add a new Data Source.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/grafana-datasource@2x.jpg&quot; srcset=&quot;/assets/images/grafana-datasource@1x.jpg 300w, /assets/images/grafana-datasource@2x.jpg 600w, /assets/images/grafana-datasource@3x.jpg 900w&quot; sizes=&quot;(min-width: 960px) 900px, 100vw&quot; alt=&quot;Add Data Source in Grafana&quot; class=&quot;center-image&quot; /&gt;
&lt;em class=&quot;image-caption&quot;&gt;Add Data Source in Grafana&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;You can give any name for the source. Check the default box, so that you won’t have to mention the data source everywhere. Choose the type as &lt;code class=&quot;highlighter-rouge&quot;&gt;InfluxDB&lt;/code&gt;. Now, the URL is &lt;code class=&quot;highlighter-rouge&quot;&gt;http://influx:8086&lt;/code&gt; and Access is &lt;code class=&quot;highlighter-rouge&quot;&gt;proxy&lt;/code&gt;. This will point to the port listened by the InfluxDb container. Finally give the Database as &lt;code class=&quot;highlighter-rouge&quot;&gt;cadvisor&lt;/code&gt; and click the &lt;code class=&quot;highlighter-rouge&quot;&gt;Save and Test&lt;/code&gt; button. This should give the message &lt;code class=&quot;highlighter-rouge&quot;&gt;Data source is working&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In the &lt;a href=&quot;https://github.com/botleg/swarm-monitoring&quot;&gt;github repository&lt;/a&gt;, I have added the file &lt;code class=&quot;highlighter-rouge&quot;&gt;dashboard.json&lt;/code&gt;, that can be imported to Grafana. This will provide a dashboard that monitors the systems and the containers running in the swarm. We will import the dashboard now and talk about it in the next section. From the menu, hover over &lt;code class=&quot;highlighter-rouge&quot;&gt;Dashboards&lt;/code&gt; and select &lt;code class=&quot;highlighter-rouge&quot;&gt;Import Option&lt;/code&gt;. Click the &lt;code class=&quot;highlighter-rouge&quot;&gt;Upload .json file&lt;/code&gt; button and choose the &lt;code class=&quot;highlighter-rouge&quot;&gt;dashboard.json&lt;/code&gt; file. Select the data source and click the &lt;code class=&quot;highlighter-rouge&quot;&gt;Import&lt;/code&gt; button to import this dashboard.&lt;/p&gt;

&lt;h2 id=&quot;grafana-dashboard&quot;&gt;Grafana Dashboard&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/grafana-dashboard@2x.jpg&quot; srcset=&quot;/assets/images/grafana-dashboard@1x.jpg 300w, /assets/images/grafana-dashboard@2x.jpg 600w, /assets/images/grafana-dashboard@3x.jpg 900w&quot; sizes=&quot;(min-width: 960px) 900px, 100vw&quot; alt=&quot;Grafana Dashboard&quot; class=&quot;center-image&quot; /&gt;
&lt;em class=&quot;image-caption&quot;&gt;Grafana Dashboard&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The dashboard imported to Grafana will monitor the host and containers in the swarm. You can drill down to host level and even to the container level in each host. To be able to do this, we are using two variables. To add variables to Grafana dashboard, we use the templating feature. To know more about templating with InfluxDB, check &lt;a href=&quot;http://docs.grafana.org/features/datasources/influxdb/#templating&quot;&gt;here&lt;/a&gt;. There are two varibles, &lt;code class=&quot;highlighter-rouge&quot;&gt;host&lt;/code&gt; to select the node and &lt;code class=&quot;highlighter-rouge&quot;&gt;container&lt;/code&gt; to select the container. To see the variables, select Settings from dashboard page and choose &lt;code class=&quot;highlighter-rouge&quot;&gt;Templating&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The first variable is &lt;code class=&quot;highlighter-rouge&quot;&gt;host&lt;/code&gt; and this provide the option to select the node and drill down to its metrics. When cAdvisor sends metrics to InfluxDB, it also includes some tags, which we will use to filter the metrics. There is a tag named &lt;code class=&quot;highlighter-rouge&quot;&gt;machine&lt;/code&gt; that shows the hostname of the cAdvisor instance. In this case, it will match the ID of the hosts in swarm. To get the values in the tag, we use &lt;code class=&quot;highlighter-rouge&quot;&gt;show tag values with key = &quot;machine&quot;&lt;/code&gt; as the query.&lt;/p&gt;

&lt;p&gt;The second variable is &lt;code class=&quot;highlighter-rouge&quot;&gt;container&lt;/code&gt; and this is to further drill down to the container level metrics. There is a tag named &lt;code class=&quot;highlighter-rouge&quot;&gt;container_name&lt;/code&gt; that contains the container name. We also need to only get the values based on the value of &lt;code class=&quot;highlighter-rouge&quot;&gt;host&lt;/code&gt; variables. So, the query is &lt;code class=&quot;highlighter-rouge&quot;&gt;show tag values with key = &quot;container_name&quot; WHERE machine =~ /^$host$/&lt;/code&gt;. This will fetch the containers which is running in the node selected by the &lt;code class=&quot;highlighter-rouge&quot;&gt;host&lt;/code&gt; variable.&lt;/p&gt;

&lt;p&gt;The container name will look something like this, &lt;code class=&quot;highlighter-rouge&quot;&gt;monitor_cadvisor.y78ac29r904m8uy6hxffb7uvn.3j231njh03spl0j8h67z069cy&lt;/code&gt;. However, we are only interested in &lt;code class=&quot;highlighter-rouge&quot;&gt;monitor_cadvisor&lt;/code&gt; part of it, till the first period. If there are multiple instance of the same service, we need seperate lines. To filter the portion until first period, we use &lt;code class=&quot;highlighter-rouge&quot;&gt;/([^.]+)/&lt;/code&gt; as the regex.&lt;/p&gt;

&lt;p&gt;Now that we have set up the varibles, we can use it in the graphs. We will discuss about &lt;code class=&quot;highlighter-rouge&quot;&gt;Memory&lt;/code&gt; graph and the rest are similar. The memory values is present in the &lt;code class=&quot;highlighter-rouge&quot;&gt;memory_usage&lt;/code&gt; series in InfluxDB, so the query starts with &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT &quot;value&quot; FROM &quot;memory_usage&quot;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now we add the filters with the &lt;code class=&quot;highlighter-rouge&quot;&gt;WHERE&lt;/code&gt; keyword. The first condition is that &lt;code class=&quot;highlighter-rouge&quot;&gt;machine&lt;/code&gt; is equal to &lt;code class=&quot;highlighter-rouge&quot;&gt;host&lt;/code&gt; variable. That is given by &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;machine&quot; =~ /^$host$/&lt;/code&gt;. The second condition is that &lt;code class=&quot;highlighter-rouge&quot;&gt;container_name&lt;/code&gt; starts with the &lt;code class=&quot;highlighter-rouge&quot;&gt;container&lt;/code&gt; variable. We use the &lt;code class=&quot;highlighter-rouge&quot;&gt;starts with&lt;/code&gt; operator here because we have filtered the &lt;code class=&quot;highlighter-rouge&quot;&gt;container&lt;/code&gt; variable until first period. This is given by &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;container_name&quot; =~ /^$container$*/&lt;/code&gt;. The final condition is to match the time interval selected in grafana dashboard, &lt;code class=&quot;highlighter-rouge&quot;&gt;$timeFilter&lt;/code&gt;. The query is now &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT &quot;value&quot; FROM &quot;memory_usage&quot; WHERE &quot;container_name&quot; =~ /^$container$*/ AND &quot;machine&quot; =~ /^$host$/ AND $timeFilter&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;As we need seperate lines for different hosts and container, you need to group the data based on the &lt;code class=&quot;highlighter-rouge&quot;&gt;machine&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;container_name&lt;/code&gt; tags. So now the entire query becomes, &lt;code class=&quot;highlighter-rouge&quot;&gt;SELECT &quot;value&quot; FROM &quot;memory_usage&quot; WHERE &quot;container_name&quot; =~ /^$container$*/ AND &quot;machine&quot; =~ /^$host$/ AND $timeFilter GROUP BY &quot;machine&quot;, &quot;container_name&quot;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We have also applied the alias for this query as &lt;code class=&quot;highlighter-rouge&quot;&gt;Memory {host: $tag_machine, container: $tag_container_name}&lt;/code&gt;. Here, &lt;code class=&quot;highlighter-rouge&quot;&gt;$tag_machine&lt;/code&gt; will be replaced by the value in &lt;code class=&quot;highlighter-rouge&quot;&gt;machine&lt;/code&gt; tag and &lt;code class=&quot;highlighter-rouge&quot;&gt;tag_container_name&lt;/code&gt; will be replaced by the value in &lt;code class=&quot;highlighter-rouge&quot;&gt;container_name&lt;/code&gt; tag. The rest of the graphs are similar. Only the series name changes. You can also create alerts for these metrics from inside Grafana. For more about Alerting, check &lt;a href=&quot;http://docs.grafana.org/alerting/rules/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article, we were able to set up scalable monitoring solution for Docker Swarm, that automatically monitors all hosts and containers running in the swarm. While doing this, we became familiar with popular open-source tools like Grafana, InfluxDB and cAdvisor.&lt;/p&gt;

&lt;p&gt;Once you are done with the demonstration, you can remove the stack with command,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker stack rm monitor&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;If you are done with the VMs created for the demo, you can stop and remove then with the following commands,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-machine stop manager agent1 agent2
docker-machine rm -f manager agent1 agent2&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Thu, 30 Mar 2017 18:00:00 +0000</pubDate>
        <link>https://botleg.com/stories/monitoring-docker-swarm-with-cadvisor-influxdb-and-grafana/</link>
        <guid isPermaLink="true">https://botleg.com/stories/monitoring-docker-swarm-with-cadvisor-influxdb-and-grafana/</guid>
        
        <category>docker</category>
        
        <category>swarm</category>
        
        <category>monitoring</category>
        
        <category>cadvisor</category>
        
        <category>influxdb</category>
        
        <category>grafana</category>
        
        <category>dashboard</category>
        
        <category>alerting</category>
        
        <category>docker-machine</category>
        
        <category>swarmmode</category>
        
        
        <category>devops</category>
        
      </item>
    
      <item>
        <title>Setup Gitlab for Docker based development</title>
        <author><name>Hanzel Jesheen</name></author>
        <description>&lt;p&gt;&lt;a href=&quot;https://about.gitlab.com/&quot;&gt;Gitlab&lt;/a&gt; is known as the open-source git repository manager. However, Gitlab does a lot more than that right now. It features a really powerful CI/CD engine and even packs a docker registry. It has become an essential part of my development process. In this article, we will discuss setting up Gitlab for docker based developments.&lt;/p&gt;

&lt;p&gt;We will start by setting up a VM in the cloud and installing Gitlab there. We will configure it to support HTTPS. We will also setup &lt;a href=&quot;https://about.gitlab.com/gitlab-ci/&quot;&gt;Gitlab CI&lt;/a&gt;, the Continuous integration solution that comes with Gitlab with multiple runners to run the builds in parallel. We will also setup the docker registry to store our docker images and secure it with HTTPs. Finally we will test this setup with docker based project.&lt;/p&gt;

&lt;p&gt;For the cloud VM, I’m using &lt;a href=&quot;https://www.digitalocean.com/&quot;&gt;Digital Ocean&lt;/a&gt;, but the process is similar for other vendors as well. We will use &lt;a href=&quot;https://letsencrypt.org/&quot;&gt;Let’s Encrypt&lt;/a&gt; for generating SSL certificates. To use this, you would also need a domain. The project used to test the gitlab setup is hosted &lt;a href=&quot;https://github.com/botleg/gitlab-nginx&quot;&gt;here&lt;/a&gt;. It is simple project that build a docker image with &lt;a href=&quot;https://www.nginx.com/&quot;&gt;nginx&lt;/a&gt; webserver.&lt;/p&gt;

&lt;h2 id=&quot;create-the-vm&quot;&gt;Create the VM&lt;/h2&gt;

&lt;p&gt;Create a VM using your cloud service, I am using Digital Ocean. You may also host Gitlab in your local system. I am choosing &lt;code class=&quot;highlighter-rouge&quot;&gt;Ubuntu 16.04 x64&lt;/code&gt; as the OS, but any linux distro will work fine. Also, since we are putting the entire setup in one VM, make it with atleast 8GB of RAM.&lt;/p&gt;

&lt;p&gt;We will register this Gitlab instance with a subdomain. Example: &lt;code class=&quot;highlighter-rouge&quot;&gt;gitlab.botleg.com&lt;/code&gt;. Once you have created your created your VM, create a new &lt;code class=&quot;highlighter-rouge&quot;&gt;A&lt;/code&gt; record in your DNS provider. The name will be subdomain name, &lt;code class=&quot;highlighter-rouge&quot;&gt;gitlab&lt;/code&gt; here and provide the public IP of the VM. SSH into the VM created and create a new user. Follow &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-16-04&quot;&gt;this&lt;/a&gt; tutorial to add this user and setup password-less access.&lt;/p&gt;

&lt;h2 id=&quot;installing-gitlab&quot;&gt;Installing Gitlab&lt;/h2&gt;

&lt;p&gt;We will be using the Community Edition of Gitlab. All the features that we need in our development process is supported in this edition. A comparison of the editions can be found &lt;a href=&quot;https://about.gitlab.com/products/#compare-options&quot;&gt;here&lt;/a&gt;. Easiest way to install Gitlab is to use the Omnibus package. It contains everything required for Gitlab in a single package with &lt;a href=&quot;https://www.chef.io/&quot;&gt;Chef&lt;/a&gt; recipes for the tasks.&lt;/p&gt;

&lt;p&gt;Just follow the steps in &lt;a href=&quot;https://about.gitlab.com/downloads/#ubuntu1604&quot;&gt;this&lt;/a&gt; site to install it. You just have to install some dependencies, add the new repository and install the &lt;code class=&quot;highlighter-rouge&quot;&gt;gitlab-ce&lt;/code&gt; package. The command &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo gitlab-ctl reconfigure&lt;/code&gt; triggers a chef receipe that reconfigures Gitlab based on the changes made to the configuration files.&lt;/p&gt;

&lt;p&gt;Once this is done, you will able to go to the domain setup in DNS service and see Gitlab login page. You will be asked to set password for the default admin account named &lt;code class=&quot;highlighter-rouge&quot;&gt;root&lt;/code&gt;. Set the admin password and login to Gitlab. Now, I recommend that you create a new admin user and use it for the next steps. This can be done from the Admin Area.&lt;/p&gt;

&lt;h2 id=&quot;enabling-https&quot;&gt;Enabling HTTPS&lt;/h2&gt;

&lt;p&gt;To enable HTTPS for Gitlab, we need to have a certificate generated for this domain. We will use &lt;code class=&quot;highlighter-rouge&quot;&gt;Let's Encrypt&lt;/code&gt; for this. To know more about this, visit &lt;a href=&quot;https://letsencrypt.org/getting-started/&quot;&gt;here&lt;/a&gt;. We will start by installing &lt;code class=&quot;highlighter-rouge&quot;&gt;Let's Encrypt&lt;/code&gt; with,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo apt-get install letsencrypt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To create the certificate, we need to verify that we indeed own the domain. To do this, &lt;code class=&quot;highlighter-rouge&quot;&gt;letencrypt&lt;/code&gt; tool provide a plugin &lt;code class=&quot;highlighter-rouge&quot;&gt;standalone&lt;/code&gt; that creates a temporary web server and verifies the domain. So, for this to work, we need to temporarily disable gitlab. To do this, use the following commands and enter the domain name and email when prompted&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo gitlab-ctl stop
sudo letsencrypt certonly --standalone --agree-tos
sudo gitlab-ctl start&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The certificates generated will be in the folder &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/letsencrypt/live/&amp;lt;domain name&amp;gt;/&lt;/code&gt;. The certificate file is &lt;code class=&quot;highlighter-rouge&quot;&gt;fullchain.pem&lt;/code&gt; and the key is &lt;code class=&quot;highlighter-rouge&quot;&gt;privkey.pem&lt;/code&gt;. We need to change this is in the Gitlab configurations. This file is located at &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/gitlab/gitlab.rb&lt;/code&gt;. This file is full of comments. We will make a backup of this file and clear it,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo cp /etc/gitlab/gitlab.rb /etc/gitlab/gitlab.rb.bak
sudo truncate -s 0 /etc/gitlab/gitlab.rb&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We need to add the following configuration items:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;external_url&lt;/code&gt;: The URL  where gitlab can be accessed. It will contain &lt;code class=&quot;highlighter-rouge&quot;&gt;https://&lt;/code&gt; followed by the domain name.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nginx['redirect_http_to_https']&lt;/code&gt;: We set it to &lt;code class=&quot;highlighter-rouge&quot;&gt;true&lt;/code&gt; to redirect all HTTP traffic to HTTPS.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nginx['ssl_certificate']&lt;/code&gt;: The location of the certificate file.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;nginx['ssl_certificate_key']&lt;/code&gt;: The location of the certificate key.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Open the file &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/gitlab/gitlab.rb&lt;/code&gt; as root and enter the following lines.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;external_url&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'https://&amp;lt;domain name&amp;gt;'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nginx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'redirect_http_to_https'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;true&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;nginx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'ssl_certificate'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/etc/letsencrypt/live/&amp;lt;domain name&amp;gt;/fullchain.pem&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;nginx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'ssl_certificate_key'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/etc/letsencrypt/live/&amp;lt;domain name&amp;gt;/privkey.pem&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Replace &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;domain name&amp;gt;&lt;/code&gt; with the domain name registered for Gitlab. Reconfigure Gitlab with new settings with the command,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo gitlab-ctl reconfigure&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now, when we go the Gitlab site, it will be in HTTPS with the &lt;code class=&quot;highlighter-rouge&quot;&gt;Let's Encrypt&lt;/code&gt; certificate.&lt;/p&gt;

&lt;h2 id=&quot;gitlab-ci-runners&quot;&gt;Gitlab CI Runners&lt;/h2&gt;

&lt;p&gt;In this step, we will setup the runners needed to run the builds for CI/CD. The runners will build, test and publish the projects as defined by the &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitlab-ci.yml&lt;/code&gt; file. We will discuss more about this later. Since we are doing docker based projects, we will use docker images for runners and use &lt;code class=&quot;highlighter-rouge&quot;&gt;Docker inside Docker&lt;/code&gt; for running our builds.&lt;/p&gt;

&lt;p&gt;The first step for this would be to actually install docker engine in this server,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl -sSL https://get.docker.com/ | sh
sudo usermod -aG docker &lt;span class=&quot;nv&quot;&gt;$USER&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The second command is to access docker without &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo&lt;/code&gt;. You might need to logout and login again to do this.Once we have the docker engine installed, we will run the &lt;a href=&quot;https://hub.docker.com/r/gitlab/gitlab-runner/&quot;&gt;Gitlab CI Multi Runner&lt;/a&gt; image. We will set the image to always restart if it goes down. With this implementation, we will share the docker engine in the server with the runner. For this, we will create a volume at the location, &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/run/docker.sock&lt;/code&gt;. To do all this, use the following command,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker run -d --name runner1 --restart always -v /var/run/docker.sock:/var/run/docker.sock gitlab/gitlab-runner:latest&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Here, &lt;code class=&quot;highlighter-rouge&quot;&gt;runner1&lt;/code&gt; is the name of this runner. You can run multiple runners to run the builds in parallel. To run more runners, run the previous command by changing the name &lt;code class=&quot;highlighter-rouge&quot;&gt;runner1&lt;/code&gt; to something else. Example: &lt;code class=&quot;highlighter-rouge&quot;&gt;docker run -d --name runner2 --restart always -v /var/run/docker.sock:/var/run/docker.sock gitlab/gitlab-runner:latest&lt;/code&gt;, and so on.&lt;/p&gt;

&lt;p&gt;To register these runners to Gitlab service, you need to have the registration token. You can find it in the &lt;code class=&quot;highlighter-rouge&quot;&gt;Runners&lt;/code&gt; section of the Admin Area. Once you find this, run the following command,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker &lt;span class=&quot;nb&quot;&gt;exec&lt;/span&gt; -it runner1 gitlab-runner register&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This command will ask the following things:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gitlab-ci coordinator URL&lt;/code&gt;: It is the domain name of the gitlab service with &lt;code class=&quot;highlighter-rouge&quot;&gt;https://&lt;/code&gt;, Example: &lt;code class=&quot;highlighter-rouge&quot;&gt;https://gitlab.botleg.com&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gitlab-ci token&lt;/code&gt;: Enter the registration token that we got from Gitlab site.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;description&lt;/code&gt;: Give a name from this runner. Example: &lt;code class=&quot;highlighter-rouge&quot;&gt;runner1&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;tags&lt;/code&gt;: Give some tags to target this runner. Gitlab provide the option to run the tests on runner with certain tags.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;run untagged builds&lt;/code&gt;: Boolean value that tell whether this runner can accept jobs without tags. Since we have only one type of runners here, we can provide &lt;code class=&quot;highlighter-rouge&quot;&gt;true&lt;/code&gt; for this.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;executor&lt;/code&gt;: How the jobs are executed by the runner. Here, we choose &lt;code class=&quot;highlighter-rouge&quot;&gt;docker&lt;/code&gt;. To more about the other executors, check &lt;a href=&quot;https://gitlab.com/gitlab-org/gitlab-ci-multi-runner/blob/master/docs/executors/README.md&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;default Docker image&lt;/code&gt;: The docker image to run the tests in. We will user &lt;code class=&quot;highlighter-rouge&quot;&gt;docker:git&lt;/code&gt; for this. This image allows for &lt;code class=&quot;highlighter-rouge&quot;&gt;docker in docker&lt;/code&gt; and also has git inbuilt.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Repeat this command for all your runners by changing the runner name. Example: &lt;code class=&quot;highlighter-rouge&quot;&gt;docker exec -it runner2 gitlab-runner register&lt;/code&gt;. After you do this, you will be able to see these runners in the &lt;code class=&quot;highlighter-rouge&quot;&gt;Runners&lt;/code&gt; section of Gitlab’s Admin Area.&lt;/p&gt;

&lt;p&gt;There is however one more step we need to do. We are sharing the docker engine in the server to the runners. These runners will create &lt;code class=&quot;highlighter-rouge&quot;&gt;docker:git&lt;/code&gt; image to run the jobs. These jobs build and push docker images. We will use the docker engine from the server to do this. So, we need to make a docker volume of &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/run/docker.sock&lt;/code&gt; for the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker:git&lt;/code&gt; images created by the runners to share the docker engine. To do this, we need to modify the configuration of each runner. Run the following command to open up the configuration file of the runner.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker &lt;span class=&quot;nb&quot;&gt;exec&lt;/span&gt; -it runner1 nano /etc/gitlab-runner/config.toml&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Edit the line &lt;code class=&quot;highlighter-rouge&quot;&gt;volumes = [&quot;/cache&quot;]&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;volumes = [&quot;/cache&quot;, &quot;/var/run/docker.sock:/var/run/docker.sock&quot;]&lt;/code&gt;. The file will look something like this:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-toml&quot; data-lang=&quot;toml&quot;&gt;&lt;span class=&quot;py&quot;&gt;concurrent&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;py&quot;&gt;check_interval&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;nn&quot;&gt;[[runners]]&lt;/span&gt;
  &lt;span class=&quot;py&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;runner1&quot;&lt;/span&gt;
  &lt;span class=&quot;py&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;https://gitlab.botleg.com&quot;&lt;/span&gt;
  &lt;span class=&quot;py&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;9ab32be14c9d2cb67fbec7aa59304f&quot;&lt;/span&gt;
  &lt;span class=&quot;py&quot;&gt;executor&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;docker&quot;&lt;/span&gt;
  &lt;span class=&quot;nn&quot;&gt;[runners.docker]&lt;/span&gt;
    &lt;span class=&quot;py&quot;&gt;tls_verify&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
    &lt;span class=&quot;py&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;docker:git&quot;&lt;/span&gt;
    &lt;span class=&quot;py&quot;&gt;privileged&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
    &lt;span class=&quot;py&quot;&gt;disable_cache&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
    &lt;span class=&quot;py&quot;&gt;volumes&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/cache&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;/var/run/docker.sock:/var/run/docker.sock&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;nn&quot;&gt;[runners.cache]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Repeat this step for other runners as well.&lt;/p&gt;

&lt;h2 id=&quot;container-registry&quot;&gt;Container Registry&lt;/h2&gt;

&lt;p&gt;The final thing we need to setup is the &lt;a href=&quot;https://docs.gitlab.com/ce/user/project/container_registry.html&quot;&gt;Container Registry&lt;/a&gt;. We will create a new sub-domain for registry, like &lt;code class=&quot;highlighter-rouge&quot;&gt;registry.botleg.com&lt;/code&gt; and secure it using HTTPS. So, first thing would be to create a new &lt;code class=&quot;highlighter-rouge&quot;&gt;A&lt;/code&gt; record with the DNS service. In this case, the name will be &lt;code class=&quot;highlighter-rouge&quot;&gt;registry&lt;/code&gt; and give the public IP of the VM. Now, our server has &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx&lt;/code&gt; webserver. If the request is for &lt;code class=&quot;highlighter-rouge&quot;&gt;gitlab&lt;/code&gt; subdomain, it will redirect to gitlab and if the request is for &lt;code class=&quot;highlighter-rouge&quot;&gt;registry&lt;/code&gt;, it will redirect to registry.&lt;/p&gt;

&lt;p&gt;We also need to create new SSL certificate for this &lt;code class=&quot;highlighter-rouge&quot;&gt;registry&lt;/code&gt; sub-domain. As before, we use Let’s Encrypt for this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo gitlab-ctl stop
sudo letsencrypt certonly --standalone --agree-tos
sudo gitlab-ctl start&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Provide the domain for the registry when prompted. This will create the new SSL certificates, which can be found in the &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/letsencrypt/live&lt;/code&gt; folder. Update the gitlab configuration file &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/gitlab/gitlab.rb&lt;/code&gt; to add the following lines.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;registry_external_url&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'https://&amp;lt;domain name&amp;gt;'&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;registry_nginx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'ssl_certificate'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/etc/letsencrypt/live/&amp;lt;domain name&amp;gt;/fullchain.pem&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;registry_nginx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'ssl_certificate_key'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/etc/letsencrypt/live/&amp;lt;domain name&amp;gt;/privkey.pem&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Replace &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;domain name&amp;gt;&lt;/code&gt; with the domain registered for the registry. This will enable registry with HTTPS enabled. To update the changes, use the &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo gitlab-ctl reconfigure&lt;/code&gt; command. In the Admin area you can see that the Container Registry is enabled. To test this out, try logging into the registry.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;login&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;registry&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Replace &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;registry domain&amp;gt;&lt;/code&gt; with the domain registered for the registry and provide the Gitlab username and password. You can see the &lt;code class=&quot;highlighter-rouge&quot;&gt;Login Succeeded&lt;/code&gt; message.&lt;/p&gt;

&lt;h2 id=&quot;testing-setup&quot;&gt;Testing Setup&lt;/h2&gt;

&lt;p&gt;We have now setup the Gitlab for the docker based development. To test this implementation, we will push a git repository to Gitlab and see the working of Gitlab CI and Container Registry. I have made a simple docker based project which can be found &lt;a href=&quot;https://github.com/botleg/gitlab-nginx&quot;&gt;here&lt;/a&gt;. This just contains a &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; that installs &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx&lt;/code&gt; websever, which serves the &lt;code class=&quot;highlighter-rouge&quot;&gt;index.html&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;The file that we are interested about is &lt;code class=&quot;highlighter-rouge&quot;&gt;.gitlab-ci.yml&lt;/code&gt;. This contains all the information on how to build and deploy this project. To know more about this file, check &lt;a href=&quot;https://docs.gitlab.com/ce/ci/yaml/&quot;&gt;here&lt;/a&gt;. The file for this project looks like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;ss&quot;&gt;image: &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:git&lt;/span&gt;

&lt;span class=&quot;ss&quot;&gt;stages:
&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;

&lt;span class=&quot;ss&quot;&gt;build:
  stage: &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;
  &lt;span class=&quot;ss&quot;&gt;script:
    &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;vg&quot;&gt;$REGISTRY_HOST&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;vg&quot;&gt;$IMAGE_NAME&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;registry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;ss&quot;&gt;stage: &lt;/span&gt;&lt;span class=&quot;n&quot;&gt;publish&lt;/span&gt;
  &lt;span class=&quot;ss&quot;&gt;script:
    &lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;login&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gitlab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ci&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;vg&quot;&gt;$CI_BUILD_TOKEN&lt;/span&gt; &lt;span class=&quot;vg&quot;&gt;$REGISTRY_HOST&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;docker&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;push&lt;/span&gt; &lt;span class=&quot;vg&quot;&gt;$REGISTRY_HOST&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;vg&quot;&gt;$IMAGE_NAME&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Since the job is docker based, we will specify the image to run this test on. The image, &lt;code class=&quot;highlighter-rouge&quot;&gt;docker:git&lt;/code&gt; contains &lt;code class=&quot;highlighter-rouge&quot;&gt;docker&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;git&lt;/code&gt; inside. We can split the entire process into multiple stages and each stage contains multiple jobs. Each job is a stage will be done in parallel and each stage will be triggered only if all jobs in the previous stage is successful.&lt;/p&gt;

&lt;p&gt;Here, we have two stages, &lt;code class=&quot;highlighter-rouge&quot;&gt;build&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;publish&lt;/code&gt;. The job &lt;code class=&quot;highlighter-rouge&quot;&gt;build&lt;/code&gt; is in the &lt;code class=&quot;highlighter-rouge&quot;&gt;build&lt;/code&gt; stage and job &lt;code class=&quot;highlighter-rouge&quot;&gt;registry&lt;/code&gt; in the &lt;code class=&quot;highlighter-rouge&quot;&gt;publish&lt;/code&gt; stage. So, &lt;code class=&quot;highlighter-rouge&quot;&gt;registry&lt;/code&gt; job will be done only if the &lt;code class=&quot;highlighter-rouge&quot;&gt;build&lt;/code&gt; job is successful. The &lt;code class=&quot;highlighter-rouge&quot;&gt;build&lt;/code&gt; job contains a bash command to build the docker image. We can use variables in this script by prepending it with &lt;code class=&quot;highlighter-rouge&quot;&gt;$&lt;/code&gt;. The values for this variables can be given from the Gitlab UI. The image name will be &lt;code class=&quot;highlighter-rouge&quot;&gt;$REGISTRY_HOST/$IMAGE_NAME&lt;/code&gt;. Here, &lt;code class=&quot;highlighter-rouge&quot;&gt;$REGISTRY_HOST&lt;/code&gt; is the registry domain name and &lt;code class=&quot;highlighter-rouge&quot;&gt;$IMAGE_NAME&lt;/code&gt; will be the repository name.&lt;/p&gt;

&lt;p&gt;In the &lt;code class=&quot;highlighter-rouge&quot;&gt;registry&lt;/code&gt; job, we push this image to the container registry. To do this, we have to login to the registry. Gitlab has a temporary user named &lt;code class=&quot;highlighter-rouge&quot;&gt;gitlab-ci-token&lt;/code&gt; with password in the variable &lt;code class=&quot;highlighter-rouge&quot;&gt;$CI_BUILD_TOKEN&lt;/code&gt; for this purpose. Once with login to the registry at &lt;code class=&quot;highlighter-rouge&quot;&gt;$REGISTRY_HOST&lt;/code&gt;, we can push the docker image.&lt;/p&gt;

&lt;p&gt;To test this out, create a new public project in Gitlab by importing from Github. In the settings, choose &lt;code class=&quot;highlighter-rouge&quot;&gt;Variables&lt;/code&gt; and add the following two variables.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;REGISTRY_HOST&lt;/code&gt;: The domain registered for container registry. Example: &lt;code class=&quot;highlighter-rouge&quot;&gt;registry.botleg.com&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;IMAGE_NAME&lt;/code&gt;: The repository name for the project. Example: &lt;code class=&quot;highlighter-rouge&quot;&gt;botleg/gitlab-nginx&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once the repository is imported, goto the &lt;code class=&quot;highlighter-rouge&quot;&gt;Pipelines&lt;/code&gt; tab and click the &lt;code class=&quot;highlighter-rouge&quot;&gt;Run Pipeline&lt;/code&gt; button to trigger the build. You can see the jobs running and image being pushed to the registry. Once the build pipeline is complete, you can see the docker image in the &lt;code class=&quot;highlighter-rouge&quot;&gt;Registry&lt;/code&gt; section of the project.&lt;/p&gt;

&lt;h2 id=&quot;certificate-renewal&quot;&gt;Certificate Renewal&lt;/h2&gt;

&lt;p&gt;The certificates generated by Let’s Encrypt will get expired in 90 days. So, we have to automate the renewal of these certificates. Let’s Encrypt provide a command &lt;code class=&quot;highlighter-rouge&quot;&gt;letsencrypt renew&lt;/code&gt; to do just this. This command will check if the certificates are about to be expired and do the renewal for those. For the renewal to happen, we need to stop the Gitlab service temporarily.&lt;/p&gt;

&lt;p&gt;The following commands will do the renewal of the certificates,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;gitlab-ctl stop
letsencrypt renew
gitlab-ctl start
gitlab-ctl reconfigure&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We need to add this as a cron job for the &lt;code class=&quot;highlighter-rouge&quot;&gt;root&lt;/code&gt; user. Open the crontab for &lt;code class=&quot;highlighter-rouge&quot;&gt;root&lt;/code&gt; user with the command &lt;code class=&quot;highlighter-rouge&quot;&gt;sudo crontab -e&lt;/code&gt; and paste the following line.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-cron&quot; data-lang=&quot;cron&quot;&gt;0 7 1 * * (gitlab-ctl stop &amp;amp;&amp;amp; letsencrypt renew &amp;amp;&amp;amp; gitlab-ctl start &amp;amp;&amp;amp; gitlab-ctl reconfigure) &amp;gt;&amp;gt; /var/log/report.log 2&amp;gt;&amp;amp;1&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This will cause this task to run at 7am on the 1st of every month and log the output to the file &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/log/report.log&lt;/code&gt;. Now, we have completely setup Gitlab for the docker based development and also tested it with a git repo.&lt;/p&gt;
</description>
        <pubDate>Wed, 01 Feb 2017 18:00:00 +0000</pubDate>
        <link>https://botleg.com/stories/setup-gitlab-for-docker-based-development/</link>
        <guid isPermaLink="true">https://botleg.com/stories/setup-gitlab-for-docker-based-development/</guid>
        
        <category>gitlab</category>
        
        <category>docker</category>
        
        <category>nginx</category>
        
        <category>digitalocean</category>
        
        <category>bash</category>
        
        <category>Dockerfile</category>
        
        <category>CI</category>
        
        <category>letsencrypt</category>
        
        <category>https</category>
        
        <category>ssl</category>
        
        <category>registry</category>
        
        <category>runner</category>
        
        
        <category>cloud</category>
        
      </item>
    
      <item>
        <title>Auto Scaling with Docker</title>
        <author><name>Hanzel Jesheen</name></author>
        <description>&lt;p&gt;In the article &lt;a href=&quot;/stories/load-balancing-with-docker-swarm/&quot;&gt;Load Balancing with Docker Swarm&lt;/a&gt;, we scaled a service by deploying multiple instance of the same docker image across the hosts in a Docker Swarm and distibuted the traffic among these instances using a load balancer. However, the scaling is manually done using &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose&lt;/code&gt; commands.&lt;/p&gt;

&lt;p&gt;In this article, we are going to automate the scaling procedure using &lt;a href=&quot;https://docs.docker.com/engine/reference/api/docker_remote_api/&quot;&gt;Docker Remote API&lt;/a&gt;. We will be creating a &lt;code class=&quot;highlighter-rouge&quot;&gt;Replicator&lt;/code&gt; docker image that listens to requests with container ID as the parameter and can create and deploy new docker images similar to the one with the given container ID.&lt;/p&gt;

&lt;p&gt;The docker image for Replicator is &lt;a href=&quot;https://hub.docker.com/r/hanzel/replicator/&quot;&gt;hanzel/replicator&lt;/a&gt; and its code can be found &lt;a href=&quot;https://github.com/botleg/replicator&quot;&gt;here&lt;/a&gt;. Also, the docker image for testing this is &lt;a href=&quot;https://hub.docker.com/r/hanzel/node-replicate/&quot;&gt;hanzel/node-replicate&lt;/a&gt; and its code can be found &lt;a href=&quot;https://github.com/botleg/node-replicate&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;docker-remote-api&quot;&gt;Docker Remote API&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://docs.docker.com/engine/reference/api/docker_remote_api/&quot;&gt;Docker Remote API&lt;/a&gt; allows us to remotely access the Docker Engine and do all the actions that we could do locally. You can see the API reference &lt;a href=&quot;https://docs.docker.com/engine/reference/api/docker_remote_api_v1.23/&quot;&gt;here&lt;/a&gt;. For our purposes, we need the following endpoints:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GET /containers/&amp;lt;id&amp;gt;/json&lt;/code&gt;: To inspect the container.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;POST /containers/create&lt;/code&gt;: To create a new container.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;POST /containers/&amp;lt;id&amp;gt;/start&lt;/code&gt;: To deploy the new container.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To send requests to the Docker Remote API, we need to verify the client using the certificate (cert.pem) and the private key (key.pem) files. To verify the client, we also need the certificate authority (ca.pem) file. When using Docker Machine, the environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_CERT_PATH&lt;/code&gt; contains the path of the folder containing these files.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;Replicator&lt;/code&gt; docker image will listen for requests which contains a container ID. This ID is used to inspect the container and create one similar to it. Then the newly created container is deployed. Now we can scale by sending a request to this Replicator image with the container ID. This can be done in two ways:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A running container can request the Replicator with its own container ID, if it cannot handle the traffic.&lt;/li&gt;
  &lt;li&gt;The container can send metrics to some monitoring service along with its container ID. Then the monitoring service can send the request to the Replicator with the container ID as needed.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;replicator-image&quot;&gt;Replicator Image&lt;/h2&gt;

&lt;p&gt;The Replicator image will be based on the &lt;a href=&quot;https://www.alpinelinux.org/&quot;&gt;Alpine Linux&lt;/a&gt; and it will contain a &lt;a href=&quot;https://nodejs.org/&quot;&gt;Node.js&lt;/a&gt; server along with &lt;a href=&quot;https://www.nginx.com/&quot;&gt;NGINX&lt;/a&gt;. Node.js server will be used to listen for the request and communicate with Docker Remote API. NGINX is used as a reverse proxy to the Node.js server and it also handle the client verification with the certificates. The docker image for Replicator is &lt;a href=&quot;https://hub.docker.com/r/hanzel/replicator/&quot;&gt;hanzel/replicator&lt;/a&gt; and its code can be found &lt;a href=&quot;https://github.com/botleg/replicator&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We need the certificate and key file to access the Remote API. So, we use these same files to authenticate the clients of our Docker Image. We need to have the file &lt;code class=&quot;highlighter-rouge&quot;&gt;cert.pem&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;key.pem&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;ca.pem&lt;/code&gt; in the folder &lt;code class=&quot;highlighter-rouge&quot;&gt;/ssl&lt;/code&gt; in our Docker Image. We will discuss how to get the files there later when we are testing this image. We also need to set the &lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_HOST&lt;/code&gt; environment variable with IP and port to access the Remote API. The Docker Machine save this in the format &lt;code class=&quot;highlighter-rouge&quot;&gt;tcp://&amp;lt;ip&amp;gt;:&amp;lt;port&amp;gt;&lt;/code&gt; inside the environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_HOST&lt;/code&gt;. We just have to pass this value to the docker image. In the next three sections, we will build the Replicator image.&lt;/p&gt;

&lt;h2 id=&quot;nodejs-application&quot;&gt;Node.js Application&lt;/h2&gt;

&lt;p&gt;The Node.js application will contain only one javascript file &lt;code class=&quot;highlighter-rouge&quot;&gt;server.js&lt;/code&gt; and uses &lt;a href=&quot;http://koajs.com/&quot;&gt;koa&lt;/a&gt; as the web server and &lt;code class=&quot;highlighter-rouge&quot;&gt;co-request&lt;/code&gt; to send requests to Docker Remote API. So the &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file will look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;name&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;replicator&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;main&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;server.js&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;scripts&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;start&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;node server.js&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;dependencies&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;co-request&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1.0.0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;koa&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1.2.0&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;server.js&lt;/code&gt; files starts with setting values to the variables.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;kr&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;app&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'koa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(),&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;fs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'fs'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;request&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'co-request'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;kr&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;cert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;readFileSync&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/ssl/cert.pem'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;readFileSync&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/ssl/key.pem'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;ca&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;readFileSync&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/ssl/ca.pem'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;host&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;DOCKER_HOST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We assiged the &lt;code class=&quot;highlighter-rouge&quot;&gt;koa&lt;/code&gt; module to &lt;code class=&quot;highlighter-rouge&quot;&gt;app&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;fs&lt;/code&gt; module to &lt;code class=&quot;highlighter-rouge&quot;&gt;fs&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;co-request&lt;/code&gt; module to &lt;code class=&quot;highlighter-rouge&quot;&gt;request&lt;/code&gt;. The file &lt;code class=&quot;highlighter-rouge&quot;&gt;/ssl/cert.pem&lt;/code&gt; is read and saved to &lt;code class=&quot;highlighter-rouge&quot;&gt;cert&lt;/code&gt;. Similarly, value of &lt;code class=&quot;highlighter-rouge&quot;&gt;key&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;ca&lt;/code&gt; is set. We have the IP and port to access the Remote API in the environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_HOST&lt;/code&gt; in the format &lt;code class=&quot;highlighter-rouge&quot;&gt;tcp://&amp;lt;ip&amp;gt;:&amp;lt;port&amp;gt;&lt;/code&gt;. We strip out the &lt;code class=&quot;highlighter-rouge&quot;&gt;tcp://&lt;/code&gt; part of it and save it to &lt;code class=&quot;highlighter-rouge&quot;&gt;host&lt;/code&gt; variable. So, if the value of the environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_HOST&lt;/code&gt; is &lt;code class=&quot;highlighter-rouge&quot;&gt;tcp://192.168.99.100:2376&lt;/code&gt;, the value of &lt;code class=&quot;highlighter-rouge&quot;&gt;host&lt;/code&gt; will be &lt;code class=&quot;highlighter-rouge&quot;&gt;192.168.99.100:2376&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now we have to write the function that handles all the requests. We accept GET request with container ID as the URL parameter. So the request &lt;code class=&quot;highlighter-rouge&quot;&gt;GET /9d65f58cca99&lt;/code&gt; will be accepted and the container ID is &lt;code class=&quot;highlighter-rouge&quot;&gt;9d65f58cca99&lt;/code&gt;. The function looks like the following.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;nx&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;use&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!==&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'/'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;    
    &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;container&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;slice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'https://'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/containers/'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/json'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;cert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;cert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;ca&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ca&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;statusCode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'https://'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/containers/create'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;json&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Hostname&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;HostConfig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;HostConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'https://'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/containers/'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/start'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

      &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'done'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;404&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'invalid container id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'container id missing'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;First of all, we check if there is any URL parameter. If there is no parameter, we send a &lt;code class=&quot;highlighter-rouge&quot;&gt;400 BAD REQUEST&lt;/code&gt; response. Or else, we take the container ID from the URL, save it in &lt;code class=&quot;highlighter-rouge&quot;&gt;container&lt;/code&gt; variable and continue. We send a &lt;code class=&quot;highlighter-rouge&quot;&gt;GET /containers/&amp;lt;id&amp;gt;/json&lt;/code&gt; request to the Docker Remote API to get the configuration of the given image using the &lt;code class=&quot;highlighter-rouge&quot;&gt;cert&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;key&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;ca&lt;/code&gt; variables for authentication. The URL for this is &lt;code class=&quot;highlighter-rouge&quot;&gt;'https://'+host+'/containers/'+container+'/json'&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;If the response code for this request is not 200, we send a &lt;code class=&quot;highlighter-rouge&quot;&gt;404 NOT FOUND&lt;/code&gt; response. This happens when the container ID is invalid. If the response code is 200, we continue. Now, we have to send a &lt;code class=&quot;highlighter-rouge&quot;&gt;POST /containers/create&lt;/code&gt; request. The body of this request must contain the configuration of the Docker Image that we wish to create. As we are going to duplicate the image, whose ID was given, this can be obtained from the reponse of the previous request. The body of this request is composed of the &lt;code class=&quot;highlighter-rouge&quot;&gt;Config&lt;/code&gt; object of the previous response.&lt;/p&gt;

&lt;p&gt;Now we need to empty the value of &lt;code class=&quot;highlighter-rouge&quot;&gt;Hostname&lt;/code&gt; parameter in the body. This is done so that the newly created image will have a unique hostname which is the substring of its ID. Now we have to set the &lt;code class=&quot;highlighter-rouge&quot;&gt;HostConfig&lt;/code&gt; parameter in the request body. This is be obtained from the &lt;code class=&quot;highlighter-rouge&quot;&gt;HostConfig&lt;/code&gt; object in the previous reponse. Now we send this &lt;code class=&quot;highlighter-rouge&quot;&gt;POST /containers/create&lt;/code&gt; request and the new container is created. The response from this request will contain the ID of the new container in the &lt;code class=&quot;highlighter-rouge&quot;&gt;Id&lt;/code&gt; parameter.&lt;/p&gt;

&lt;p&gt;Now we send the &lt;code class=&quot;highlighter-rouge&quot;&gt;POST /containers/&amp;lt;id&amp;gt;/start&lt;/code&gt; request to start this newly created container. The ID for this reqeust can be obtained from the previous response, so the URL will be &lt;code class=&quot;highlighter-rouge&quot;&gt;'https://'+host+'/containers/'+init.body.Id+'/start'&lt;/code&gt;. This will start the new container and we can now send the &lt;code class=&quot;highlighter-rouge&quot;&gt;200 OK&lt;/code&gt; response with &lt;code class=&quot;highlighter-rouge&quot;&gt;done&lt;/code&gt; as the body.&lt;/p&gt;

&lt;p&gt;Finally, we need to make this app listen to the port &lt;code class=&quot;highlighter-rouge&quot;&gt;3000&lt;/code&gt; using the command, &lt;code class=&quot;highlighter-rouge&quot;&gt;app.listen(3000)&lt;/code&gt;. So the entire &lt;code class=&quot;highlighter-rouge&quot;&gt;server.js&lt;/code&gt; file looks like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-javascript&quot; data-lang=&quot;javascript&quot;&gt;&lt;span class=&quot;kr&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;app&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'koa'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)(),&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;fs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'fs'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;request&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;require&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'co-request'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;kr&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;cert&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;readFileSync&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/ssl/cert.pem'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;readFileSync&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/ssl/key.pem'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;ca&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;readFileSync&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/ssl/ca.pem'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;nx&quot;&gt;host&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;DOCKER_HOST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;substr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;use&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;function&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(){&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!==&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'/'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;    
    &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;container&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;slice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'https://'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/containers/'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/json'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;cert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;cert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
      &lt;span class=&quot;na&quot;&gt;ca&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;ca&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

    &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;info&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;statusCode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'https://'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/containers/create'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;json&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Config&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Hostname&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;HostConfig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;JSON&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;parse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;info&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;HostConfig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'https://'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;host&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/containers/'&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;Id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'/start'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;yield&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;request&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;options&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

      &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'done'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;404&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'invalid container id'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; 
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;status&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;body&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'container id missing'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

&lt;span class=&quot;nx&quot;&gt;app&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;listen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;nginx-configuration&quot;&gt;NGINX Configuration&lt;/h2&gt;

&lt;p&gt;We are using NGINX as the reverse proxy to our Node.js Application. NGINX is also used for SSL termination and client authentication. The encrypted requests will be received by the NGINX server, the SSL will be terminated and the plain-text requests will be forwarded to our Node.js server running at port &lt;code class=&quot;highlighter-rouge&quot;&gt;3000&lt;/code&gt;. The configuration file &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx.conf&lt;/code&gt; look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-nginx&quot; data-lang=&quot;nginx&quot;&gt;&lt;span class=&quot;k&quot;&gt;worker_processes&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;pid&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/var/run/nginx.pid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;events&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;worker_connections&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;http&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;listen&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;443&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ssl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;kn&quot;&gt;ssl_certificate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/ssl/cert.pem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;ssl_certificate_key&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/ssl/key.pem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;ssl_client_certificate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/ssl/ca.pem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;ssl_verify_client&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;kn&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;kn&quot;&gt;add_header&lt;/span&gt;          &lt;span class=&quot;s&quot;&gt;Access-Control-Allow-Origin&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kn&quot;&gt;add_header&lt;/span&gt;          &lt;span class=&quot;s&quot;&gt;Access-Control-Allow-Methods&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;GET&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kn&quot;&gt;proxy_pass&lt;/span&gt;          &lt;span class=&quot;s&quot;&gt;http://127.0.0.1:3000/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kn&quot;&gt;proxy_set_header&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;X-Real-IP&lt;/span&gt;         &lt;span class=&quot;nv&quot;&gt;$remote_addr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kn&quot;&gt;proxy_set_header&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;X-Forwarded-For&lt;/span&gt;   &lt;span class=&quot;nv&quot;&gt;$proxy_add_x_forwarded_for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kn&quot;&gt;proxy_set_header&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;X_FORWARDED_PROTO&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kn&quot;&gt;proxy_set_header&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;Host&lt;/span&gt;              &lt;span class=&quot;nv&quot;&gt;$http_host&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kn&quot;&gt;proxy_buffering&lt;/span&gt;     &lt;span class=&quot;no&quot;&gt;off&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;kn&quot;&gt;proxy_redirect&lt;/span&gt;      &lt;span class=&quot;no&quot;&gt;off&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;NGINX listens to port 443 with SSL turned on. As, port 443 is the default port for SSL, we can now access this service with &lt;code class=&quot;highlighter-rouge&quot;&gt;https&lt;/code&gt; without any ports. We authenticate the clients using the files &lt;code class=&quot;highlighter-rouge&quot;&gt;cert.pem&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;key.pem&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;ca.pem&lt;/code&gt; in the &lt;code class=&quot;highlighter-rouge&quot;&gt;/ssl&lt;/code&gt; folder. We use the &lt;code class=&quot;highlighter-rouge&quot;&gt;proxy_pass&lt;/code&gt; parameter to pass these requests to the Node.js server listening at port &lt;code class=&quot;highlighter-rouge&quot;&gt;3000&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;replicator-dockerfile&quot;&gt;Replicator Dockerfile&lt;/h2&gt;

&lt;p&gt;We need to have both Node.js and NGINX to be running inside the docker image. So we will write a script &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt; which acts as our entry point.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/sh&lt;/span&gt;

nginx -g &lt;span class=&quot;s1&quot;&gt;'daemon off;'&lt;/span&gt; &amp;amp;
npm start&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Our Docker Image will be based on Alpine Linux with Node.js server and NGINX running in it. We need to put the four files &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;server.js&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx.conf&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt; into a folder named &lt;code class=&quot;highlighter-rouge&quot;&gt;files&lt;/code&gt;. Create the &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; in the folder containing this &lt;code class=&quot;highlighter-rouge&quot;&gt;files&lt;/code&gt; folder and it will contain the following.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-c&quot; data-lang=&quot;c&quot;&gt;&lt;span class=&quot;n&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mhart&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alpine&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;RUN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;apk&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;add&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;no&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nginx&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ADD&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;package&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;js&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;WORKDIR&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;code&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;RUN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;npm&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ADD&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nginx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;etc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nginx&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ADD&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;files&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;RUN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;chmod&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sh&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;EXPOSE&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;443&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ENTRYPOINT&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/bin/start.sh&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The base image is &lt;code class=&quot;highlighter-rouge&quot;&gt;mhart/alpine-node:6&lt;/code&gt;, which is based on Alpine Linux and contains Node.js v6. We install nginx using Alpine Pacakge Manager, &lt;code class=&quot;highlighter-rouge&quot;&gt;apk&lt;/code&gt;. We move the files &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;server.js&lt;/code&gt; to the folder &lt;code class=&quot;highlighter-rouge&quot;&gt;/code&lt;/code&gt; in the image and it will act as the working directory. We run &lt;code class=&quot;highlighter-rouge&quot;&gt;npm install&lt;/code&gt; in this location to install all Node.js dependencies from &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Next, we move the file &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx.conf&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/nginx&lt;/code&gt; folder and &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;/bin&lt;/code&gt; folder. We make the &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt; executable with &lt;code class=&quot;highlighter-rouge&quot;&gt;chmod&lt;/code&gt; command. The port &lt;code class=&quot;highlighter-rouge&quot;&gt;443&lt;/code&gt; will be exposed and accessible from outside. This port is listened by NGINX. Finally, we set the &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt; file as the entry point to this image. You can build this image with the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker build -t replicator .&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;testing&quot;&gt;Testing&lt;/h2&gt;

&lt;p&gt;To send requests to the replicator from inside a running container, the replicator must run in the same network. If the container name of the replicator image is &lt;code class=&quot;highlighter-rouge&quot;&gt;replicator&lt;/code&gt;, we can send request to &lt;code class=&quot;highlighter-rouge&quot;&gt;https://replicator&lt;/code&gt;. We also need to provide the container ID as the URL parameter. This value can be accessed from the environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;HOSTNAME&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For authentication of this request, we need to provide the certificate file (cert.pem) and its private key (key.pem). If &lt;code class=&quot;highlighter-rouge&quot;&gt;curl&lt;/code&gt; is installed in the image and the authentication files are in &lt;code class=&quot;highlighter-rouge&quot;&gt;/ssl&lt;/code&gt; folder, we can make this request using the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl --insecure --cert /ssl/cert.pem --key /ssl/key.pem &lt;span class=&quot;s2&quot;&gt;&quot;https://replicator/&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$HOSTNAME&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To test the working of this replicator image, I have made a docker image. This docker image contains a Node.js server that server an HTML page with a button. If the button is clicked, the above &lt;code class=&quot;highlighter-rouge&quot;&gt;curl&lt;/code&gt; command is executed. I have built it into a docker image, &lt;a href=&quot;https://hub.docker.com/r/hanzel/node-replicate/&quot;&gt;hanzel/node-replicate&lt;/a&gt; and its code can be found &lt;a href=&quot;https://github.com/botleg/node-replicate&quot;&gt;here&lt;/a&gt;. With this image, we can see that everytime we click the button a new instance of this service will be spun up. We will be deploying all this to a Docker Swarm now.&lt;/p&gt;

&lt;h2 id=&quot;creating-the-swarm&quot;&gt;Creating the Swarm&lt;/h2&gt;

&lt;p&gt;We will be using &lt;a href=&quot;https://docs.docker.com/machine/&quot;&gt;Docker Machine&lt;/a&gt; to create and manage remote hosts as a swarm. With Docker Machine, you can create hosts on your local machine or your cloud provider. Check &lt;a href=&quot;https://docs.docker.com/machine/drivers/&quot;&gt;this link&lt;/a&gt; to see the drivers supported by Docker Machine.&lt;/p&gt;

&lt;p&gt;You need to have the following installed in you local computer:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker&lt;/code&gt;: version &amp;gt;= 1.10, to support Docker Compose File version 2 and Multi-Host networking.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Machine&lt;/code&gt;: version &amp;gt;= 0.6&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Compose&lt;/code&gt;: version &amp;gt;= 1.6, to support Docker Compose file version 2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can create the virtual hosts in you local system if you have &lt;a href=&quot;https://www.virtualbox.org/wiki/Downloads&quot;&gt;VirtualBox&lt;/a&gt; installed. For this demonstration, I will be using &lt;a href=&quot;https://www.digitalocean.com/&quot;&gt;DigitalOcean&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The first thing we need to do is to create the Docker Swarm using Docker Machine and set it up. I have explained how to do this in the article, &lt;a href=&quot;/stories/load-balancing-with-docker-swarm/&quot;&gt;Load Balancing with Docker Swarm&lt;/a&gt;. Follow the steps from &lt;code class=&quot;highlighter-rouge&quot;&gt;Initial Setup&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;The Swarm&lt;/code&gt; of that article to create and setup the Swarm.&lt;/p&gt;

&lt;p&gt;Once the swarm is setup, you can see the hosts with &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-machine ls&lt;/code&gt; command. The output of this command must look something like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;NAME     ACTIVE      DRIVER         STATE     URL                          SWARM             DOCKER
consul   -           digitalocean   Running   tcp://104.131.23.60:2376                       v1.11.2
master   &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;swarm&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   digitalocean   Running   tcp://104.131.109.181:2376   master &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;master&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   v1.11.2
slave    -           digitalocean   Running   tcp://45.55.243.156:2376     master            v1.11.2 &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;key-distribution&quot;&gt;Key Distribution&lt;/h2&gt;

&lt;p&gt;For the replicator image to access the Docker Remote API, it needs the certificate file (cert.pem), private key (key.pem) and certificate authority file (ca.pem). As we are using Docker Machine, the value in the environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_CERT_PATH&lt;/code&gt; is the path of the folder containing these files. We are also going to use these same files to authenticate requests coming to the replicator. So we need to have these three files in the &lt;code class=&quot;highlighter-rouge&quot;&gt;replicator&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;node-replicate&lt;/code&gt; image.&lt;/p&gt;

&lt;p&gt;Before moving the files to the Docker images, we need to get the files to all the remote hosts that we create with Docker Machine. We create a new folder name &lt;code class=&quot;highlighter-rouge&quot;&gt;ssl&lt;/code&gt; and copy the required three file to this folder.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;mkdir ssl
cp &lt;span class=&quot;nv&quot;&gt;$DOCKER_CERT_PATH&lt;/span&gt;/cert.pem &lt;span class=&quot;nv&quot;&gt;$DOCKER_CERT_PATH&lt;/span&gt;/key.pem &lt;span class=&quot;nv&quot;&gt;$DOCKER_CERT_PATH&lt;/span&gt;/ca.pem ssl/&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We now use &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-machine scp&lt;/code&gt; command to copy the contents of &lt;code class=&quot;highlighter-rouge&quot;&gt;ssl&lt;/code&gt; folder to &lt;code class=&quot;highlighter-rouge&quot;&gt;/home/ssl&lt;/code&gt; folder in the remote hosts &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;slave&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-machine scp -r ssl master:/home/ssl
docker-machine scp -r ssl slave:/home/ssl&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;If you have more remote hosts, just repeat these commands by changing the host name. Once these files are in the remote hosts, you can create volumes that point from &lt;code class=&quot;highlighter-rouge&quot;&gt;/home/ssl&lt;/code&gt; in the host to &lt;code class=&quot;highlighter-rouge&quot;&gt;/ssl&lt;/code&gt; in the container, to bring these files into the containers.&lt;/p&gt;

&lt;h2 id=&quot;running-with-docker-compose&quot;&gt;Running with Docker Compose&lt;/h2&gt;

&lt;p&gt;We will test the working of the replicator using Docker Compose. The configuration file &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; looks like the following.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'2'&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;overlay&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;replicator&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;hanzel&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;replicator&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;container_name&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;replicator&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
      - &lt;span class=&quot;s2&quot;&gt;&quot;443:443&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;constraint&lt;/span&gt;:&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;==&lt;span class=&quot;n&quot;&gt;slave&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;DOCKER_HOST&lt;/span&gt;=${&lt;span class=&quot;n&quot;&gt;DOCKER_HOST&lt;/span&gt;}
    &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
      - /&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;ssl&lt;/span&gt;:/&lt;span class=&quot;n&quot;&gt;ssl&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;lb&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;hanzel&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;balancing&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;swarm&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;container_name&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;lb&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
      - &lt;span class=&quot;s2&quot;&gt;&quot;80:80&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;constraint&lt;/span&gt;:&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;==&lt;span class=&quot;n&quot;&gt;master&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;APP_NAME&lt;/span&gt;=&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;replicate&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;CONSUL_URL&lt;/span&gt;=${&lt;span class=&quot;n&quot;&gt;KV_IP&lt;/span&gt;}:&lt;span class=&quot;m&quot;&gt;8500&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depends_on&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;hanzel&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;replicate&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
      - &lt;span class=&quot;s2&quot;&gt;&quot;3000&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
      - /&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;ssl&lt;/span&gt;:/&lt;span class=&quot;n&quot;&gt;ssl&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We have an overlay network &lt;code class=&quot;highlighter-rouge&quot;&gt;web&lt;/code&gt; that contains all the services. The first service is the &lt;code class=&quot;highlighter-rouge&quot;&gt;replicator&lt;/code&gt; and uses &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/replicator&lt;/code&gt; image. We give the name &lt;code class=&quot;highlighter-rouge&quot;&gt;replicator&lt;/code&gt; for this container and export the port &lt;code class=&quot;highlighter-rouge&quot;&gt;443&lt;/code&gt;. This make the replicator accessible at &lt;code class=&quot;highlighter-rouge&quot;&gt;https://replicator&lt;/code&gt;. We set the &lt;code class=&quot;highlighter-rouge&quot;&gt;constraint:node&lt;/code&gt; environment variable to &lt;code class=&quot;highlighter-rouge&quot;&gt;slave&lt;/code&gt; so that this container always runs in the &lt;code class=&quot;highlighter-rouge&quot;&gt;slave&lt;/code&gt; remote host. As discussed above, we need to set the &lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_HOST&lt;/code&gt; environment variable to the URL to access the Remote API. This is set in the &lt;code class=&quot;highlighter-rouge&quot;&gt;DOCKER_HOST&lt;/code&gt; environment variable set by the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-machine&lt;/code&gt;. We also need to create a Docker Volume from &lt;code class=&quot;highlighter-rouge&quot;&gt;/home/ssl&lt;/code&gt; in the host to &lt;code class=&quot;highlighter-rouge&quot;&gt;/ssl&lt;/code&gt; in the container to share the certificates and keys.&lt;/p&gt;

&lt;p&gt;The second service is a load balancer which can distibuted the traffic to different instances of the same image. To know more about this service, read my article &lt;a href=&quot;/stories/load-balancing-with-docker-swarm/&quot;&gt;Load Balancing with Docker Swarm&lt;/a&gt;. The third service is named &lt;code class=&quot;highlighter-rouge&quot;&gt;web&lt;/code&gt; and contains the image &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/node-replicate&lt;/code&gt; that was created to test the replicator. It listens to port &lt;code class=&quot;highlighter-rouge&quot;&gt;3000&lt;/code&gt;, so it is exposed. As this service make requests to the replicator, it need the same certificates and keys for authentication. This is done by creating a docker volume similar to &lt;code class=&quot;highlighter-rouge&quot;&gt;replicator&lt;/code&gt; service.&lt;/p&gt;

&lt;p&gt;Make sure that your docker client is connected to the swarm with &lt;code class=&quot;highlighter-rouge&quot;&gt;eval $(docker-machine env -swarm master)&lt;/code&gt; command. Now open up the terminal in the folder containing &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; and start the services using the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-compose up -d&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This will start these services. You can see the running containers with the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose ps&lt;/code&gt;. The output of the command must look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;Name         Command         State   Ports           
------------------------------------------------------------------------
lb           /bin/start.sh   Up      443/tcp, 104.131.109.181:80-&amp;gt;80/tcp
replicator   /bin/start.sh   Up      104.131.109.181:443-&amp;gt;443/tcp
tmp_web_1    npm start       Up      45.55.243.156:32772-&amp;gt;3000/tcp&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can see the application from the url given by the command, &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose port lb 80&lt;/code&gt;. You will get some IP address like &lt;code class=&quot;highlighter-rouge&quot;&gt;104.131.109.181:80&lt;/code&gt;. Go to this url and we can see the running app. To test the &lt;code class=&quot;highlighter-rouge&quot;&gt;replicator&lt;/code&gt;, click on the &lt;code class=&quot;highlighter-rouge&quot;&gt;Replicate&lt;/code&gt; button. This sends a request to replicator with the current container’s ID and the replicator will create a new service similar to this and deploy it. Once all that is done, the text &lt;code class=&quot;highlighter-rouge&quot;&gt;done&lt;/code&gt; appears in the webpage.&lt;/p&gt;

&lt;p&gt;Check again the running services with &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose ps&lt;/code&gt; command and we can see two instances of our &lt;code class=&quot;highlighter-rouge&quot;&gt;node-replicate&lt;/code&gt; images running.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;Name                Command         State   Ports           
------------------------------------------------------------------------
lb                  /bin/start.sh   Up      443/tcp, 104.131.109.181:80-&amp;gt;80/tcp
replicator          /bin/start.sh   Up      104.131.109.181:443-&amp;gt;443/tcp
reverent_dubinsky   npm start       Up      45.55.243.156:32773-&amp;gt;3000/tcp
tmp_web_1           npm start       Up      45.55.243.156:32772-&amp;gt;3000/tcp&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Here, the container named &lt;code class=&quot;highlighter-rouge&quot;&gt;reverent_dubinsky&lt;/code&gt; in the new one replicated. Everytime we press the button, a new instance will be deployed. You can also send the request to replicator externally. You need to have the certificate and key file in the &lt;code class=&quot;highlighter-rouge&quot;&gt;ssl&lt;/code&gt; folder. Run the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker ps&lt;/code&gt; to get the list of running container. Pick the required container and note its ID. Now run the following command to replicate this container.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl --insecure --cert ssl/cert.pem --key ssl/key.pem &lt;span class=&quot;s2&quot;&gt;&quot;https://&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;docker-machine ip slave&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/&amp;lt;container-id&amp;gt;&quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Example: If the container ID is 'd44f756ca3a1'&lt;/span&gt;
curl --insecure --cert ssl/cert.pem --key ssl/key.pem &lt;span class=&quot;s2&quot;&gt;&quot;https://&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;docker-machine ip slave&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;/d44f756ca3a1&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Run this command or press the button a few times and the output of &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose ps&lt;/code&gt; will look something like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;Name                Command         State                  Ports
-------------------------------------------------------------------------------
drunk_borg          npm start       Up      104.131.109.181:32770-&amp;gt;3000/tcp
hungry_banach       npm start       Up      104.131.109.181:32769-&amp;gt;3000/tcp
kickass_hoover      npm start       Up      45.55.243.156:32775-&amp;gt;3000/tcp
lb                  /bin/start.sh   Up      443/tcp, 104.131.109.181:80-&amp;gt;80/tcp
replicator          /bin/start.sh   Up      104.131.109.181:443-&amp;gt;443/tcp
reverent_dubinsky   npm start       Up      45.55.243.156:32773-&amp;gt;3000/tcp
sleepy_williams     npm start       Up      45.55.243.156:32774-&amp;gt;3000/tcp
tmp_web_1           npm start       Up      45.55.243.156:32772-&amp;gt;3000/tcp &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can still use the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose scale&lt;/code&gt; command to manually scale the services. Also, you can see that the load balancer is also updated with the new instances. You can see the load balancer configuration with the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker exec -t lb cat /etc/nginx/conf.d/default.conf&lt;/code&gt;. Its output looks something like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-nginx&quot; data-lang=&quot;nginx&quot;&gt;&lt;span class=&quot;k&quot;&gt;upstream&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;node-replicate&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;least_conn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.11.48&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32770&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.11.48&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32769&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.69.218&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32775&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.69.218&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32773&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.69.218&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32774&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.69.218&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32772&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;listen&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;80&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;proxy_pass&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;http://node-replicate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article, we can set up an auto-scaling system with Docker using Docker Remote API. This can be used to scale the service as the traffic increases. We have made a docker image to that replicates services and tested it on an app deployed with Docker Swarm.&lt;/p&gt;

&lt;p&gt;Once you are done, the services can be stopped and the hosts removed with the following commands.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-compose down
docker-machine stop consul master slave
docker-machine rm consul master slave&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Wed, 13 Jul 2016 18:00:00 +0000</pubDate>
        <link>https://botleg.com/stories/auto-scaling-with-docker/</link>
        <guid isPermaLink="true">https://botleg.com/stories/auto-scaling-with-docker/</guid>
        
        <category>auto-scaling</category>
        
        <category>replicator</category>
        
        <category>remote</category>
        
        <category>API</category>
        
        <category>docker</category>
        
        <category>machine</category>
        
        <category>swarm</category>
        
        <category>registrator</category>
        
        <category>nginx</category>
        
        <category>digitalocean</category>
        
        <category>compose</category>
        
        <category>machine</category>
        
        <category>bash</category>
        
        <category>Dockerfile</category>
        
        <category>Node.js</category>
        
        <category>nginx</category>
        
        
        <category>devops</category>
        
      </item>
    
      <item>
        <title>Building Blue-Green Deployment with Docker</title>
        <author><name>Hanzel Jesheen</name></author>
        <description>&lt;p&gt;Blue-Green Deployment is a strategy to release new version of the app without downtime. The basic idea behind this technique involves using two identical production environments, named &lt;code class=&quot;highlighter-rouge&quot;&gt;Blue&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Green&lt;/code&gt;. At any time, only one of these environment is live and serving the production traffic. The other one is used to test newer version or for roll-back.&lt;/p&gt;

&lt;p&gt;Let us assume that the current live production environment is Blue. When the new version is ready, we can deploy it to the non-production environment - Green. None of our users can see this new version as the live environment is still Blue. We can test the new version from the Green environment now. If this version is ready for release, we switch the production environment to Green and the users can now see the new release. Now the live version in at Green and staging can be done in Blue. If there is some error with the new release in Green, it is easy to roll-back to previous version by just switching the production environment back to Blue. Only thing to note here is that the switching is seamless.&lt;/p&gt;

&lt;p&gt;In this article, we will build a blue-green deployment system with Dockers. We will create and control a cluster of nodes with Docker Swarm. We will build a Blue-Green deployment docker image that creates two environment, each running different versions of same test app. We will also see how to switch the live environment with out Docker image.&lt;/p&gt;

&lt;p&gt;The docker image for Blue-Green deployment is &lt;a href=&quot;https://hub.docker.com/r/hanzel/blue-green/&quot;&gt;hanzel/blue-green&lt;/a&gt; and its code can be found &lt;a href=&quot;https://github.com/botleg/blue-green&quot;&gt;here&lt;/a&gt;. Also, the docker image for the test application is &lt;a href=&quot;https://hub.docker.com/r/hanzel/nginx-html/&quot;&gt;hanzel/nginx-html&lt;/a&gt; and its code can be found &lt;a href=&quot;https://github.com/botleg/nginx-html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h2&gt;

&lt;p&gt;We will be using &lt;a href=&quot;https://docs.docker.com/machine/&quot;&gt;Docker Machine&lt;/a&gt; to create and manage remote hosts as a swarm. With Docker Machine, you can create hosts on your local machine or your cloud provider. Check &lt;a href=&quot;https://docs.docker.com/machine/drivers/&quot;&gt;this link&lt;/a&gt; to see the drivers supported by Docker Machine.&lt;/p&gt;

&lt;p&gt;You need to have the following installed in you local computer:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker&lt;/code&gt;: version &amp;gt;= 1.10, to support Docker Compose File version 2 and Multi-Host networking.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Machine&lt;/code&gt;: version &amp;gt;= 0.6&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Compose&lt;/code&gt;: version &amp;gt;= 1.6, to support Docker Compose file version 2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can create the virtual hosts in you local system if you have &lt;a href=&quot;https://www.virtualbox.org/wiki/Downloads&quot;&gt;VirtualBox&lt;/a&gt; installed. For this demonstration, I will be using &lt;a href=&quot;https://www.digitalocean.com/&quot;&gt;DigitalOcean&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;creating-the-swarm&quot;&gt;Creating the Swarm&lt;/h2&gt;

&lt;p&gt;The first thing we need to do is to create the Docker Swarm using Docker Machine and set it up. I have explained how to do this in my previous article, &lt;a href=&quot;/stories/load-balancing-with-docker-swarm/&quot;&gt;Load Balancing with Docker Swarm&lt;/a&gt;. Follow the steps from &lt;code class=&quot;highlighter-rouge&quot;&gt;Initial Setup&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;The Swarm&lt;/code&gt; of that article to create and setup the Swarm.&lt;/p&gt;

&lt;p&gt;Once the swarm is setup, you can see the hosts with &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-machine ls&lt;/code&gt; command. The output of this command must look something like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;NAME     ACTIVE      DRIVER         STATE     URL                          SWARM             DOCKER
consul   -           digitalocean   Running   tcp://104.236.235.185:2376                     v1.10.1
master   &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;swarm&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   digitalocean   Running   tcp://159.203.119.37:2376    master &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;master&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   v1.10.1
slave    -           digitalocean   Running   tcp://45.55.185.18:2376      master            v1.10.1 &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;test-app&quot;&gt;Test App&lt;/h2&gt;

&lt;p&gt;To demonstrate blue-green deployment, we will deploy different versions of our test app. The docker image for this app is &lt;a href=&quot;https://hub.docker.com/r/hanzel/nginx-html/&quot;&gt;hanzel/nginx-html&lt;/a&gt; and the code for it can be found &lt;a href=&quot;https://github.com/botleg/nginx-html&quot;&gt;here&lt;/a&gt;. The docker image contains the &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx&lt;/code&gt; webserver that serves a static HTML page at port &lt;code class=&quot;highlighter-rouge&quot;&gt;80&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The HTML page contains the current version or tag of the docker image. So the image &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/nginx-html:1&lt;/code&gt; serves the HTML page with &lt;code class=&quot;highlighter-rouge&quot;&gt;Version 1&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/nginx-html:2&lt;/code&gt; serves the HTML page with &lt;code class=&quot;highlighter-rouge&quot;&gt;Version 2&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/nginx-html:3&lt;/code&gt; serves the HTML page with &lt;code class=&quot;highlighter-rouge&quot;&gt;Version 3&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;consul-template&quot;&gt;Consul Template&lt;/h2&gt;

&lt;p&gt;Now, we are going to build the image that does the blue-green deployment. It uses &lt;a href=&quot;https://www.nginx.com/&quot;&gt;nginx&lt;/a&gt; webserver for load balancing and &lt;a href=&quot;https://github.com/hashicorp/consul-template&quot;&gt;consul-template&lt;/a&gt; to manage nginx configuration dynamically. The docker image for this app is &lt;a href=&quot;https://hub.docker.com/r/hanzel/blue-green/&quot;&gt;hanzel/blue-green&lt;/a&gt; and the code for it can be found &lt;a href=&quot;https://github.com/botleg/blue-green&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;If the current live environment is &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;, we can access that at port 80 of the container. The staging environment, &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt; in this case, can be accessed from the port 8080 of the container. We will be able to switch the live environment anytime with just one command. If we switch the live environment to &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;, then we can access the live &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt; environment at port 80 and staging &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; environment at port 8080. This is how the image facilitates blue-green deployment.&lt;/p&gt;

&lt;p&gt;We have used the &lt;code class=&quot;highlighter-rouge&quot;&gt;registrator&lt;/code&gt; image to register our running docker images to &lt;code class=&quot;highlighter-rouge&quot;&gt;consul&lt;/code&gt;. Now, &lt;code class=&quot;highlighter-rouge&quot;&gt;consul-template&lt;/code&gt; will read these and create custom configuration of &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx&lt;/code&gt;. So, we need to create a template of nginx configuration. This file will be called &lt;code class=&quot;highlighter-rouge&quot;&gt;default.ctmpl&lt;/code&gt; and it looks like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;{{$&lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;  := &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;BLUE_NAME&quot;&lt;/span&gt;}}
{{$&lt;span class=&quot;n&quot;&gt;green&lt;/span&gt; := &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;GREEN_NAME&quot;&lt;/span&gt;}}
{{$&lt;span class=&quot;n&quot;&gt;live&lt;/span&gt;  := &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;/var/live&quot;&lt;/span&gt;}}
&lt;span class=&quot;n&quot;&gt;worker_processes&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;;

&lt;span class=&quot;n&quot;&gt;events&lt;/span&gt; {
    &lt;span class=&quot;n&quot;&gt;worker_connections&lt;/span&gt;  &lt;span class=&quot;m&quot;&gt;1024&lt;/span&gt;;
}

&lt;span class=&quot;n&quot;&gt;http&lt;/span&gt; {
  &lt;span class=&quot;n&quot;&gt;upstream&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt; {
    &lt;span class=&quot;n&quot;&gt;least_conn&lt;/span&gt;;
    {{&lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service&lt;/span&gt; $&lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;}}
    &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; {{.&lt;span class=&quot;n&quot;&gt;Address&lt;/span&gt;}}:{{.&lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;}} &lt;span class=&quot;n&quot;&gt;max_fails&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fail_timeout&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;;{{&lt;span class=&quot;n&quot;&gt;else&lt;/span&gt;}}
    &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;127&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;:&lt;span class=&quot;m&quot;&gt;55000&lt;/span&gt;;{{&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;}}
  }

  &lt;span class=&quot;n&quot;&gt;upstream&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;green&lt;/span&gt; {
    &lt;span class=&quot;n&quot;&gt;least_conn&lt;/span&gt;;
    {{&lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service&lt;/span&gt; $&lt;span class=&quot;n&quot;&gt;green&lt;/span&gt;}}
    &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; {{.&lt;span class=&quot;n&quot;&gt;Address&lt;/span&gt;}}:{{.&lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;}} &lt;span class=&quot;n&quot;&gt;max_fails&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fail_timeout&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;;{{&lt;span class=&quot;n&quot;&gt;else&lt;/span&gt;}}
    &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;127&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;.&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;:&lt;span class=&quot;m&quot;&gt;55000&lt;/span&gt;;{{&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;}}
  }

  &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; {
    &lt;span class=&quot;n&quot;&gt;listen&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;80&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;;

    &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt; / {
      {{&lt;span class=&quot;n&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt; $&lt;span class=&quot;n&quot;&gt;live&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;blue&quot;&lt;/span&gt;}}
      &lt;span class=&quot;n&quot;&gt;proxy_pass&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;://&lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;;
      {{&lt;span class=&quot;n&quot;&gt;else&lt;/span&gt;}}
      &lt;span class=&quot;n&quot;&gt;proxy_pass&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;://&lt;span class=&quot;n&quot;&gt;green&lt;/span&gt;;
      {{&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;}}
    }
  }

  &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; {
    &lt;span class=&quot;n&quot;&gt;listen&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;8080&lt;/span&gt;;

    &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt; / {
      {{&lt;span class=&quot;n&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eq&lt;/span&gt; $&lt;span class=&quot;n&quot;&gt;live&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;blue&quot;&lt;/span&gt;}}
      &lt;span class=&quot;n&quot;&gt;proxy_pass&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;://&lt;span class=&quot;n&quot;&gt;green&lt;/span&gt;;
      {{&lt;span class=&quot;n&quot;&gt;else&lt;/span&gt;}}
      &lt;span class=&quot;n&quot;&gt;proxy_pass&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;://&lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;;
      {{&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;}}
    }
  }
}&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;First of all, we set three variables:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;: The docker service name of the blue environment, taken from environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;BLUE_NAME&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;: The docker service name of the green environment, taken from environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;GREEN_NAME&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;live&lt;/code&gt;: Current live environment, &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;, taken from the file &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/live&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will store the current live environment, &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;, in the file &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/live&lt;/code&gt;. We cannot use environment variable for this because we cannot globally change the value of environment variable from inside a running docker image. So we write the current live environment, while switching, to the file and read its content from inside consul-template.&lt;/p&gt;

&lt;p&gt;Inside the http block, we create an upstream block for &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;. Inside each of this upstream block, we specify the load balancing configuration for each service. The &lt;code class=&quot;highlighter-rouge&quot;&gt;least_conn&lt;/code&gt; line causes nginx is to route traffic to the least connected instance. We need to generate &lt;code class=&quot;highlighter-rouge&quot;&gt;server&lt;/code&gt; configuration lines for each instance of the service currently running. This is done by the code blocks, &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{range&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;service&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$blue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{range&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;service&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$blue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt;. The code between these directives are repeated for each instance of the service running with &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{.Address&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt; replaced by the address and &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{.Port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt; replaced by its port of that instance. If there is no instance of any service, we have the default &lt;code class=&quot;highlighter-rouge&quot;&gt;server 127.0.0.1:55000;&lt;/code&gt; line that causes an error.&lt;/p&gt;

&lt;p&gt;Next we have the server block that is listening to the port 80. If the value of the &lt;code class=&quot;highlighter-rouge&quot;&gt;live&lt;/code&gt; variable is &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;, this is proxied to the &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; app. If the value of &lt;code class=&quot;highlighter-rouge&quot;&gt;live&lt;/code&gt; is &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;, this is proxied to &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt; app. So, in essence, the port 80 will point to the live environment.&lt;/p&gt;

&lt;p&gt;Similarly, we have a server block that listens to port 8080. This is proxied to the staging environment. So, if the value of &lt;code class=&quot;highlighter-rouge&quot;&gt;live&lt;/code&gt; is &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;, this points to the &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt; app and vice-versa. In any case, the port 80 will give the live environment and port 8080 will give the staging environment.&lt;/p&gt;

&lt;h2 id=&quot;image-scripts&quot;&gt;Image Scripts&lt;/h2&gt;

&lt;p&gt;We need a bash script, that acts as the entry point to this docker image. The file &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt; looks like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/sh&lt;/span&gt;
nginx -g &lt;span class=&quot;s1&quot;&gt;'daemon off;'&lt;/span&gt; &amp;amp;
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; -n &lt;span class=&quot;nv&quot;&gt;$LIVE&lt;/span&gt; &amp;gt; /var/live
consul-template -consul&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$CONSUL_URL&lt;/span&gt; -template&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/templates/default.ctmpl:/etc/nginx/nginx.conf:nginx -s reload&quot;&lt;/span&gt;  &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The first line of the scipt starts up &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx&lt;/code&gt;. Now, we write the value of environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;LIVE&lt;/code&gt; to the file &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/live&lt;/code&gt;. This environment variable contains the value &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;, which is the initial live environment.&lt;/p&gt;

&lt;p&gt;We then start up &lt;code class=&quot;highlighter-rouge&quot;&gt;consul-template&lt;/code&gt;. This command need two parameter. The first one is &lt;code class=&quot;highlighter-rouge&quot;&gt;-consul&lt;/code&gt; and it requires the url for consul. We pass an environment variable for this. The next one is called &lt;code class=&quot;highlighter-rouge&quot;&gt;-template&lt;/code&gt; and it consists of three parts seperated by a colon. The first one is the path of the template file. The second is the path where the generated configuration file must be placed. The third is the command that must by run when new configuration is generated. Here, we need to reload nginx.&lt;/p&gt;

&lt;p&gt;The consul-template listens for services and create new configuration file whenever a service starts or stops. The information about this is collected by the registrator services running in each node is our swarm and is stored in consul.&lt;/p&gt;

&lt;p&gt;Now, we need another script to switch the live environment. The script will accept a parameter, either &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; of &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt; and change the current live environment to that value. The file &lt;code class=&quot;highlighter-rouge&quot;&gt;switch&lt;/code&gt; looks like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/sh&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$# &lt;/span&gt;-eq 0 &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;No arguments supplied&quot;&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;exit &lt;/span&gt;1
&lt;span class=&quot;k&quot;&gt;fi

if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;blue&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;then
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; -n &lt;span class=&quot;s2&quot;&gt;&quot;blue&quot;&lt;/span&gt; &amp;gt; /var/live
  &lt;span class=&quot;k&quot;&gt;else
    &lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; -n &lt;span class=&quot;s2&quot;&gt;&quot;green&quot;&lt;/span&gt; &amp;gt; /var/live
&lt;span class=&quot;k&quot;&gt;fi

&lt;/span&gt;consul-template -consul&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$CONSUL_URL&lt;/span&gt; -template&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/templates/default.ctmpl:/etc/nginx/nginx.conf:nginx -s reload&quot;&lt;/span&gt; -retry 30s -once &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;If there is no arguments passed to this scripts, it exits showing the error message, &lt;code class=&quot;highlighter-rouge&quot;&gt;No arguments supplied&lt;/code&gt;. If the parameter is &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;, it is written to the file &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/live&lt;/code&gt;. Else, the value &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt; is written to that file. This is now the current live environment.&lt;/p&gt;

&lt;p&gt;Finally, we run the &lt;code class=&quot;highlighter-rouge&quot;&gt;consul-template&lt;/code&gt; command with the &lt;code class=&quot;highlighter-rouge&quot;&gt;once&lt;/code&gt; parameter. This causes the consul-template to create new nginx configuration based on the new value in &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/live&lt;/code&gt; and reload nginx. This will switch the current live environment. As we have used the &lt;code class=&quot;highlighter-rouge&quot;&gt;once&lt;/code&gt; parameter, the new configuration in made only once and consul-template will not listen for new services. For that, we have a consul-template running from our &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt; file.&lt;/p&gt;

&lt;h2 id=&quot;blue-green-image&quot;&gt;Blue-Green Image&lt;/h2&gt;

&lt;p&gt;Save these three files, &lt;code class=&quot;highlighter-rouge&quot;&gt;default.ctmpl&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;switch&lt;/code&gt;, in folder named &lt;code class=&quot;highlighter-rouge&quot;&gt;files&lt;/code&gt;. In its parent, we can have the &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; contains information on how to build this docker image and will look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;FROM nginx:alpine

RUN apk add --no-cache --virtual unzip
ADD https://releases.hashicorp.com/consul-template/0.14.0/consul-template_0.14.0_linux_amd64.zip /usr/bin/
RUN unzip /usr/bin/consul-template_0.14.0_linux_amd64.zip -d /usr/local/bin

COPY files/s&lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; /bin/
RUN chmod +x /bin/switch /bin/start.sh
COPY files/default.ctmpl /templates/

ENV LIVE blue
ENV BLUE_NAME blue
ENV GREEN_NAME green

EXPOSE 80 8080
ENTRYPOINT &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/bin/start.sh&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This dockerfile uses &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx:alpine&lt;/code&gt; as the base and installs unzip and consul-template into it. It then copies the &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;switch&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;default.ctmpl&lt;/code&gt; to required locations and make the scripts executable.&lt;/p&gt;

&lt;p&gt;We also set the default values for following environment variables:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;LIVE&lt;/code&gt;: The initial live environment. Set to &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BLUE_NAME&lt;/code&gt;: The docker service name of blue environment. Set to &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GREEN_NAME&lt;/code&gt;: The docker service name of green environment. Set to &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We expose the port 80 and 8080. The &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt; file will be the entry point to this image.&lt;/p&gt;

&lt;h2 id=&quot;testing-blue-green-deployment&quot;&gt;Testing Blue-Green deployment&lt;/h2&gt;

&lt;p&gt;To test blue-green deployment, we will use the following &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; file.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'2'&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;bg&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;hanzel&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;green&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;container_name&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;bg&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
      - &lt;span class=&quot;s2&quot;&gt;&quot;80:80&quot;&lt;/span&gt;
      - &lt;span class=&quot;s2&quot;&gt;&quot;8080:8080&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;constraint&lt;/span&gt;:&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;==&lt;span class=&quot;n&quot;&gt;master&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;CONSUL_URL&lt;/span&gt;=${&lt;span class=&quot;n&quot;&gt;KV_IP&lt;/span&gt;}:&lt;span class=&quot;m&quot;&gt;8500&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;BLUE_NAME&lt;/span&gt;=&lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;GREEN_NAME&lt;/span&gt;=&lt;span class=&quot;n&quot;&gt;green&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;LIVE&lt;/span&gt;=&lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depends_on&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;green&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;green&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;hanzel&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;nginx&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;:&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
      - &lt;span class=&quot;s2&quot;&gt;&quot;80&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;SERVICE_80_NAME&lt;/span&gt;=&lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;green&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;green&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;hanzel&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;nginx&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;:&lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
      - &lt;span class=&quot;s2&quot;&gt;&quot;80&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;SERVICE_80_NAME&lt;/span&gt;=&lt;span class=&quot;n&quot;&gt;green&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;green&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;blue&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;green&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;overlay&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We are using the version 2 of docker-compose file, with three services in an overlay network named &lt;code class=&quot;highlighter-rouge&quot;&gt;blue-green&lt;/code&gt;. We have two versions of &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/nginx-html&lt;/code&gt; image running as blue and green services. We also have &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/blue-green&lt;/code&gt; image running for blue-green deployment.&lt;/p&gt;

&lt;p&gt;The first service is the blue service, named &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;. The image used is version 1 of &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/nginx-html&lt;/code&gt;. We have mapped the port 80 of the container to some port in the host. We have set the environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;SERVICE_80_NAME&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;. This causes the &lt;code class=&quot;highlighter-rouge&quot;&gt;registrator&lt;/code&gt; to register this service into consul named as &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;. This is the initial live environment.&lt;/p&gt;

&lt;p&gt;Similarly, we have the green service, named &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;. The image used here is version 2 of the &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/nginx-html&lt;/code&gt;. The environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;SERVICE_80_NAME&lt;/code&gt; is set to &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt; so that &lt;code class=&quot;highlighter-rouge&quot;&gt;registrator&lt;/code&gt; will register it named as &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;. This is the initial statging environment.&lt;/p&gt;

&lt;p&gt;Finally, we have the &lt;code class=&quot;highlighter-rouge&quot;&gt;bg&lt;/code&gt; service with &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/blue-green&lt;/code&gt; image. You can also build the image we just made in the previous section for this service by replacing the line &lt;code class=&quot;highlighter-rouge&quot;&gt;image: hanzel/blue-green&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;build: .&lt;/code&gt; and placing this file along with the &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; we made in the previous section.&lt;/p&gt;

&lt;p&gt;We map the ports &lt;code class=&quot;highlighter-rouge&quot;&gt;80&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;8080&lt;/code&gt; of the container to that of the host. We also need to set the following environment variables.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;constraint:node&lt;/code&gt;: The name of the node where this service should run. We want this service to always run on the &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt; node.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;CONSUL_URL&lt;/code&gt;: The url endpoint of consul. We have set it to &lt;code class=&quot;highlighter-rouge&quot;&gt;${KV_IP}:8500&lt;/code&gt;, where &lt;code class=&quot;highlighter-rouge&quot;&gt;KV_IP&lt;/code&gt; is the environment variable we have set while making the swarm.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;BLUE_NAME&lt;/code&gt;: The docker service name of the blue image. Set to &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;GREEN_NAME&lt;/code&gt;: The docker service name of the green image. Set to &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;LIVE&lt;/code&gt;: The initial live environment, blue or green. Set to &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We can start the services with the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-compose up -d&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This will start up a single instance of each of these three services. We can scale the blue and green services to 3 instances each with the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-compose scale &lt;span class=&quot;nv&quot;&gt;blue&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3 &lt;span class=&quot;nv&quot;&gt;green&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;These will create two new instances for blue and green service. You can see the running services of docker-compose with the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose ps&lt;/code&gt; command. The output of the command will look something like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;Name          Command                State                               Ports
----------------------------------------------------------------------------------------------------------
&lt;span class=&quot;nb&quot;&gt;bg&lt;/span&gt;            /bin/start.sh          Up      443/tcp, 45.55.185.18:80-&amp;gt;80/tcp, 45.55.185.18:8080-&amp;gt;8080/tcp
tmp_blue_1    nginx -g daemon off;   Up      443/tcp, 45.55.185.18:32777-&amp;gt;80/tcp
tmp_blue_2    nginx -g daemon off;   Up      443/tcp, 159.203.119.37:32769-&amp;gt;80/tcp
tmp_blue_3    nginx -g daemon off;   Up      443/tcp, 45.55.185.18:32778-&amp;gt;80/tcp
tmp_green_1   nginx -g daemon off;   Up      443/tcp, 159.203.119.37:32768-&amp;gt;80/tcp
tmp_green_2   nginx -g daemon off;   Up      443/tcp, 45.55.185.18:32779-&amp;gt;80/tcp
tmp_green_3   nginx -g daemon off;   Up      443/tcp, 159.203.119.37:32770-&amp;gt;80/tcp&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can see the live production environment from the url given by the command, &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose port bg 80&lt;/code&gt;. You will get some IP address like &lt;code class=&quot;highlighter-rouge&quot;&gt;45.55.185.18:80&lt;/code&gt;, which is the IP for the &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt; node. Go to this url and we can see the live environment, currently &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt;, showing &lt;code class=&quot;highlighter-rouge&quot;&gt;Version 1&lt;/code&gt;. You can see the staging environment, currently &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;, by going to port &lt;code class=&quot;highlighter-rouge&quot;&gt;8080&lt;/code&gt; of the same IP. That will be &lt;code class=&quot;highlighter-rouge&quot;&gt;45.55.185.18:8080&lt;/code&gt; in this case. This will show you &lt;code class=&quot;highlighter-rouge&quot;&gt;Version 2&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now, the users can see the version 1 of your app and only you can see version 2. You can test the new version and if you are satisfied, you can switch the live environment to &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt;. To do this, use the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker &lt;span class=&quot;nb&quot;&gt;exec bg &lt;/span&gt;switch green&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now, the live version is &lt;code class=&quot;highlighter-rouge&quot;&gt;green&lt;/code&gt; and at port 80, you can see version 2 and at port 8080, you can see version 1. You can see the new nginx configuration with the command, &lt;code class=&quot;highlighter-rouge&quot;&gt;docker exec bg cat /etc/nginx/nginx.conf&lt;/code&gt;. The output of this command will look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-nginx&quot; data-lang=&quot;nginx&quot;&gt;&lt;span class=&quot;k&quot;&gt;worker_processes&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;events&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;worker_connections&lt;/span&gt;  &lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;http&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;upstream&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;blue&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;least_conn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.12.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32769&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.35.39&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32777&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.35.39&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32778&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;upstream&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;green&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;least_conn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.12.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32768&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.12.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32770&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.35.39&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32779&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;listen&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;80&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;kn&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;kn&quot;&gt;proxy_pass&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;http://green&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;listen&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8080&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;kn&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;kn&quot;&gt;proxy_pass&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;http://blue&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can always check the current live environment using the command, &lt;code class=&quot;highlighter-rouge&quot;&gt;docker exec bg cat /var/live&lt;/code&gt;. Now, &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; is the staging environment and we can check version 3 there. So in the blue service of the &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; file, change the line &lt;code class=&quot;highlighter-rouge&quot;&gt;image: hanzel/nginx-html:1&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;image: hanzel/nginx-html:3&lt;/code&gt;. To update the blue service, run the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-compose up -d blue&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;All three instances for &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; services will be upgraded from version 1 to version 3 now. The staging environment at port &lt;code class=&quot;highlighter-rouge&quot;&gt;8080&lt;/code&gt; of the &lt;code class=&quot;highlighter-rouge&quot;&gt;bg&lt;/code&gt; service will now show &lt;code class=&quot;highlighter-rouge&quot;&gt;Version 3&lt;/code&gt;. You can check this version and if it is okay for production, switch the live environment to &lt;code class=&quot;highlighter-rouge&quot;&gt;blue&lt;/code&gt; with the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker &lt;span class=&quot;nb&quot;&gt;exec bg &lt;/span&gt;switch blue&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now, live environment at port &lt;code class=&quot;highlighter-rouge&quot;&gt;80&lt;/code&gt; will show &lt;code class=&quot;highlighter-rouge&quot;&gt;Version 3&lt;/code&gt; and the staging environment at port &lt;code class=&quot;highlighter-rouge&quot;&gt;8080&lt;/code&gt; will show &lt;code class=&quot;highlighter-rouge&quot;&gt;Version 2&lt;/code&gt;. You can repeat this process for newer versions.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this article, we have seen how to build a blue-green deployment system with Dockers to release new version of the app without downtime. We have made a docker image to implement this blue-green deployment and tested it on an app deployed with Docker Swarm.&lt;/p&gt;

&lt;p&gt;Once you are done, the services can be stopped and the hosts removed with the following commands.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-compose down
docker-machine stop consul master slave
docker-machine rm consul master slave&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Sun, 10 Apr 2016 18:00:00 +0000</pubDate>
        <link>https://botleg.com/stories/blue-green-deployment-with-docker/</link>
        <guid isPermaLink="true">https://botleg.com/stories/blue-green-deployment-with-docker/</guid>
        
        <category>blue-green</category>
        
        <category>live</category>
        
        <category>staging</category>
        
        <category>docker</category>
        
        <category>swarm</category>
        
        <category>registrator</category>
        
        <category>nginx</category>
        
        <category>consul</category>
        
        <category>consul-template</category>
        
        <category>overlay</category>
        
        <category>digitalocean</category>
        
        <category>compose</category>
        
        <category>machine</category>
        
        <category>bash</category>
        
        <category>Dockerfile</category>
        
        
        <category>devops</category>
        
      </item>
    
      <item>
        <title>Load Balancing with Docker Swarm</title>
        <author><name>Hanzel Jesheen</name></author>
        <description>&lt;blockquote&gt;
  &lt;p&gt;Docker Swarm is native clustering for Docker. It turns a pool of Docker hosts into a single, virtual Docker host.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Docker Swarm lets us group a number of hosts into a cluster and distribute the docker images among these hosts. So, the workload in divided by the nodes in the swarm. In this article, we are going to deploy and scale an application. We will also deploy a load balancer that will distribute the traffic to different instances of the docker images in the swarm. You can follow along this article with only your terminal.&lt;/p&gt;

&lt;p&gt;In my &lt;a href=&quot;/stories/orchestrate-docker-containers-with-tutum/&quot;&gt;previous article&lt;/a&gt;, we discussed load balancing with a docker orchestration tool, &lt;a href=&quot;https://cloud.docker.com/&quot;&gt;Docker Cloud&lt;/a&gt; (previously known as &lt;a href=&quot;https://www.tutum.co/&quot;&gt;Tutum&lt;/a&gt;). Now, we do the same thing with Docker Swarm. The docker image for load balancer is &lt;a href=&quot;https://hub.docker.com/r/hanzel/load-balancing-swarm/&quot;&gt;hanzel/load-balancing-swarm&lt;/a&gt; and its code can be found &lt;a href=&quot;https://github.com/botleg/load-balancing-swarm&quot;&gt;here&lt;/a&gt;. We are load balancing a Node.js application with Redis as the database. Also, the docker image for the Node.js application is &lt;a href=&quot;https://hub.docker.com/r/hanzel/tutum-nodejs-redis/&quot;&gt;hanzel/tutum-nodejs-redis&lt;/a&gt; and its code can be found &lt;a href=&quot;https://github.com/botleg/tutum-nodejs-redis&quot;&gt;here&lt;/a&gt;. For Redis, we use its official docker image - &lt;a href=&quot;https://hub.docker.com/_/redis/&quot;&gt;redis&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h2&gt;

&lt;p&gt;We will be using &lt;a href=&quot;https://docs.docker.com/machine/&quot;&gt;Docker Machine&lt;/a&gt; to create and manage remote hosts as a swarm. With Docker Machine, you can create hosts on your local machine or your cloud provider. Check &lt;a href=&quot;https://docs.docker.com/machine/drivers/&quot;&gt;this link&lt;/a&gt; to see the drivers supported by Docker Machine.&lt;/p&gt;

&lt;p&gt;You need to have the following installed in you local computer:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker&lt;/code&gt;: version &amp;gt;= 1.10, to support Docker Compose File version 2 and Multi-Host networking.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Machine&lt;/code&gt;: version &amp;gt;= 0.6&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Compose&lt;/code&gt;: version &amp;gt;= 1.6, to support Docker Compose file version 2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can create the virtual hosts in you local system if you have &lt;a href=&quot;https://www.virtualbox.org/wiki/Downloads&quot;&gt;VirtualBox&lt;/a&gt; installed. For this demonstration, I will be using &lt;a href=&quot;https://docs.docker.com/machine/&quot;&gt;DigitalOcean&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;initial-setup&quot;&gt;Initial Setup&lt;/h2&gt;

&lt;p&gt;Before we start using Docker Machine, we need to setup some environment variables. You can see more about these environment variables from &lt;a href=&quot;https://docs.docker.com/machine/drivers/&quot;&gt;here&lt;/a&gt;. Create a Personal Access Token from DigitalOcean. If you need help for that, check &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-use-the-digitalocean-api-v2#how-to-generate-a-personal-access-token&quot;&gt;this&lt;/a&gt; out. Your token will look something like &lt;code class=&quot;highlighter-rouge&quot;&gt;ed1d3d280778fe0e86b7a3e0fea065cf799fce3e575c722458897354e59de0b0&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We will use &lt;code class=&quot;highlighter-rouge&quot;&gt;Debian 8&lt;/code&gt; as ths OS of the nodes and enable private networking, so that the hosts in the swarm can communicate with each other. Set these environment variables with the following bash commands.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;DIGITALOCEAN_ACCESS_TOKEN&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;YOUR_DIGITALOCEAN_TOKEN
&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;DIGITALOCEAN_PRIVATE_NETWORKING&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;true
export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;DIGITALOCEAN_IMAGE&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;debian-8-x64&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;consul&quot;&gt;Consul&lt;/h2&gt;

&lt;p&gt;To create a Swarm, we need access to a Key-Value store for service discovery and to store configuration. Swarm supports Consul, Etcd, and ZooKeeper. We will be using &lt;a href=&quot;https://www.consul.io/&quot;&gt;Consul&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will be creating a host for running Consul alone. It will not be a part of the swarm. So we can create a host named &lt;code class=&quot;highlighter-rouge&quot;&gt;consul&lt;/code&gt; first.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-machine create &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  -d digitalocean &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  consul&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This command will create a host in DigitalOcean and provision it. You can use the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-machine ssh consul&lt;/code&gt;, to ssh into this host. We will store the private IP of this host as &lt;code class=&quot;highlighter-rouge&quot;&gt;KV_IP&lt;/code&gt; environment variable with the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KV_IP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;docker-machine ssh consul &lt;span class=&quot;s1&quot;&gt;'ifconfig eth1 | grep &quot;inet addr:&quot; | cut -d: -f2 | cut -d&quot; &quot; -f1'&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We need to connect out docker client to this host and then run &lt;a href=&quot;https://hub.docker.com/r/progrium/consul/&quot;&gt;progrium/consul&lt;/a&gt; image there.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;docker-machine env consul&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;

docker run -d &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  -p &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KV_IP&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;:8500:8500 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  -h consul &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --restart always &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  gliderlabs/consul-server -bootstrap&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This command will pull and deploy the image in &lt;code class=&quot;highlighter-rouge&quot;&gt;consul&lt;/code&gt; host.&lt;/p&gt;

&lt;h2 id=&quot;the-swarm&quot;&gt;The Swarm&lt;/h2&gt;

&lt;p&gt;Now, we will create the swarm. A Docker swarm need a master node and an arbitrary number of ordinary nodes. The swarm master is named &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt; and we will create this now.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-machine create &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  -d digitalocean &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --swarm &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --swarm-master &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --swarm-discovery&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;consul://&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KV_IP&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:8500&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --engine-opt&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;cluster-store=consul://&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KV_IP&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:8500&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --engine-opt&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;cluster-advertise=eth1:2376&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  master&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;swarm-master&lt;/code&gt; flag idetifies this node as the swarm master. We also need to provide the consul endpoint as the &lt;code class=&quot;highlighter-rouge&quot;&gt;swarm-discovery&lt;/code&gt; flag. For us, this is &lt;code class=&quot;highlighter-rouge&quot;&gt;consul://${KV_IP}:8500&lt;/code&gt;. We will set the private IP for this host as &lt;code class=&quot;highlighter-rouge&quot;&gt;MASTER_IP&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;MASTER_IP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;docker-machine ssh master &lt;span class=&quot;s1&quot;&gt;'ifconfig eth1 | grep &quot;inet addr:&quot; | cut -d: -f2 | cut -d&quot; &quot; -f1'&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can now create any number of nodes in this swarm. For this example, we will have only one other node in the swarm and it is named &lt;code class=&quot;highlighter-rouge&quot;&gt;slave&lt;/code&gt;. We will create this host and set its private IP as &lt;code class=&quot;highlighter-rouge&quot;&gt;SLAVE_IP&lt;/code&gt; with the following commands.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-machine create &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  -d digitalocean &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --swarm &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --swarm-discovery&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;consul://&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KV_IP&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:8500&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --engine-opt&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;cluster-store=consul://&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KV_IP&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;:8500&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --engine-opt&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;cluster-advertise=eth1:2376&quot;&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  slave

&lt;span class=&quot;nb&quot;&gt;export &lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SLAVE_IP&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;docker-machine ssh slave &lt;span class=&quot;s1&quot;&gt;'ifconfig eth1 | grep &quot;inet addr:&quot; | cut -d: -f2 | cut -d&quot; &quot; -f1'&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can create more nodes in the swarm by repeating these commands by just changing the hostname. We also need to have a registrator service running in each of these hosts to keep track of all services running in each host. The version 6 of &lt;code class=&quot;highlighter-rouge&quot;&gt;gliderlabs/registrator&lt;/code&gt; image is used for this.&lt;/p&gt;

&lt;p&gt;We need to connect our client to each of these hosts and run the registrator image.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;docker-machine env master&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;

docker run -d &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --name&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;registrator &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  -h &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;MASTER_IP&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --volume&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/var/run/docker.sock:/tmp/docker.sock &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  gliderlabs/registrator:v6 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  consul://&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KV_IP&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;:8500

&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;docker-machine env slave&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;

docker run -d &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --name&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;registrator &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  -h &lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;SLAVE_IP&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  --volume&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/var/run/docker.sock:/tmp/docker.sock &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  gliderlabs/registrator:v6 &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  consul://&lt;span class=&quot;k&quot;&gt;${&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;KV_IP&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;}&lt;/span&gt;:8500&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This service will keep track of the information like IP and PORT of each service running in the host and saves it to consul. We can now connect the docker client to the swarm. For this, we use &lt;code class=&quot;highlighter-rouge&quot;&gt;-swarm&lt;/code&gt; parameter with the swarm master.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;eval&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;$(&lt;/span&gt;docker-machine env -swarm master&lt;span class=&quot;k&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can see all the hosts created with &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-machine&lt;/code&gt; with the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-machine ls&lt;/code&gt;. The output of this command must look something like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;NAME     ACTIVE      DRIVER         STATE     URL                          SWARM             DOCKER
consul   -           digitalocean   Running   tcp://104.131.126.139:2376                     v1.10.1
master   &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;swarm&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   digitalocean   Running   tcp://45.55.48.84:2376       master &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;master&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt;   v1.10.1
slave    -           digitalocean   Running   tcp://104.131.177.65:2376    master            v1.10.1 &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;docker-compose&quot;&gt;Docker Compose&lt;/h2&gt;

&lt;p&gt;We have set up the swarm, it is ready for deployment. For this demonstration, we will be deploying multiple instances of Node.js application with a single instance of Redis as the database. The code for this Node.js application can be found &lt;a href=&quot;https://github.com/botleg/tutum-nodejs-redis&quot;&gt;here&lt;/a&gt;. It just lets us set the read values from redis. The docker images used for this is &lt;a href=&quot;https://hub.docker.com/r/hanzel/tutum-nodejs-redis/&quot;&gt;hanzel/tutum-nodejs-redis&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Docker Compose allows us to write the configuration file for this deployment. We are going to use the Docker Compose File version 2, which allows us to define configuration about the network and volumes used for the deployment in &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; file. You can know more about Version 2 of compose file &lt;a href=&quot;https://docs.docker.com/compose/compose-file/#version-2&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; file looks like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'2'&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;hanzel&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;tutum&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;nodejs&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
      - &lt;span class=&quot;s2&quot;&gt;&quot;4000&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;APP_PORT&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;4000&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;REDIS_IP&lt;/span&gt;=&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;REDIS_PORT&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;6379&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depends_on&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;back&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;tier&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;container_name&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;command&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; --&lt;span class=&quot;n&quot;&gt;appendonly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yes&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;:/&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;back&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;tier&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;back&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;tier&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;overlay&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The first service is &lt;code class=&quot;highlighter-rouge&quot;&gt;web&lt;/code&gt; and it contains the image &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/tutum-nodejs-redis&lt;/code&gt;, which is the node.js application. We are pulishing the port 4000 inside the container. It will be mapped to some port of the host. We need to setup some environment variables:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;APP_PORT&lt;/code&gt;: Port to run the Node.js application.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;REDIS_IP&lt;/code&gt;: The IP of the redis instance.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;REDIS_PORT&lt;/code&gt;: The PORT of the redis instance.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The second service is the official &lt;code class=&quot;highlighter-rouge&quot;&gt;redis&lt;/code&gt; image. For persistant data storage, we are creating a data volumes named &lt;code class=&quot;highlighter-rouge&quot;&gt;redis-data&lt;/code&gt;. This volume is of the type &lt;code class=&quot;highlighter-rouge&quot;&gt;local&lt;/code&gt;, so the data is stored in the local host system.&lt;/p&gt;

&lt;p&gt;The services in the same network are linked. Here, both these services are in the &lt;code class=&quot;highlighter-rouge&quot;&gt;back-tier&lt;/code&gt; network which is of the type &lt;code class=&quot;highlighter-rouge&quot;&gt;overlay&lt;/code&gt;. The overlay network allow &lt;code class=&quot;highlighter-rouge&quot;&gt;multi-host networking&lt;/code&gt;, this allows the service to be linked even if the these are in different hosts.&lt;/p&gt;

&lt;p&gt;Save this code as &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; and save it in a folder. Make sure that your docker client is connected to the swarm with &lt;code class=&quot;highlighter-rouge&quot;&gt;eval $(docker-machine env -swarm master)&lt;/code&gt; command. Now open up the terminal in this folder and start the services using the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-compose up -d&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This will start up the services, which are distributed across the different hosts in the swarm. You can see details about the running services with the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose ps&lt;/code&gt;. The output must look something like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;Name                       Command                          State     Ports           
-------------------------------------------------------------------------------------------------
loadbalancingswarm_web_1   npm start                        Up        45.55.48.84:32768-&amp;gt;4000/tcp
redis                      /entrypoint.sh redis-serve ...   Up        6379/tcp                   &lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In this case, you can see the app running at &lt;code class=&quot;highlighter-rouge&quot;&gt;45.55.48.84:32768&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;load-balancer&quot;&gt;Load Balancer&lt;/h2&gt;

&lt;p&gt;We have a single instance of the app running. We need to now implement a load balancer that can distribute the traffic across all the instances of this service. As we increase and decrease the instances of the service, we need to automatically update the load balancer. The code for the load balancer can be found &lt;a href=&quot;https://github.com/botleg/load-balancing-swarm&quot;&gt;here&lt;/a&gt; and the docker image for this is &lt;a href=&quot;https://hub.docker.com/r/hanzel/load-balancing-swarm/&quot;&gt;hanzel/load-balancing-swarm&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We will use &lt;a href=&quot;https://www.nginx.com/&quot;&gt;nginx&lt;/a&gt; for load balancing and &lt;a href=&quot;https://github.com/hashicorp/consul-template&quot;&gt;consul-template&lt;/a&gt; to manage nginx configuration. You can also use HAproxy as the load balancer, the process is similar.&lt;/p&gt;

&lt;p&gt;First, we need to create a template file for nginx configuration. This file is filled with the service information by consul-template and forms the configuration for nginx. The file &lt;code class=&quot;highlighter-rouge&quot;&gt;default.ctmpl&lt;/code&gt; looks like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;{{$&lt;span class=&quot;n&quot;&gt;app&lt;/span&gt; := &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;APP_NAME&quot;&lt;/span&gt;}}

&lt;span class=&quot;n&quot;&gt;upstream&lt;/span&gt; {{&lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt; $&lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;}} {
    &lt;span class=&quot;n&quot;&gt;least_conn&lt;/span&gt;;
    {{&lt;span class=&quot;n&quot;&gt;range&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;service&lt;/span&gt; $&lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;}}
    &lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; {{.&lt;span class=&quot;n&quot;&gt;Address&lt;/span&gt;}}:{{.&lt;span class=&quot;n&quot;&gt;Port&lt;/span&gt;}} &lt;span class=&quot;n&quot;&gt;max_fails&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fail_timeout&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;;{{&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;}}
}

&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; {
    &lt;span class=&quot;n&quot;&gt;listen&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;80&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;default&lt;/span&gt;;

    &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt; / {
        &lt;span class=&quot;n&quot;&gt;proxy_pass&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;http&lt;/span&gt;://{{&lt;span class=&quot;n&quot;&gt;printf&lt;/span&gt; $&lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;}};
    }
}&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We will set variable &lt;code class=&quot;highlighter-rouge&quot;&gt;app&lt;/code&gt; with the value of environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;APP_NAME&lt;/code&gt;. We create a upstream named with the variable &lt;code class=&quot;highlighter-rouge&quot;&gt;app&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;least_conn&lt;/code&gt; line causes nginx is to route traffic to the least connected instance. We need to generate &lt;code class=&quot;highlighter-rouge&quot;&gt;server&lt;/code&gt; configuration lines for each instance of the service currently running. This is done by the code block, &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{range&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;service&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;$app&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}...&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt;. The code between these directives are repeated for each instance of the service running with &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{.Address&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt; replaced by the address and &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;{.Port&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;}&lt;/span&gt;&lt;/code&gt; replaced by its port of that instance. Next we have the server block that is listening to the port 80. This will create a reverse proxy to the upstream we just created.&lt;/p&gt;

&lt;p&gt;We need a bash script, that acts as the entry point to this docker image. The file &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt; looks like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;c&quot;&gt;#!/bin/bash&lt;/span&gt;
service nginx start
consul-template -consul&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$CONSUL_URL&lt;/span&gt; -template&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/templates/default.ctmpl:/etc/nginx/conf.d/default.conf:service nginx reload&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This script starts up nginx service. We then start up &lt;code class=&quot;highlighter-rouge&quot;&gt;consul-template&lt;/code&gt;. This command need two parameter. The first one is &lt;code class=&quot;highlighter-rouge&quot;&gt;-consul&lt;/code&gt; and it requires the url for consul. We pass an environment variable for this. The next one is called &lt;code class=&quot;highlighter-rouge&quot;&gt;-template&lt;/code&gt; and it consists of three parts seperated by a colon. The first one is the path of the template file. The second is the path where the generated configuration file must be placed. The third is the command that must by run when new configuration is generated. Here, we need to reload nginx.&lt;/p&gt;

&lt;p&gt;The consul-template will create new configuration file whenever a service starts or stops. The information about this is collected by the registrator services running in each node is our swarm and is stored in consul.&lt;/p&gt;

&lt;p&gt;Save these two files in folder named &lt;code class=&quot;highlighter-rouge&quot;&gt;files&lt;/code&gt; and in its parent, we can have the &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; contains information on how to build this docker image.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;FROM nginx:latest

RUN apt-get update &lt;span class=&quot;se&quot;&gt;\&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; apt-get install -y unzip

ADD files/start.sh /bin/start.sh
RUN chmod +x /bin/start.sh
ADD files/default.ctmpl /templates/default.ctmpl

ADD https://releases.hashicorp.com/consul-template/0.12.2/consul-template_0.12.2_linux_amd64.zip /usr/bin/
RUN unzip /usr/bin/consul-template_0.12.2_linux_amd64.zip -d /usr/local/bin

EXPOSE 80
ENTRYPOINT &lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/bin/start.sh&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This dockerfile uses &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx&lt;/code&gt; as the base and installs consul-template into it. It then copies the &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;default.ctmpl&lt;/code&gt; to required location. Finally, it exposes the port 80 and sets &lt;code class=&quot;highlighter-rouge&quot;&gt;start.sh&lt;/code&gt; as the entry point of the image.&lt;/p&gt;

&lt;h2 id=&quot;new-compose-file&quot;&gt;New Compose file&lt;/h2&gt;

&lt;p&gt;Create the file &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; in the folder containing Dockerfile. We can now add this service to this file. So, the new compose file will look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;&lt;span class=&quot;n&quot;&gt;version&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'2'&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;services&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;lb&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;build&lt;/span&gt;: .
    &lt;span class=&quot;n&quot;&gt;container_name&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;lb&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
      - &lt;span class=&quot;s2&quot;&gt;&quot;80:80&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;constraint&lt;/span&gt;:&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;==&lt;span class=&quot;n&quot;&gt;master&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;APP_NAME&lt;/span&gt;=&lt;span class=&quot;n&quot;&gt;tutum&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;nodejs&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;CONSUL_URL&lt;/span&gt;=${&lt;span class=&quot;n&quot;&gt;KV_IP&lt;/span&gt;}:&lt;span class=&quot;m&quot;&gt;8500&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depends_on&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;front&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;tier&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;web&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;hanzel&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;tutum&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;nodejs&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
      - &lt;span class=&quot;s2&quot;&gt;&quot;4000&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;APP_PORT&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;4000&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;REDIS_IP&lt;/span&gt;=&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;REDIS_PORT&lt;/span&gt;=&lt;span class=&quot;m&quot;&gt;6379&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;depends_on&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;front&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;tier&lt;/span&gt;
      - &lt;span class=&quot;n&quot;&gt;back&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;tier&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;container_name&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;command&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; --&lt;span class=&quot;n&quot;&gt;appendonly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yes&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;:/&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
      - &lt;span class=&quot;n&quot;&gt;back&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;tier&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;local&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;networks&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;front&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;tier&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;overlay&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;back&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;tier&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;driver&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;overlay&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We have new service name &lt;code class=&quot;highlighter-rouge&quot;&gt;lb&lt;/code&gt;. It is build using Dockerfile in the current directory. The port 80 of the container is mapped to port 80 of the host. We need to set up three environment variables:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;constraint:node&lt;/code&gt;: The name of the node where this service should run. We want the load balancing to always run on the &lt;code class=&quot;highlighter-rouge&quot;&gt;master&lt;/code&gt; node.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;APP_NAME&lt;/code&gt;: The image name of the service you need to load balance. Here, it is &lt;code class=&quot;highlighter-rouge&quot;&gt;tutum-nodejs-redis&lt;/code&gt;. You can load balance any service by providing its name here.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;CONSUL_URL&lt;/code&gt;: The url of consul. We are using the &lt;code class=&quot;highlighter-rouge&quot;&gt;KV_IP&lt;/code&gt; environment variable for this.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We have a new overlay network named &lt;code class=&quot;highlighter-rouge&quot;&gt;front-tier&lt;/code&gt;. This connects &lt;code class=&quot;highlighter-rouge&quot;&gt;lb&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;web&lt;/code&gt; services. Note that, the load balancer doesn’t need to connect to redis, so these are put in two different networks. The &lt;code class=&quot;highlighter-rouge&quot;&gt;web&lt;/code&gt; services is connected to both these networks.&lt;/p&gt;

&lt;p&gt;Instead of building a new image, you may use the image &lt;a href=&quot;https://hub.docker.com/r/hanzel/load-balancing-swarm/&quot;&gt;hanzel/load-balancing-swarm&lt;/a&gt;. Just replace the line &lt;code class=&quot;highlighter-rouge&quot;&gt;build: .&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;image: hanzel/load-balancing-swarm&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now we need to stop and remove the running services and start the new services.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-compose stop; docker-compose rm -f
docker-compose up -d&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We have only one instance of &lt;code class=&quot;highlighter-rouge&quot;&gt;web&lt;/code&gt; running now. We will scale this to three with the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-compose scale &lt;span class=&quot;nv&quot;&gt;web&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;3&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We can see that three instances of the &lt;code class=&quot;highlighter-rouge&quot;&gt;web&lt;/code&gt; service is running when we do &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose ps&lt;/code&gt;. The output will look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;Name                       Command                          State   Ports               
------------------------------------------------------------------------------------------------------
lb                         /bin/start.sh                    Up      443/tcp, 104.131.177.65:80-&amp;gt;80/tcp
loadbalancingswarm_web_1   npm start                        Up      45.55.48.84:32777-&amp;gt;4000/tcp
loadbalancingswarm_web_2   npm start                        Up      104.131.177.65:32772-&amp;gt;4000/tcp
loadbalancingswarm_web_3   npm start                        Up      45.55.48.84:32778-&amp;gt;4000/tcp
redis                      /entrypoint.sh redis-serve ...   Up      6379/tcp&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;In this case, you can go to &lt;code class=&quot;highlighter-rouge&quot;&gt;104.131.177.65&lt;/code&gt;, the IP of your master node to see the application running. Refresh the page and see the &lt;code class=&quot;highlighter-rouge&quot;&gt;host&lt;/code&gt; value changing. This shows that the load balancer is working.&lt;/p&gt;

&lt;p&gt;You can see the nginx configuration generated by consul-template by using the command &lt;code class=&quot;highlighter-rouge&quot;&gt;docker exec -t lb cat /etc/nginx/conf.d/default.conf&lt;/code&gt;. This should produce an output that looks like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-nginx&quot; data-lang=&quot;nginx&quot;&gt;&lt;span class=&quot;k&quot;&gt;upstream&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;tutum-nodejs-redis&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;least_conn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.1.191&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32777&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.1.191&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32778&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;10.132.14.17&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32772&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;max_fails=3&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;fail_timeout=60&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;weight=1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;listen&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;80&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;proxy_pass&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;http://tutum-nodejs-redis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Docker Swarm allows us to seamlessly scale and distribute docker work load to a cluster of hosts. We have now implemented load balancing of docker images using Docker Swarm. This is just a basic application of docker swarm. You can create more sophisticated setups with docker swarm like auto-scaling, database cluster, etc. I will try talking more about that in the coming articles.&lt;/p&gt;

&lt;p&gt;You can stop the services and remove the hosts using the following commands.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-compose down
docker-machine stop consul master slave
docker-machine rm consul master slave&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
</description>
        <pubDate>Tue, 08 Mar 2016 02:00:00 +0000</pubDate>
        <link>https://botleg.com/stories/load-balancing-with-docker-swarm/</link>
        <guid isPermaLink="true">https://botleg.com/stories/load-balancing-with-docker-swarm/</guid>
        
        <category>docker</category>
        
        <category>swarm</category>
        
        <category>cluster</category>
        
        <category>nodejs</category>
        
        <category>redis</category>
        
        <category>nginx</category>
        
        <category>consul</category>
        
        <category>consul-template</category>
        
        <category>multi-host</category>
        
        <category>networking</category>
        
        <category>overlay</category>
        
        <category>digitalocean</category>
        
        <category>compose</category>
        
        <category>machine</category>
        
        
        <category>devops</category>
        
      </item>
    
      <item>
        <title>Orchestrate Docker containers with Tutum</title>
        <author><name>Hanzel Jesheen</name></author>
        <description>&lt;p&gt;&lt;a href=&quot;https://www.tutum.co/&quot;&gt;Tutum&lt;/a&gt; simplifies the process of hosting Docker containers. We can connect Tutum to our cloud provider and create node clusters. We can then deploy, scale and link Docker containers from the Tutum interface. In this article, we will see how to deploy a Node.js application with Redis as the data store. We will also scale this application and use load balacing. The entire code for this application can be found &lt;a href=&quot;https://github.com/botleg/tutum-nodejs-redis&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;the-containers&quot;&gt;The Containers&lt;/h2&gt;

&lt;p&gt;I have made a simple Node.js application that connects to Redis database and lets you to set and see the value of a key. We use the &lt;a href=&quot;https://hub.docker.com/_/redis/&quot;&gt;official image&lt;/a&gt; for Redis. The app has three endpoints:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;/key&lt;/code&gt;: Returns the value of the &lt;code class=&quot;highlighter-rouge&quot;&gt;key&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;/key/value&lt;/code&gt;: Sets the value of the &lt;code class=&quot;highlighter-rouge&quot;&gt;key&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;value&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;/&lt;/code&gt;: Return the host name.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, if your site is hosted at &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost:8000&lt;/code&gt;, you can go to &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost:8000/foo/bar&lt;/code&gt; to set the value of the key &lt;code class=&quot;highlighter-rouge&quot;&gt;foo&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;bar&lt;/code&gt; and then you can go to &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost:8000/foo&lt;/code&gt; to get the value of &lt;code class=&quot;highlighter-rouge&quot;&gt;foo&lt;/code&gt;(in this case, &lt;code class=&quot;highlighter-rouge&quot;&gt;bar&lt;/code&gt;). To check load balacing, all the endpoints returns the current host name.&lt;/p&gt;

&lt;p&gt;You can check out the code for this in the GitHub &lt;a href=&quot;https://github.com/botleg/tutum-nodejs-redis&quot;&gt;repo&lt;/a&gt;. It is also built into a Docker image under &lt;a href=&quot;https://hub.docker.com/r/hanzel/tutum-nodejs-redis/&quot;&gt;hanzel/tutum-nodejs-redis&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;To run this application, you need to set the following environment variables:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;APP_PORT&lt;/code&gt;: Port to run the Node.js application.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;REDIS_IP&lt;/code&gt;: The IP of the redis instance.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;REDIS_PORT&lt;/code&gt;: The PORT of the redis instance.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We are going to use HAProxy to do the load balancing. Tutum provides it’s own docker &lt;a href=&quot;https://github.com/tutumcloud/haproxy&quot;&gt;image&lt;/a&gt; for HAProxy. If we deploy this image in Tutum and the link a service, it will configure itself based on the target number of containers of that linked service.&lt;/p&gt;

&lt;h2 id=&quot;creating-a-node-clusters&quot;&gt;Creating a Node clusters&lt;/h2&gt;

&lt;p&gt;Create an account with &lt;a href=&quot;https://www.tutum.co/&quot;&gt;Tutum&lt;/a&gt;. Then connect it to your favourite cloud provider. Nodes are server instances or hosts, where we will be hosting the containers.&lt;/p&gt;

&lt;p&gt;Goto Nodes tab and click on the &lt;code class=&quot;highlighter-rouge&quot;&gt;Launch your first node&lt;/code&gt; button. Give a name for the cluster. You can use &lt;code class=&quot;highlighter-rouge&quot;&gt;Deploy tags&lt;/code&gt; to specify where you want the services to be hosted. For this article, it’s not needed. Now select your provider, region and instance type, as needed. I am selecting 1GB instance from Digital Ocean.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/tutum-nodes@2x.jpg&quot; srcset=&quot;/assets/images/tutum-nodes@1x.jpg 300w, /assets/images/tutum-nodes@2x.jpg 600w, /assets/images/tutum-nodes@3x.jpg 900w&quot; sizes=&quot;(min-width: 960px) 900px, 100vw&quot; alt=&quot;New node cluster settings&quot; class=&quot;center-image&quot; /&gt;
&lt;em class=&quot;image-caption&quot;&gt;New node cluster settings&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Now select the number of nodes you want in your cluster. I want two nodes in the cluster. You can change any time as needed. Now click the button &lt;code class=&quot;highlighter-rouge&quot;&gt;Launch node cluster&lt;/code&gt; button to deploy the cluster. This could take a few minutes. Once it’s ready, we can see the status &lt;code class=&quot;highlighter-rouge&quot;&gt;Deployed&lt;/code&gt; for each node.&lt;/p&gt;

&lt;h2 id=&quot;stackfiles&quot;&gt;Stackfiles&lt;/h2&gt;

&lt;p&gt;Each docker image running are called services here. We can add each services and configure it from the Tutum web UI with the &lt;code class=&quot;highlighter-rouge&quot;&gt;Services&lt;/code&gt; tab. However, this is not the best way to do this.&lt;/p&gt;

&lt;p&gt;Tutum supports configuration files called &lt;code class=&quot;highlighter-rouge&quot;&gt;Stackfiles&lt;/code&gt; and those files are named &lt;code class=&quot;highlighter-rouge&quot;&gt;tutum.yml&lt;/code&gt;. This is very similar to &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; with additional parameters for the deployment configuration. We can specify, configure and link services with this file.&lt;/p&gt;

&lt;p&gt;We will start with the redis service. The configuration required for this is given below:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'redis'&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;target_num_containers&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;deployment_strategy&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;high_availability&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;command&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; --&lt;span class=&quot;n&quot;&gt;appendonly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yes&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;expose&lt;/span&gt;:
    - &lt;span class=&quot;s1&quot;&gt;'6379'&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
    - /&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The image used in &lt;code class=&quot;highlighter-rouge&quot;&gt;redis&lt;/code&gt;. The next two parameters are for deployment purpose. The &lt;code class=&quot;highlighter-rouge&quot;&gt;target_num_containers&lt;/code&gt; parameters is for scaling and it show how many instance of this containers that we need. We need only one instance of Redis. There are many deployment strategies available. The &lt;code class=&quot;highlighter-rouge&quot;&gt;high_availability&lt;/code&gt; value ensures that the containers are deployment in such a way that it’s is always available. You can read more about these parameters in &lt;a href=&quot;https://support.tutum.co/support/solutions/articles/5000583471-stack-yaml-reference&quot;&gt;Stackfile docs&lt;/a&gt;. We use the command &lt;code class=&quot;highlighter-rouge&quot;&gt;redis-server --appendonly yes&lt;/code&gt; for persistance with Redis. We need to expose the port 6379 of Redis container to link it to other services. The final parameter &lt;code class=&quot;highlighter-rouge&quot;&gt;volumes&lt;/code&gt;, save the data in &lt;code class=&quot;highlighter-rouge&quot;&gt;/data&lt;/code&gt; folder for persistance.&lt;/p&gt;

&lt;p&gt;The configuration for Node.js application is given below:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'hanzel/tutum-nodejs-redis'&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;target_num_containers&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;deployment_strategy&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;high_availability&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;links&lt;/span&gt;:
    - &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;APP_PORT&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;4000&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;REDIS_IP&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;REDIS_PORT&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;6379&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;expose&lt;/span&gt;:
    - &lt;span class=&quot;s1&quot;&gt;'4000'&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The images used here is &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/tutum-nodejs-redis&lt;/code&gt;. We are using the load balancing of this service. So we will have four instances of this container. Since we have used the &lt;code class=&quot;highlighter-rouge&quot;&gt;high_availability&lt;/code&gt; deployment strategy, each of our two nodes will have two containers of this image each.&lt;/p&gt;

&lt;p&gt;We are linking the redis service to this service with the &lt;code class=&quot;highlighter-rouge&quot;&gt;links&lt;/code&gt; paramter. This allows us to access the port 6379 of redis, which is the exposed port of redis service. We can also access the IP of redis service with &lt;code class=&quot;highlighter-rouge&quot;&gt;redis&lt;/code&gt; keyword.&lt;/p&gt;

&lt;p&gt;Now, we need to set the environment variables. This application will run on the port defined in &lt;code class=&quot;highlighter-rouge&quot;&gt;APP_PORT&lt;/code&gt; variable, 4000 in this case. The IP for redis instance is &lt;code class=&quot;highlighter-rouge&quot;&gt;redis&lt;/code&gt; and the port is 6379. We now expose the port 4000 of this application.&lt;/p&gt;

&lt;p&gt;The final service that we use is for load balancing and the configuration for this is given below:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;&lt;span class=&quot;n&quot;&gt;lb&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'tutum/haproxy:latest'&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;links&lt;/span&gt;:
    - &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
    - &lt;span class=&quot;s1&quot;&gt;'80:80'&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;restart&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;always&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;roles&lt;/span&gt;:
    - &lt;span class=&quot;n&quot;&gt;global&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The image used here is &lt;code class=&quot;highlighter-rouge&quot;&gt;tutum/haproxy:latest&lt;/code&gt; and we are linking the &lt;code class=&quot;highlighter-rouge&quot;&gt;node&lt;/code&gt; service. With the &lt;code class=&quot;highlighter-rouge&quot;&gt;ports&lt;/code&gt; parameter, we can set the ports that are publicly accessible. We are mapping the port &lt;code class=&quot;highlighter-rouge&quot;&gt;80&lt;/code&gt; of the host device with port &lt;code class=&quot;highlighter-rouge&quot;&gt;80&lt;/code&gt; of this container. We set the &lt;code class=&quot;highlighter-rouge&quot;&gt;restart&lt;/code&gt; parameter to &lt;code class=&quot;highlighter-rouge&quot;&gt;always&lt;/code&gt; so that this service will restarted everytime it stops. We also need to set the &lt;code class=&quot;highlighter-rouge&quot;&gt;roles&lt;/code&gt; parameter to &lt;code class=&quot;highlighter-rouge&quot;&gt;global&lt;/code&gt;. This allow this service to communicate with Tutum APIs and reconfigure based on your cluster.&lt;/p&gt;

&lt;p&gt;So the entire Stackfile will be this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;&lt;span class=&quot;n&quot;&gt;lb&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'tutum/haproxy:latest'&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;links&lt;/span&gt;:
    - &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ports&lt;/span&gt;:
    - &lt;span class=&quot;s1&quot;&gt;'80:80'&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;restart&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;always&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;roles&lt;/span&gt;:
    - &lt;span class=&quot;n&quot;&gt;global&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'hanzel/tutum-nodejs-redis'&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;target_num_containers&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;4&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;deployment_strategy&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;high_availability&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;links&lt;/span&gt;:
    - &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;environment&lt;/span&gt;:
    &lt;span class=&quot;n&quot;&gt;APP_PORT&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;4000&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;REDIS_IP&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;REDIS_PORT&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;6379&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;expose&lt;/span&gt;:
    - &lt;span class=&quot;s1&quot;&gt;'4000'&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;:
  &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;: &lt;span class=&quot;s1&quot;&gt;'redis'&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;target_num_containers&lt;/span&gt;: &lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;deployment_strategy&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;high_availability&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;command&lt;/span&gt;: &lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;server&lt;/span&gt; --&lt;span class=&quot;n&quot;&gt;appendonly&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;yes&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;expose&lt;/span&gt;:
    - &lt;span class=&quot;s1&quot;&gt;'6379'&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;volumes&lt;/span&gt;:
    - /&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;deploying-the-stack&quot;&gt;Deploying the Stack&lt;/h2&gt;

&lt;p&gt;To deploy this stack, goto the &lt;code class=&quot;highlighter-rouge&quot;&gt;Stacks&lt;/code&gt; tab in Tutum and click the &lt;code class=&quot;highlighter-rouge&quot;&gt;Create stack&lt;/code&gt; button. Now give a name for this stack and paste &lt;a href=&quot;https://stackfiles.io/registry/56a37bc035a28a01009e57ed&quot;&gt;the Stackfile&lt;/a&gt;. Now, click &lt;code class=&quot;highlighter-rouge&quot;&gt;Create and deploy&lt;/code&gt;. This will deploy all the services. This can also take a few minutes.&lt;/p&gt;

&lt;p&gt;Once the stack is running, goto &lt;code class=&quot;highlighter-rouge&quot;&gt;Endpoints&lt;/code&gt; tab in the stack. This will have all publicly accessible ports of any service. We have only one, the port 80 in load balancer service. A &lt;code class=&quot;highlighter-rouge&quot;&gt;tutum.io&lt;/code&gt; subdomain will be created for this. Open this link to access your stack.&lt;/p&gt;

&lt;p&gt;You can see the hostname in the page. Try reloading this page and we can see that the hostname is changing. This shows that out load balancing is working.&lt;/p&gt;

&lt;h2 id=&quot;tldr&quot;&gt;TL;DR&lt;/h2&gt;

&lt;p&gt;In this article, we deployed a load balanced Node.js application and Redis database with Docker containers with &lt;a href=&quot;https://www.tutum.co/&quot;&gt;Tutum&lt;/a&gt;. We have seen that, Tutum provides us with easy access to powerful features like load balancing and scaling when using Docker hosting.&lt;/p&gt;
</description>
        <pubDate>Wed, 03 Feb 2016 01:00:00 +0000</pubDate>
        <link>https://botleg.com/stories/orchestrate-docker-containers-with-tutum/</link>
        <guid isPermaLink="true">https://botleg.com/stories/orchestrate-docker-containers-with-tutum/</guid>
        
        <category>tutum</category>
        
        <category>docker</category>
        
        <category>container</category>
        
        <category>haproxy</category>
        
        <category>node.js</category>
        
        <category>redis</category>
        
        <category>scale</category>
        
        <category>load</category>
        
        <category>balance</category>
        
        <category>deploy</category>
        
        
        <category>devops</category>
        
      </item>
    
      <item>
        <title>HTTPS with Let's Encrypt and nginx</title>
        <author><name>Hanzel Jesheen</name></author>
        <description>&lt;p&gt;HTTPS is a secure protocol for the internet. Unlike the communication in HTTP, which happens in plain-text, the data transferred between the server and the client with HTTPS is encrypted. HTTPS also verifies the identity of the website we are accessing with a &lt;code class=&quot;highlighter-rouge&quot;&gt;SSL/TLS&lt;/code&gt; certificate. It was initially used in online payment website, but in the recent age of privacy, it is deemed mandatory. That’s where &lt;a href=&quot;https://letsencrypt.org/&quot;&gt;Let’s Encrypt&lt;/a&gt; comes in.&lt;/p&gt;

&lt;p&gt;Let’s Encrypt is a &lt;code class=&quot;highlighter-rouge&quot;&gt;Certificate Authority&lt;/code&gt;, they verify a website and issues certificates. The browsers have a list of trusted Certificate Authorities whose certificates it will accept. There are a lot of Certificate Authorities, so what make Let’s Encrypt different?&lt;/p&gt;

&lt;p&gt;Two main issues with SSL certificates was that, it was paid and the process is not generally automated. Let’s Encrypt solves both these issues. Let’s Encrypt issues certificates &lt;code class=&quot;highlighter-rouge&quot;&gt;free of cost&lt;/code&gt; and it can be automated. You just need root terminal access to the server. It is currently in public beta and is backed by major players like Mozilla, Facebook, Google, etc.&lt;/p&gt;

&lt;p&gt;In this article, we will see how to create a certificate with Let’s Encrypt and use it to host our server via HTTPS. We will be using an &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx&lt;/code&gt; server here but the process is similar to all servers.&lt;/p&gt;

&lt;h2 id=&quot;installing-lets-encrypt&quot;&gt;Installing Let’s Encrypt&lt;/h2&gt;
&lt;p&gt;Use SSH to log into your server as &lt;code class=&quot;highlighter-rouge&quot;&gt;root&lt;/code&gt; user. If you have &lt;code class=&quot;highlighter-rouge&quot;&gt;git&lt;/code&gt; installed in the server, you can clone the Let’s Encrypt repo in &lt;code class=&quot;highlighter-rouge&quot;&gt;/opt&lt;/code&gt; folder.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /opt
git clone https://github.com/letsencrypt/letsencrypt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Otherwise, download the latest &lt;code class=&quot;highlighter-rouge&quot;&gt;tar.gz&lt;/code&gt; package from &lt;code class=&quot;highlighter-rouge&quot;&gt;https://github.com/letsencrypt/letsencrypt/releases&lt;/code&gt; with wget. Extract this to &lt;code class=&quot;highlighter-rouge&quot;&gt;/opt/&lt;/code&gt; and rename the folder to &lt;code class=&quot;highlighter-rouge&quot;&gt;letsencrypt&lt;/code&gt;. Latest version at the time of writing was &lt;code class=&quot;highlighter-rouge&quot;&gt;v0.2.0&lt;/code&gt;, so the commands for this are.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;wget https://github.com/letsencrypt/letsencrypt/archive/v0.2.0.tar.gz
tar xf v0.2.0.tar.gz -C /opt/
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /opt
mv letsencrypt-0.2.0 letsencrypt&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now we have letsencrypt installed at &lt;code class=&quot;highlighter-rouge&quot;&gt;/opt/letsencrypt&lt;/code&gt;. You can add this to &lt;code class=&quot;highlighter-rouge&quot;&gt;PATH&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;lets-encrypt-configuration&quot;&gt;Let’s Encrypt Configuration&lt;/h2&gt;
&lt;p&gt;Before you add SSL certificates, you need to register a domain and the domain must point to the server’s public address. For this, you need to a set up a &lt;code class=&quot;highlighter-rouge&quot;&gt;A&lt;/code&gt; or &lt;code class=&quot;highlighter-rouge&quot;&gt;CNAME&lt;/code&gt; record with your DNS. You can check with your domain registar or custom DNS service to do this. If you have a HTTP site running in the server, you would have already done this.&lt;/p&gt;

&lt;p&gt;Let’s Encrypt need to verify that you own the domain before they provide you with the certificates. This can be done in various ways. If you are running &lt;code class=&quot;highlighter-rouge&quot;&gt;Apache&lt;/code&gt; server, Let’s Encrypt can use it to verify your ownership and even install the certificates in the server for you. There is also something similar for &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx&lt;/code&gt;, but it’s still experimental and not production-ready.&lt;/p&gt;

&lt;p&gt;Another method is &lt;code class=&quot;highlighter-rouge&quot;&gt;standalone&lt;/code&gt;, where the Let’s Encrypt client will create a temporary webserver for verification. However, this need our &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx&lt;/code&gt; server to be shutdown while creating and renewing our certificates. That’s just not viable.&lt;/p&gt;

&lt;p&gt;So we will go with the &lt;code class=&quot;highlighter-rouge&quot;&gt;webroot&lt;/code&gt; method. In this method, we provide a folder path as &lt;code class=&quot;highlighter-rouge&quot;&gt;webroot-path&lt;/code&gt;. This folder must be served by our server. A temporary file will be made inside &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;webroot-path&amp;gt;/.well-known/acme-challenge/&lt;/code&gt; by the client. Let’s Encrypt will access it from the domain to verify the ownership.&lt;/p&gt;

&lt;p&gt;For example, if the domain in &lt;code class=&quot;highlighter-rouge&quot;&gt;www.example.com&lt;/code&gt; and the &lt;code class=&quot;highlighter-rouge&quot;&gt;webroot-path&lt;/code&gt; is &lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/share/nginx/html&lt;/code&gt;. The client will create a temporary file named something like &lt;code class=&quot;highlighter-rouge&quot;&gt;1PnCIkY&lt;/code&gt; inside &lt;code class=&quot;highlighter-rouge&quot;&gt;/usr/share/nginx/html/.well-known/acme-challenge/&lt;/code&gt; and it will accessed from &lt;code class=&quot;highlighter-rouge&quot;&gt;www.example.com/.well-known/acme-challenge/1PnCIkY&lt;/code&gt; for verification of the domain ownership.&lt;/p&gt;

&lt;p&gt;The configuration needed to create the certificates are put in a file named &lt;code class=&quot;highlighter-rouge&quot;&gt;cli.ini&lt;/code&gt; inside &lt;code class=&quot;highlighter-rouge&quot;&gt;/opt/letsencrypt&lt;/code&gt;.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-conf&quot; data-lang=&quot;conf&quot;&gt;&lt;span class=&quot;n&quot;&gt;rsa&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; = &lt;span class=&quot;m&quot;&gt;4096&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;email&lt;/span&gt; = &amp;lt;&lt;span class=&quot;n&quot;&gt;your&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;email&lt;/span&gt;&amp;gt;
&lt;span class=&quot;n&quot;&gt;domains&lt;/span&gt; = &amp;lt;&lt;span class=&quot;n&quot;&gt;domains&lt;/span&gt;&amp;gt;
&lt;span class=&quot;n&quot;&gt;authenticator&lt;/span&gt; = &lt;span class=&quot;n&quot;&gt;webroot&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;webroot&lt;/span&gt;-&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt; = /&lt;span class=&quot;n&quot;&gt;usr&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;share&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;nginx&lt;/span&gt;/&lt;span class=&quot;n&quot;&gt;html&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You need to provide your email address for recovering the certificate credentials. Also add the domains for which you want the certificates for seperated by commas like, &lt;code class=&quot;highlighter-rouge&quot;&gt;example.com, www.example.com&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;nginx&quot;&gt;Nginx&lt;/h2&gt;
&lt;p&gt;We need to set up nginx to serve the &lt;code class=&quot;highlighter-rouge&quot;&gt;webroot-path&lt;/code&gt; folder with nginx. If you have not installed &lt;code class=&quot;highlighter-rouge&quot;&gt;nginx&lt;/code&gt; yet, install it with,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;apt-get install nginx&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now, open the nginx configuration at &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/nginx/sites-available/default&lt;/code&gt; and change it as following to serve &lt;code class=&quot;highlighter-rouge&quot;&gt;.well-known&lt;/code&gt; folder.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-nginx&quot; data-lang=&quot;nginx&quot;&gt;&lt;span class=&quot;k&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;listen&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;server_name&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;domain-name&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  
  &lt;span class=&quot;kn&quot;&gt;root&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/usr/share/nginx/html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;index.html&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;index.htm&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;index.nginx-debian.html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;^~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/.well-known/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;allow&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;create-certificate&quot;&gt;Create Certificate&lt;/h2&gt;
&lt;p&gt;Finally, we are ready to create our first certificate. Execute the following commands.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /opt/letsencrypt
./letsencrypt-auto certonly --agree-tos --config cli.ini&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;certonly&lt;/code&gt; parameter creates the certificate. &lt;code class=&quot;highlighter-rouge&quot;&gt;--agree-tos&lt;/code&gt; flag is used say that we are accepting the terms. &lt;code class=&quot;highlighter-rouge&quot;&gt;--config&lt;/code&gt; flag is used to point to the configuration file, which is found in &lt;code class=&quot;highlighter-rouge&quot;&gt;/opt/letsencrypt/cli.ini&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This creates the SSL certificates in &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/letsencrypt/live/&amp;lt;domain-name&amp;gt;/&lt;/code&gt; folder. Whenever we renew the certificates, the latest will be found in this folder.&lt;/p&gt;

&lt;h2 id=&quot;nginx-https-configuration&quot;&gt;Nginx HTTPS configuration&lt;/h2&gt;
&lt;p&gt;Now that we have the certificates, we can change the configuration in nginx to serve via HTTPS. The HTTPS connection is done via the port &lt;code class=&quot;highlighter-rouge&quot;&gt;443&lt;/code&gt;. The first server block in nginx configuration at &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/nginx/sites-available/default&lt;/code&gt; is to redirect the HTTP traffic to HTTPS. We are also returning a &lt;code class=&quot;highlighter-rouge&quot;&gt;301 Moved Permanently&lt;/code&gt; header back. Replace the &lt;code class=&quot;highlighter-rouge&quot;&gt;domain-name&lt;/code&gt; here to your domain.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-nginx&quot; data-lang=&quot;nginx&quot;&gt;&lt;span class=&quot;k&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;listen&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;80&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;server_name&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;domain-name&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;301&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$host$request_uri&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The second server block is for HTTPS running at port 443. It uses the certificates found at &lt;code class=&quot;highlighter-rouge&quot;&gt;/etc/letsencrypt/live/&amp;lt;domain-name&amp;gt;&lt;/code&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-nginx&quot; data-lang=&quot;nginx&quot;&gt;&lt;span class=&quot;k&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;listen&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;443&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;ssl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;server_name&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;domain-name&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;ssl_certificate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/etc/letsencrypt/live/&amp;lt;domain-name&amp;gt;/fullchain.pem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;ssl_certificate_key&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/etc/letsencrypt/live/&amp;lt;domain-name&amp;gt;/privkey.pem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;root&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/usr/share/nginx/html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;index&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;index.html&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;index.htm&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;index.nginx-debian.html&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;try_files&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$uri&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$uri&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;404&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;^~&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/.well-known/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;allow&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;You can reload the nginx with,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;service nginx reload&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;If your are using reverse-proxy to host in some other port, the configuration will look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-nginx&quot; data-lang=&quot;nginx&quot;&gt;&lt;span class=&quot;k&quot;&gt;server&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;listen&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4125&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;server_name&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;lt;domain-name&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;error_page&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;497&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;https://&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$host&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4125&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$request_uri&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;ssl&lt;/span&gt; &lt;span class=&quot;no&quot;&gt;on&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;ssl_certificate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/etc/letsencrypt/live/&amp;lt;domain-name&amp;gt;/fullchain.pem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kn&quot;&gt;ssl_certificate_key&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/etc/letsencrypt/live/&amp;lt;domain-name&amp;gt;/privkey.pem&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kn&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;proxy_pass&lt;/span&gt;          &lt;span class=&quot;s&quot;&gt;http://127.0.0.1:4125/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;proxy_set_header&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;X-Real-IP&lt;/span&gt;         &lt;span class=&quot;nv&quot;&gt;$remote_addr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;proxy_set_header&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;X-Forwarded-For&lt;/span&gt;   &lt;span class=&quot;nv&quot;&gt;$proxy_add_x_forwarded_for&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;proxy_set_header&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;X_FORWARDED_PROTO&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;https&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;proxy_set_header&lt;/span&gt;    &lt;span class=&quot;s&quot;&gt;Host&lt;/span&gt;              &lt;span class=&quot;nv&quot;&gt;$http_host&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;proxy_buffering&lt;/span&gt;     &lt;span class=&quot;no&quot;&gt;off&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kn&quot;&gt;proxy_redirect&lt;/span&gt;      &lt;span class=&quot;no&quot;&gt;off&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Here, the &lt;code class=&quot;highlighter-rouge&quot;&gt;error_page 497&lt;/code&gt; is used to redirect the HTTP traffic to port &lt;code class=&quot;highlighter-rouge&quot;&gt;4125&lt;/code&gt; to HTTPS.&lt;/p&gt;

&lt;h2 id=&quot;automated-renewal&quot;&gt;Automated Renewal&lt;/h2&gt;
&lt;p&gt;Let’s Encrypt certificates are only valid for 90 days, so you would have to renew them. To renew, you just have to run the client with &lt;code class=&quot;highlighter-rouge&quot;&gt;--renew-by-default&lt;/code&gt; flag also. The command would look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;/opt/letsencrypt/letsencrypt-auto certonly --renew-by-default --agree-tos --config /opt/letsencrypt/cli.ini&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This command will renew the certificate. We can automate renewal by running this command as a &lt;code class=&quot;highlighter-rouge&quot;&gt;cron&lt;/code&gt; job. Cron is a time-based job scheduler. We can make this command run once a month to renew certificates at a monthly basis to prevent it from being expired. We also need to reload the nginx configurations.&lt;/p&gt;

&lt;p&gt;To add a new cron job, type the following command.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;sudo crontab -e&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Add the following lines to the end of the cron file.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nv&quot;&gt;SHELL&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/bin/bash
&lt;span class=&quot;nv&quot;&gt;HOME&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;/
&lt;span class=&quot;nv&quot;&gt;MAILTO&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;”example@mail.com”
30 4 1 &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;/opt/letsencrypt/letsencrypt-auto certonly --renew-by-default --agree-tos --config /opt/letsencrypt/cli.ini &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; service nginx reload&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &amp;gt;&amp;gt; /var/log/letsencrypt.log&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This causes the command to run every month on the 1st at 4:30AM. The output of this command is stored in &lt;code class=&quot;highlighter-rouge&quot;&gt;/var/log/letsencrypt.log&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;As a side note, there are some limits on the number of certificates we can make a week for a single domain. So to try these command with no limits, you can add the flag &lt;code class=&quot;highlighter-rouge&quot;&gt;--server https://acme-staging.api.letsencrypt.org/directory&lt;/code&gt; to Let’s Encrypt commands. This creates dummy certificates, which are NOT valid but you can use it to test the working of the cron job.&lt;/p&gt;
</description>
        <pubDate>Sun, 17 Jan 2016 17:00:00 +0000</pubDate>
        <link>https://botleg.com/stories/https-with-lets-encrypt-and-nginx/</link>
        <guid isPermaLink="true">https://botleg.com/stories/https-with-lets-encrypt-and-nginx/</guid>
        
        <category>https</category>
        
        <category>letsencrypt</category>
        
        <category>ssl</category>
        
        <category>tls</category>
        
        <category>certificate</category>
        
        <category>authority</category>
        
        <category>nginx</category>
        
        <category>git</category>
        
        
        <category>devops</category>
        
      </item>
    
      <item>
        <title>Docker Hosting with sloppy.io</title>
        <author><name>Hanzel Jesheen</name></author>
        <description>&lt;p&gt;&lt;a href=&quot;http://sloppy.io/&quot;&gt;Sloppy.io&lt;/a&gt; is a new Container as a Service (CaaS) platform that you can use to host Docker images. It is currently in a generous private beta, which provides you with 4GB RAM, 10 containers and 10GB storage for free. You can sign up for this &lt;a href=&quot;http://sloppy.io/#signup&quot;&gt;here&lt;/a&gt;. I received the reply from them within the hour. sloppy.io makes it really easy to host and especially scale docker images.&lt;/p&gt;

&lt;p&gt;In this article, we are going to host a Docker project in sloppy.io which has a Node.js server and Redis database. The code for this project can be found &lt;a href=&quot;https://github.com/botleg/docker-sloppy&quot;&gt;here&lt;/a&gt; and the demo of the site can be found &lt;a href=&quot;http://botleg.sloppy.zone&quot;&gt;here&lt;/a&gt;. Also, the docker image we have created with Node.js server is hosted in &lt;a href=&quot;https://hub.docker.com/r/hanzel/docker-sloppy&quot;&gt;Docker Hub&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;the-app&quot;&gt;The App&lt;/h2&gt;
&lt;p&gt;The app has a &lt;a href=&quot;http://redis.io/&quot;&gt;Redis&lt;/a&gt; database and we have used the &lt;a href=&quot;https://hub.docker.com/_/redis/&quot;&gt;official redis image&lt;/a&gt; for it. The Node.js application is also really basic. It connects to this redis database and lets you to set and see the value of a key. It has two routes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;/key&lt;/code&gt;: Returns the value of the &lt;code class=&quot;highlighter-rouge&quot;&gt;key&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;/key/value&lt;/code&gt;: Sets the value of the &lt;code class=&quot;highlighter-rouge&quot;&gt;key&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;value&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, if your site is hosted at &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost:8000&lt;/code&gt;, you can go to &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost:8000/foo/bar&lt;/code&gt; to set the value of the key &lt;code class=&quot;highlighter-rouge&quot;&gt;foo&lt;/code&gt; to &lt;code class=&quot;highlighter-rouge&quot;&gt;bar&lt;/code&gt; and then you can go to &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost:8000/foo&lt;/code&gt; to get the value of &lt;code class=&quot;highlighter-rouge&quot;&gt;foo&lt;/code&gt;(in this case, &lt;code class=&quot;highlighter-rouge&quot;&gt;bar&lt;/code&gt;). You can check out the code for this in the GitHub &lt;a href=&quot;https://github.com/botleg/docker-sloppy&quot;&gt;repo&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The only thing that change for Docker is that, you need to get the &lt;code class=&quot;highlighter-rouge&quot;&gt;host&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;port&lt;/code&gt; for redis connect from environment variables. So the code to connect to the redis instance becomes,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;n&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;createClient&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;REDIS_PORT_6379_TCP_PORT&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;process&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;REDIS_PORT_6379_TCP_ADDR&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The port exists in &lt;code class=&quot;highlighter-rouge&quot;&gt;REDIS_PORT_6379_TCP_PORT&lt;/code&gt; and the host IP is in &lt;code class=&quot;highlighter-rouge&quot;&gt;REDIS_PORT_6379_TCP_ADDR&lt;/code&gt;. We will talk about setting these environment varibles later.&lt;/p&gt;

&lt;h2 id=&quot;dockerfile&quot;&gt;Dockerfile&lt;/h2&gt;
&lt;p&gt;To make this project a Docker image, we need a &lt;code class=&quot;highlighter-rouge&quot;&gt;Dockerfile&lt;/code&gt; for the instructions. The Dockerfile for this project looks like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;no&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;ss&quot;&gt;:argon&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;RUN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;RUN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;sr&quot;&gt;/app
WORKDIR /&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;package&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;json&lt;/span&gt; &lt;span class=&quot;sr&quot;&gt;/app/&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;RUN&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;npm&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;install&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;COPY&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;.&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;app&lt;/span&gt;
&lt;span class=&quot;no&quot;&gt;EXPOSE&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8000&lt;/span&gt;

&lt;span class=&quot;no&quot;&gt;CMD&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;npm&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;start&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;This is pretty basic stuff. We use the &lt;code class=&quot;highlighter-rouge&quot;&gt;node:argon&lt;/code&gt; as the base image, which has version 4 of Node.js. Then we set &lt;code class=&quot;highlighter-rouge&quot;&gt;/app&lt;/code&gt; as the working directory in the image and we copy the &lt;code class=&quot;highlighter-rouge&quot;&gt;package.json&lt;/code&gt; file there. We run &lt;code class=&quot;highlighter-rouge&quot;&gt;npm install&lt;/code&gt; to install all the dependencies and then copy the rest of the repo to &lt;code class=&quot;highlighter-rouge&quot;&gt;/app&lt;/code&gt; folder. Next, we start the application with &lt;code class=&quot;highlighter-rouge&quot;&gt;npm start&lt;/code&gt; command. This Docker image in hosted in Docker Hub named &lt;a href=&quot;https://hub.docker.com/r/hanzel/docker-sloppy/&quot;&gt;hanzel/docker-sloppy&lt;/a&gt;. You can read more about writing Dockerfile &lt;a href=&quot;https://docs.docker.com/engine/reference/builder/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;docker-compose&quot;&gt;Docker Compose&lt;/h2&gt;
&lt;p&gt;Before we actually do the hosting in sloppy.io, let’s see how to do it in a PaaS tool like &lt;a href=&quot;https://www.digitalocean.com/&quot;&gt;Digital Ocean&lt;/a&gt; or &lt;a href=&quot;https://aws.amazon.com/ec2/&quot;&gt;AWS EC2&lt;/a&gt; using the &lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Compose&lt;/code&gt;. It is used to run multi-container applications and the configurations for this are given in the file &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt;. You can read more about it &lt;a href=&quot;https://docs.docker.com/compose/compose-file/&quot;&gt;here&lt;/a&gt;. We have two servies, one for Node.js server and one for Redis database.&lt;/p&gt;

&lt;p&gt;We will start with the &lt;code class=&quot;highlighter-rouge&quot;&gt;redis&lt;/code&gt; service.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;s&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;redis&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;redis-server --appendonly yes&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;expose&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;6379&quot;&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;.:/data&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The image for this is the official &lt;code class=&quot;highlighter-rouge&quot;&gt;redis&lt;/code&gt; image. We need to expose the port &lt;code class=&quot;highlighter-rouge&quot;&gt;6379&lt;/code&gt; for the server to connect to it. By exposing the port, only the other linked services can access it and it is not published to the host machine. So, we have prevented external access to this redis instance. Now, for persistance storage in redis, we need to use a docker volume and map the current folder in host machine to &lt;code class=&quot;highlighter-rouge&quot;&gt;/data&lt;/code&gt; in the docker image. We do this with the &lt;code class=&quot;highlighter-rouge&quot;&gt;volume&lt;/code&gt; configuration. We also need to start redis with &lt;code class=&quot;highlighter-rouge&quot;&gt;appendonly&lt;/code&gt; flag.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; for &lt;code class=&quot;highlighter-rouge&quot;&gt;node&lt;/code&gt; servie looks like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-yaml&quot; data-lang=&quot;yaml&quot;&gt;&lt;span class=&quot;s&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;hanzel/docker-sloppy&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;8000:8000&quot;&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;links&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;redis&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The image for this is the one we have made, &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/docker-sloppy&lt;/code&gt;. The Node.js server is listening to port &lt;code class=&quot;highlighter-rouge&quot;&gt;8000&lt;/code&gt;. We then map the port &lt;code class=&quot;highlighter-rouge&quot;&gt;8000&lt;/code&gt; in the image to port &lt;code class=&quot;highlighter-rouge&quot;&gt;8000&lt;/code&gt; in the host machine. So the application can be accessed in &lt;code class=&quot;highlighter-rouge&quot;&gt;localhost:8000&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We link this service to the &lt;code class=&quot;highlighter-rouge&quot;&gt;redis&lt;/code&gt; service that we had defined earlier. Because of this linking, we can access the redis instance from &lt;code class=&quot;highlighter-rouge&quot;&gt;node&lt;/code&gt; service. This creates the environment variables &lt;code class=&quot;highlighter-rouge&quot;&gt;REDIS_PORT_6379_TCP_ADDR&lt;/code&gt; (for host address of redis instance) and &lt;code class=&quot;highlighter-rouge&quot;&gt;REDIS_PORT_6379_TCP_PORT&lt;/code&gt; (for port of the redis instance), which can be accessed from within the  Node.js application.&lt;/p&gt;

&lt;p&gt;The entire &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt; looks like this,&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-yml&quot; data-lang=&quot;yml&quot;&gt;&lt;span class=&quot;s&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;hanzel/docker-sloppy&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;ports&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;8000:8000&quot;&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;links&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;redis&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;redis&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;redis&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;redis-server --appendonly yes&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;expose&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;6379&quot;&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;volumes&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;.:/data&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Now, you can start this application with &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose up -d&lt;/code&gt; command.&lt;/p&gt;

&lt;h2 id=&quot;hosting-with-sloppyio&quot;&gt;Hosting with sloppy.io&lt;/h2&gt;
&lt;p&gt;Hosting in sloppy.io is similar to using &lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Compose&lt;/code&gt;, but you need to write &lt;code class=&quot;highlighter-rouge&quot;&gt;sloppy.json&lt;/code&gt; for configurations here. Most of the parameters here are the same, but there are a few additional parameters here, which is for the hosting purpose. Documentation about &lt;code class=&quot;highlighter-rouge&quot;&gt;sloppy.json&lt;/code&gt; can be found &lt;a href=&quot;http://sloppy.io/home/documentation/reference/the-sloppy-json/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the json file, each project can have multiple services and each service can have multiple apps. That seems a bit overwhelming. In most cases, we would need only one application in each service. For this application, we have two services:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;frontend&lt;/code&gt;, containing the &lt;code class=&quot;highlighter-rouge&quot;&gt;node&lt;/code&gt; application.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;backend&lt;/code&gt;, containing the &lt;code class=&quot;highlighter-rouge&quot;&gt;redis&lt;/code&gt; application.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The json for &lt;code class=&quot;highlighter-rouge&quot;&gt;frontend&lt;/code&gt; service is given below.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;frontend&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;apps&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;node&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;domain&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;uri&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{subdomain-name}.sloppy.zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;HTTP&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;instances&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;mem&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;image&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;hanzel/docker-sloppy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;port_mappings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;container_port&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8000&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;env&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;REDIS_PORT_6379_TCP_ADDR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;redis.backend.botleg.{user-name}&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;dependencies&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;../../backend/redis&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Here, we have one app named &lt;code class=&quot;highlighter-rouge&quot;&gt;node&lt;/code&gt;. The default url provied by sloppy.io is a &lt;code class=&quot;highlighter-rouge&quot;&gt;sloppy.zone&lt;/code&gt; subdomain. You can also use a custom domain with CNAME records. We use the domain property object to choose the service URL, change &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;subdomain-name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt; as you require. Next, we have asked sloppy to create 2 instances of this application, with each instance having 512MB RAM. Then we have the docker image name, which is &lt;code class=&quot;highlighter-rouge&quot;&gt;hanzel/docker-sloppy&lt;/code&gt;. We use the &lt;code class=&quot;highlighter-rouge&quot;&gt;port_mappings&lt;/code&gt; property to tell which port of the container to be used when the URL is accessed.&lt;/p&gt;

&lt;p&gt;Instead of &lt;code class=&quot;highlighter-rouge&quot;&gt;links&lt;/code&gt; property in &lt;code class=&quot;highlighter-rouge&quot;&gt;docker-compose.yml&lt;/code&gt;, we have &lt;code class=&quot;highlighter-rouge&quot;&gt;dependencies&lt;/code&gt;. We will write the &lt;code class=&quot;highlighter-rouge&quot;&gt;backend&lt;/code&gt; service soon and it will have the &lt;code class=&quot;highlighter-rouge&quot;&gt;redis&lt;/code&gt; app. Now, this dependency doesn’t create the environment variable as we had seen in &lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Compose&lt;/code&gt;. Rather, the host of the redis instance can be accessed with &lt;code class=&quot;highlighter-rouge&quot;&gt;redis.backend.botleg.{user-name}&lt;/code&gt;. Here change &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;user-name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt; to your sloppy.io username. This gives the IP for redis app in backend service of botleg project by &lt;code class=&quot;highlighter-rouge&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;user-name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;. To make our application work, we need to set this as the environment variable &lt;code class=&quot;highlighter-rouge&quot;&gt;REDIS_PORT_6379_TCP_ADDR&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The json configuration for &lt;code class=&quot;highlighter-rouge&quot;&gt;backend&lt;/code&gt; service is given below.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;backend&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;apps&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;redis&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;instances&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;mem&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;image&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;redis&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;cmd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;redis-server --appendonly yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;volumes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;container_path&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/data/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;mode&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;RW&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;40MB&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We have an app name &lt;code class=&quot;highlighter-rouge&quot;&gt;redis&lt;/code&gt; and we have one 512MB RAM instance of it. The image used in the official &lt;code class=&quot;highlighter-rouge&quot;&gt;redis&lt;/code&gt; image. We start &lt;code class=&quot;highlighter-rouge&quot;&gt;redis-server&lt;/code&gt; with &lt;code class=&quot;highlighter-rouge&quot;&gt;--appendonly&lt;/code&gt; flag with the &lt;code class=&quot;highlighter-rouge&quot;&gt;command&lt;/code&gt; property. We then set a 40MB docker volume pointing to &lt;code class=&quot;highlighter-rouge&quot;&gt;/data&lt;/code&gt; in the docker image.&lt;/p&gt;

&lt;p&gt;The entire sloppy.json will look like this.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-json&quot; data-lang=&quot;json&quot;&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;project&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;botleg&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;services&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;frontend&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;apps&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;node&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;domain&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;uri&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;{subdomain-name}.sloppy.zone&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;type&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;HTTP&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;instances&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;mem&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;image&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;hanzel/docker-sloppy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;port_mappings&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;container_port&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8000&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}],&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;env&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;REDIS_PORT_6379_TCP_ADDR&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;redis.backend.botleg.{user-name}&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;dependencies&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;../../backend/redis&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;backend&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;apps&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;id&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;redis&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;instances&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;mem&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;image&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;redis&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;cmd&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;redis-server --appendonly yes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;volumes&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;container_path&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;/data/&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;mode&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;RW&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
        &lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&quot;size&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;40MB&quot;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
      &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;

    &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
  &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}]&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;To host this project, install sloppy CLI from &lt;a href=&quot;http://sloppy.io/home/documentation/&quot;&gt;here&lt;/a&gt;. Login in with sloppy CLI with &lt;code class=&quot;highlighter-rouge&quot;&gt;sloppy login&lt;/code&gt; command. Type in your sloppy.io username and password. Then come to folder where you have this &lt;code class=&quot;highlighter-rouge&quot;&gt;sloppy.json&lt;/code&gt; and type the command &lt;code class=&quot;highlighter-rouge&quot;&gt;sloppy start sloppy.json&lt;/code&gt;. This will start up the application in a few minutes.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Now, you have seen how easy it is to host Docker images with &lt;a href=&quot;http://sloppy.io/&quot;&gt;sloppy.io&lt;/a&gt;. If you have experience with &lt;code class=&quot;highlighter-rouge&quot;&gt;Docker Compose&lt;/code&gt;, you will feel right at home. Even otherwise, it is pretty simple. If you are working with Dockers, a CaaS like sloppy.io will provide you with easy hosting and scaling of the Docker images.&lt;/p&gt;
</description>
        <pubDate>Sun, 03 Jan 2016 16:00:00 +0000</pubDate>
        <link>https://botleg.com/stories/docker-hosting-with-sloppyio/</link>
        <guid isPermaLink="true">https://botleg.com/stories/docker-hosting-with-sloppyio/</guid>
        
        <category>docker</category>
        
        <category>hub</category>
        
        <category>sloppy.io</category>
        
        <category>container</category>
        
        <category>node.js</category>
        
        <category>redis</category>
        
        <category>docker-compose</category>
        
        <category>dockerfile</category>
        
        <category>sloppy.json</category>
        
        
        <category>cloud</category>
        
      </item>
    
  </channel>
</rss>
